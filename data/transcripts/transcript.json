{
  "text": " So, hello everyone. Welcome to the PC seminar. Today we have with us Professor Amir Mohad from American University of Beirut and he'll be talking on the Goethe and Parameterized Complexity of Token Sliding and Token Jumping. Thank you for joining us Professor. Over to you now. Thank you, Prasipatay. Thank you for having me. It's a real pleasure to be here. So, all right, let's jump right into it. So, since I did not really know the audience too well, I made the assumption that many of you maybe have not seen this area of combinatorial reconfiguration problems. So, I decided what I'm going to do is I'm going to give a gentle introduction to the area just to show you how many exciting problems and open problems are there. And then I will talk more about token jumping and token sliding specifically, what we know about them, what we knew about them before we started working on this project, what we managed to discover and the tons of questions that remain to be answered. Right? And it's a really, I mean, the questions are so nice to state, so easy to state and they are accessible really to researchers at any level, which is one of the reasons why I enjoy working on these problems. So, hopefully, you'll get to enjoy them too. So, before I start, I should point out that this is joint work that started back in the combinatorial reconfiguration workshop almost two years ago. And it's joint work with Valentin Barche, Nicolas Busquet, Clement Dallard and Karl Lohmer, who is my master's student. All right. So, the outline of the talk, it's going to be in four sections. I will give a gentle introduction to combinatorial reconfiguration because I know many of you might not have seen such problems. Then I will talk about token jumping and token sliding, what we know about them in terms of classical complexity or one-dimensional complexity. Then I'll talk about the parametreous complexity of these two problems and what we know as of today, as we speak, and what are the problems that remain to be solved. And then the last part of the lecture is where I will put some of the technical stuff to show you, to give you an idea about how we prove things when we deal with such problems and where are the difficulties and what kind of techniques have been developed. So, I try to keep the technical part as light as I could so that really, I mean, I can focus on the big picture and the questions to be asked and answered. So, if you have any questions along the way, please feel free to interrupt me either in the chat or by unmuting yourselves. So, don't worry about leaving the questions till the end. You can interrupt me whenever you feel, whenever I say something that doesn't make sense. Hopefully, that won't happen too often. All right, so what is combinatorial reconfiguration? So, the best way, I think, to introduce is with a familiar example, which is one player games and the most common one that we use is the 15 puzzle game. So, for those of you who don't know the 15 puzzle game, so you're given like a four by four grid and you have one empty square and basically, you have all the remaining 15 squares are numbered from 1 to 15 and they come in some ordering and your job is to basically move the squares around so that all the numbers become ordered. So, it's a byro, so they have to be ordered this way. So, if you notice in this figure, the only problem is that 14 and 15 are reversed, but the only moves that you're allowed to do is to basically move a number into the empty square and basically, you have to do a sequence of moves so that you get all of the numbers in order. And for those of you who know this game, this example that I have on the slide is actually unsolvable. There is no way you can flip the order of 14 and 15 in this puzzle. And I have a link here if you want to actually play the puzzle online, which is pretty fun. So, why do I do I start my talk by talking about 15 puzzle? It's because it's really, I mean, the way you solve the 15 puzzle tells you a lot about the area of combinatorial reconfiguration. So, the standard way we would think about the 15 puzzle is by looking at the state space or what we call the reconfiguration graph of the 15 puzzle. So, what does that graph consist of? Well, we have one vertex or one node in this graph for each possible configuration of the puzzle. So, basically, each possible configuration, so it would be a possible permutation of the 15 numbers in addition to where you're going to put the empty square. Each one of those will be a vertex in the graph. And now we connect two vertices in that graph whenever one can be reached from the other by a single move. And what do we mean here by a single move where it's basically just moving a number into the empty square? So, if you look at the top node here in this graph, there are four possibilities that you can do in one move, which we call a reconfiguration step, which is you can move nine into the empty square, you can move three into the empty square, 12 or 15. And that gives us basically four neighbors of that vertex in the graph. Okay, and we call this whole graph the reconfiguration graph or the state space if you're more comfortable thinking about states, the states of the game. So, now, given this graph, the reconfiguration graph, there are tons of very interesting questions that you can ask about it. There are structural questions and there are algorithmic questions. And these are typically the types of questions that we're interested in in this area of combinatorially configuration. So, a couple of examples of structural questions would be, well, the simplest one would be how big is this reconfiguration graph, right? How many vertices or how many edges? And that's usually not a very hard question to answer in terms of upper and lower bounds. More interestingly, you could ask, is this reconfiguration graph connected, right? Or is, can I reach any state starting from any other state by a sequence of legal moves? And as I told you before, for the 15 puzzle, the reconfiguration graph is definitely not connected, because there was no way to reverse 14 and 15 in the previous example that I showed you, and you can easily prove that, by the way. So, when it's not connected, another question would be, how many components does it have? Is there some sort of nice structure to the components of this graph? And then another question would be, what is the diameter of this reconfiguration graph or of each one of its components? And that's usually a very important question to ask when you're dealing with one-player games, because this could tell you what would be the worst possible shortest path to reach a target configuration or to solve your game, to win your game, for example. And in the literature, this is sometimes known as God's number, which would be the diameter of the reconfiguration graph. And these are all very interesting structural questions to ask about this reconfiguration graph. Now, on the algorithmic side or the computational side, there's the obvious question of, if I'm given a starting state and some ending state or target state, like in the case of the puzzle game, that I'm given some starting state and we know what the goal state is. So, here one decision problem would be to answer the question whether it's possible to get to the target state starting from some initial state that is also given to me. So, you could decide to solve this problem either as a decision problem or as a search problem, which would give you the actual sequence of steps that will take you from a state to the target state. Other interesting computational problems, is it always possible to go from one configuration to any other? And this is basically also related to the structural question about connected components. And the last question that I will mention, which is also interesting, is how fast can you go from one configuration to another? Meaning, can you do it in at most case steps? There is a question I should wait or no? Okay. All right. So, think about all of these questions that we paused using the simple 15 puzzle game. And now we're going to look at a lot of other possible problems where the same any configuration graph can be extracted. And we can ask the same set of questions. So, all of you here are familiar with the KSAT problem. So, you're given a Boolean formula and you want to know if you can satisfy this formula by assigning values to the variables. And we know that this is NP-complete for K greater than or equal to three. So, now how can you transform this into a reconfiguration problem? Well, it's very simple. So, now you're given a formula and you're given two satisfying assignments. So, you can think of those satisfying assignments as bit vectors. And so, now the question that you can ask is, can I go from the first satisfying assignment to the next one by basically flipping one bit at a time under the condition that I remain a satisfying assignment at all times? And notice that without this condition, the problem is trivial. So, you can basically just flip the bits however you like and reach S from T or T from S. But once you add this constraint of you should remain a satisfying assignment, the problem becomes way more interesting. And you can think of this problem again as walking in the solution space of the given formula of all the satisfying assignment of the formula F. All right, so that's the SAT reconfiguration problem. Let's look at another example. Graph coloring. We all know it, we all love it. You're given a graph and some integer K and you are asked whether you can properly K color the graph G. And we know again that this is NP-complete for K greater than or equal to three. How do you transform that into a reconfiguration problem? Well, now you're given a graph, you're given two colorings of the graph, alpha and beta. And the question is, can you recolor alpha to get the, to beta? But you need to recolor one vertex at a time and you need to remain a proper K coloring throughout. Same idea again leads us to this notion of the reconfiguration space where we are looking at the K colorings of the graph and how they are connected under this adjacent simulation that we define, which is a single vertex recoloring. The final example that I will mention, which will be basically what we will focus on in the rest of the talk is a token placement, I call it, but as you will all guess, this is the famous independent set problem. But we will look at it as a token placement problem because it will be more useful for the rest of the talk. So you're given a graph G and an integer K. And the question is, can you place K tokens on your graph, K black tokens, so that no two of these tokens share an edge? And of course, we all know that this is an NP-complete problem. So how can you transform this problem into a reconfiguration problem? Again, now I'm given a graph, two independent sets of the graph, each of size K. And the question is, can I go from one independent set to the other under what rule? So here defining the rule for independent set, how can I go between consecutive independent sets becomes a little bit less obvious. And there are two main strategies that people have attempted. So the first rule is what we call token jumping. So you are basically allowed to take any token on your graph and jump it to any other vertex on the graph, assuming that it doesn't have a token and that you maintain an independent set at all times. So for example, in this example that I have here, it would be perfectly okay to take this token here and jump it to this vertex here. Or I could also take this token here and jump it to this vertex here. So that no, actually that would violate the independence. So you can jump to any other vertex as long as you maintain independence. And we call that the token jumping rule. The other rule is basically token sliding. So in this case, we only allow a token to slide along edges of the graph. So a token can only move to an adjacent vertex, assuming of course this does not violate independence. So now we have two different reconfiguration graphs we can think about. We can think about the reconfiguration graph under the token jumping adjacency. And we can think about the reconfiguration graph under the token sliding adjacency. And we're going to talk about these two different problems because they do actually behave quite differently and they produce quite interesting results. Like the difference between the two, we don't fully understand yet, but we kind of know that token sliding can be harder than token jumping. But there's still a lot of questions to be answered. All right. So some of you might be asking, why do we care about studying such problems? There's a lot of motivations out there. I mean, as sometimes I would say you don't need motivation. They're interesting. There's a lot of open questions that we need to answer. But you can also think about reconfiguration problems as another way of modeling real world algorithmic problems. Because you usually never start from scratch. When you're trying to solve real world problems, you usually start from something and you're trying to prove it or make it better or change it to something more appropriate. Another very good application of studying these problems is that they give you a better understanding of solution spaces, which can be very important for other areas as well. And they have been used in statistical physics, quantum computing, and in the field of physics, quantum computing, and in complexity theory, combinatorics, and robotics, and hopefully many more applications to come. But what I would tell you is that there are so many very interesting problems that are so easy to start thinking about without having too much background, which is why I think this is a very nice area to start working on at any level in your research career. All right, so I'll take a break here and take questions if there are any. And then we will dive into the token jumping and token sliding problems, what we know about them, in terms of classical complexity, and what was basically the starting point for the project that led us to this paper. Any questions at this point? I apologize for the small context which I am interrupting here. So this is just to announce for the PC 301 workshop that will be happening in December end. And this will be slightly different from the previous two workshops. First major difference, this will be online. Second is some advanced topics will be discussed. So anyone who intends to explore somewhat more complex topics in parameterized algorithms is invited to have a check. They can look at the website that has been shared on the chat. And if you wish, you can register simply by filling a form that is linked at the bottom of the webpage. So just to inform you all about it and sorry for the interruption professor. Now you can come to us. All right. All right. So let's start talking about token jumping, token sliding, and a little bit about classical complexity. I know everybody here knows about P and NP. So I'm not going to talk about this. Some of you might not be familiar with the PSPACE class. So just a quick note that's as much as you will need to know for this talk is that PSPACE is the set of all decision problems that can be solved using a polynomial amount of space. And the reason why I mentioned this class is because many, many, many, many reconfiguration problems actually are PSPACE complete. Okay. And so what we know, the standard inclusion is we know that P is contained in NP, which is contained in PSPACE. But a very useful thing about PSPACE is that Savage proved that it's equal to NP SPACE. So polynomial space and non-deterministic polynomial space are the same class, basically. And that's extremely useful when you start to think about reconfiguration problems. Because if you think about a reconfiguration problem where you're given some state and you want to reach the other one. So basically you can solve that easily in non-deterministic polynomial space, which basically implies that they are in PSPACE. But actually you can show a lot more than that. You can show that many, really many reconfiguration problems are actually PSPACE complete, which is not surprising. The fact that many of these reconfiguration problems are PSPACE complete is not very surprising. And them not being in NP is because they don't always have polynomial size certificates, which also makes sense. Because sometimes the number of steps that you need to take to go from one configuration to the other might very well be exponential in the graph size. But there are also some extremely surprising results. And these are some of the results, some of my favorite results in the area. So for example, you all know that coloring is NP complete even for K equals three. However, it turns out that if you try to solve the recoloring problem for K equals three, it's actually polynomial time solvable. So if I give you two, three colorings of a graph and I ask you, is there a path between them that recolors one vertex at a time and is always a valid three coloring, then this problem can be solved in polynomial time. And the recoloring problem only becomes PSPACE complete for K equal four and more. Right. So that's the first surprising result. Another very surprising result is that as your old FPT experts here, I know that you're all familiar with the fact that usually when we study problems on graphs of bounded bucket width, path width, tree width, they tend to become easier. It turns out that that's not really the case for reconfiguration problems, at least for token sliding and jumping, which is the two problems that are related to independent set. It turns out that those two problems remain PSPACE complete even if you have a graph of constant tree width or path width or even bucket width. So a very, very, very simple graph structure. Still the problem remains hard. All right. And finally, the last theorem that I also like a lot shows you basically that sliding and jumping behave differently. And it was shown that if you restrict yourself to bipartite graphs, where we know that max independent set can be solved in polynomial time, if you restrict yourself to those graphs, it turns out that token jumping is NP complete, whereas token sliding is PSPACE complete, which is a strange difference between the behavior of those two problems. All right. So in fact, we know a lot more about token sliding and token jumping. These problems have been at the heart of the area of combinatorial reconfiguration. They have been studied so much. And we know so much about them, at least in terms of standard or classical complexity. So some of the important results for our paper that we're going to focus on is this result. So that's going to be the starting point of the results that we will discuss next when we move to parametrize complexity. So the fact that token sliding and token jumping, our PSPACE complete and then NP complete respectively on bipartite graphs was the starting point of our next paper. But there are some very interesting results here that are also worth mentioning. So for example, for even whole field graphs, we know how to solve token jumping in polynomial time. But the complexity of independent set even remains open on this class of graphs. And the complexity of token sliding also remains open. So we don't know how to check if given two independent sets, I can slide one to the other. Can you answer that question in polynomial time for even whole free graphs? For split graphs and chordal graphs, they also behave extremely differently, token sliding and token jumping. So token sliding is PSPACE complete on split graphs and chordal graphs while token jumping is polynomial time. And that is some of the reasons why we feel that token sliding is harder usually than token jumping. But it's not always the case. All right. So that's it for classical complexity. So now let's move on to parametrize complexity. And let's basically think about how you can parametrize those two problems, token jumping and token sliding. So there's the obvious parameter would be the number of tokens. Right. So one of the obvious parameters would be the number of tokens. So and we're going to denote that by K. Another parameter would be the length of the sequence, like how many steps does it take to go from one independent set to the other? You can also obviously parametrize by tree width or path width or any combination of the above. When we started working on this problem, our initial aim was to basically study the parametrized complexity of token sliding and token jumping on bipartite graphs using the parameter K number of tokens. Right. Because remember, we saw that token sliding is PSPACE complete on bipartite graphs and token jumping is NP-com. So you were interested to see if basically this is going to give us W1 hardness for token sliding and FPTNES for token jumping. Or at least that was the initial hope. That's why we started working on this project. We weren't able to answer the two questions. So we were able to answer one side of the question, which is we were able to show that on bipartite graphs, token sliding is in fact W1 hard. So token sliding parametrized by the number of tokens on bipartite graphs is W1 hard. We were not able to answer the question for token jumping. So that is still an open question. So we haven't answered that question and failed on the next question. We started thinking about ways to basically simplify a little bit some of these questions. So the next thing we asked ourselves, so there are two directions where you can try and simplify. So the next thing we asked ourselves was, okay, so from bipartite graphs, how can I go to other classes of graphs and see where token jumping becomes hard or easy? And it turned out that if you basically exclude only C4 from your graph, right? And so because in bipartite graphs, you're excluding all odd cycles. Right? So we started thinking about what kinds of cycles affect the behavior of those problems. So the first question was, what about C4 free graphs? And it turned out that both problems remain W1 hard on C4 free graphs. Now, if you exclude C3 and C4, it turns out that token jumping becomes FPD, has an order K squared kernel. But for token sliding, we were not able to determine the complexity. Now, if you go to the other side of that, so what if we enforce both bipartite as well as C4 freeness? So in that case, we were able to show that both problems became FPD. Okay, and basically the bipartite bounded degree graphs was just a stepping stone to get to the bipartite C4 free graph result. So let me repeat that maybe slightly more clearly. So after basically answering the first question, which was bipartite graphs, we were able to show that token sliding was W1 hard, but we were not able to determine the complexity of token jumping. So then we went to C4 free graphs, and we were able to show that both problems are actually W1 hard. Then if we added one more constraint, which was C3 C4 free graphs, we got FPDness for token jumping, but it remained open for token sliding. And on the other side of the spectrum, so if we keep bipartite and enforce the C4 freeness, we get FPD for both problems. And as a side note, this blue result is not part of our paper. This was known prior to our paper. So any questions about the results? No questions. All right, cool. So lots of open problems. The first and obvious one is what is the pattern? Is token jumping FPD paramptres by K on bipartite graphs? And that's really, I mean, that was the initial question that we set out to answer and couldn't. So that remains open. And so I will not be going over the hardness reduction for token sliding on bipartite graphs because it's quite technical. I don't feel a talk is the right place to go over it. But if you go over the reduction, you will see that that it's the two problems really behave differently. And there doesn't seem to be a chance to basically make the same type of reduction work for token jumping. So the second interesting open question is how about token jumping parametrized by K on triangle free graphs? That's basically even more general than question one. Right? So and the reason why I mentioned this question separately is because almost every reduction that I know of includes large cliques. So you need to use large cliques in your reductions. So how about if we don't allow triangles and large cliques? So can we then say something about the problem? So that's for token jumping. Now when you go to token sliding, so the open problem is what happens for token sliding on graphs of girth at least five? So if they are C3, C4 free. Or you can even make that a bit weaker and ask for any girth of at least P for some constant P. And for all of these questions, of course, polynomial kernels would be interesting as well, because in our case, we do get polynomial kernels for the FPT. The polynomials are not great, but polynomial regardless. All right. So in the rest of the talk, I will try to cover some of the technical stuff. And as promised, I will try to keep it as light as possible so that I can give you some of a lot of the intuition and techniques that are used in this paper and that are generally used when dealing with reconfiguration problems. So the first result that we will go over is this W hardness on C4 free graphs, right? For both token sliding and token jumping. It's the same reduction and you will get both results because we will be using maximum independent sets. So if you're trying to basically do token sliding from one maximum independent set to the other or token jumping, these two rules become equivalent. Jumping becomes equivalent to sliding. Jumping becomes equivalent to sliding. So when you're dealing with maximum independent sets, these two basically rules are the same. And that's what we're going to do. But what we're going to prove actually is a stronger theorem. What we're going to prove is the following theorem. If you take any P greater than or equal to four, then both problems are W hard on C4, C5, dot, dot, dot, up to Cp free graphs, which implies of course C4 free graphs. But you can basically exclude any cycles from C4 up to Cp for constant P and the problems will remain W1 hard. So how do we prove this result? In fact, we use a known reduction from a problem known as grid tiling, which is a W1 hard problem. And grid tiling is reduced to the independent set problem on C4 up to Cp free graphs. And that reduction was used to show that independent set remains W1 hard if you exclude C4 up to Cp for any constant P. But what is interesting and useful in that reduction is the graph that is obtained from the reduction. So the graph that is obtained from the reduction has three properties that are going to be useful to us. The first property is that you can partition the graph into basically 8k squared into P plus one cliques. So you have a bunch of cliques, each of size n, and all of the edges basically are between the cliques. But that's it. That's it. That's the whole of the graph. It's a bunch of cliques and edges between them. Of course, the more important property as well here is that this graph is going to be C4 up to Cp free. It will not have any of those cycles as an induced subgraph. And it's an equivalent instance to the grid tiling instance. And that basically gives you W1 hardness of independent set on this class of graphs. So notice in this case that an independent set of size 8k squared into P plus one will have to be a maximum independent set because that's how many cliques we get in the resulting graph. And that's basically the sizes that we will be working with more or less up to some modifications. But this will allow us to basically conclude that both sliding and jumping are hard on this class of graphs. So how do we use this for showing hardness of token sliding and token jumping? And let's focus on token sliding for now because it's going to be the same anyway. So we have those cliques and some edges that go between the cliques. So the first attempt would be as follows. We will add a universal vertex to each one of the cliques and we will call this the starting set or the starting independent set. And then we add another universal vertex to each one of the cliques and call this the target independent set. And now basically we have our instance of token sliding. We want to slide everybody in S down to T. So notice that this is useful because we don't introduce any of the forbidden cycles. So we are still fine. And if we could guarantee that all of the tokens will be on the on the cliques simultaneously, then this will imply an independent set in the original graph, which concludes our proof. But unfortunately in this case, we definitely cannot conclude that because each red token can slide independently here and then here and then the next one can follow, etc, etc, etc. So you need some way of forbidden, of forbidding these tokens to behave freely. We want to make sure that they will all be inside the cliques simultaneously and we will be done. And notice that we're going to have 8k squared and 2p plus 1 tokens, right? One for each clique and two universal vertices for each clique. So how do we fix this simultaneity issue? Well, here's how we can do it. So instead of simply adding universal vertices, we're also going to add an edge between every two universal vertices of a clique and then we're going to add something that we call a switch. And in this case, it's a simple edge and the red token here needs to go to the blue position, right? So now we have one extra token inside our graph. But now notice what happens. If any red token wants to come to the blue position, then this red token needs to be moved to this position before. And if you move that token up to the blue position, then you can no longer have any of the red tokens on the universal vertices, which means that they will all have to be simultaneously inside the cliques. And now we get the behavior that we want. So now we can guarantee that if there is a sequence that takes the red tokens to the blue position, then some way along that sequence, the tokens are all going to be within the cliques. Unfortunately, what happened here is we might have introduced some of the forbidden cycles. We can no longer guarantee that this is C4 up to CP3. So what you can do in this case to solve this problem, and I'm not going to go into the details, but the intuition should be pretty clear is that you can subdivide those edges, make them long enough so that you don't introduce any forbidden cycles, and add appropriate tokens inside of them to get the same behavior. Because notice that the number of such edges is bounded by a function of K, by a function of, yes, K and P. So you can make these edges, subdivide them as many times as needed, add as many tokens as needed to maintain all the properties that we need, and to maintain that we're going from one maximum independent set to the other, which will give you W1 hardness for both token sliding as well as token jumping. All right. Questions? No questions. All right. So let's keep going. So now I'm going to talk about some positive, a positive result. So the result that I'm going to talk about is this one here. Right? So I'm going to show you that on C3, C4 free graphs, token jumping is actually FPT and has a quadratic kernel. But again, what we will show is a stronger result. So what we will show is the following theorem. What we will show is, can be summarized as follows. So if you look at any graph, or at any instance of the token jumping problem, so remember an instance of token jumping has the input graph, the starting set, the target set, and K as the number of tokens. So let me try and draw something here. So if you look at your graph, you can kind of decompose it into something which is more or less as follows. So you have S, you have T, the intersection need not be empty. And then you have the neighborhood of S, you need T. And then you have the rest of the graph. So we're going to call the rest of the graph H. And we're going to call the closed neighborhood of S, you need T, or if you will, this yellow part here, we call that J. Right? So we can think of our problem of our graph as being decomposed into those two areas, H and J. Okay, so the theorem states the following. If H is epsilon sparse, where epsilon sparse means that the number of edges is at most N squared minus epsilon, positive epsilon. So if H is epsilon sparse, and J is C3, C4 free, then the problem admits a kernel, which is that big, k squared plus k into one plus one over epsilon. So notice now that we only need that H is epsilon sparse. And we only require C3, C4, freeness inside J, which is S union T closed neighborhood, closed neighborhood of S union T. And this idea is actually, is not a new idea. So this idea is, okay, I had the drawing here, I should have used it. So the idea comes from, has been used before. And it's what we call the buffer technique for the token jumping problem. And then the intuition behind the buffer technique is very simple. So if I have S union T, but somewhere in the graph, which is not in the closed neighborhood of S union T, I have a case sized independent set, then you are done. Right, if I have a case sized independent set in H, then you're done. You can basically take all the tokens on S, jump them into those independent yellow vertices in H, and then jump them back to T. So in some sense, when H has a large independent set, that's the easy case. Right, you're done. If you can find a large enough independent set in H, you're done. And that's what we call the buffer technique, because it's been also used to show that the problem is FPT on planar graphs, for example, or K3J free graphs, so graphs without large bikings. So it's a well known technique. All right. So what do we show? So we're going to use the buffer technique, and we're going to combine it with something else. So we show that you have a yes instance whenever one of those two conditions is true. The first condition is that H is epsilon sparse and contains more than this many vertices. And this is relatively easy. When you contain this many vertices and you add epsilon sparse, then you will have a case sized independent set. And that's basically the buffer technique. When H is epsilon sparse and has that many vertices or more, then H is guaranteed to have an independent set of size K and you're done. So now you are stuck with what happens inside J, or the closed neighborhood of S union T. And it turns out there, if you have C3C4 freeness, the only thing you need on top of that to guarantee a yes instance is a vertex of degree at least 3K. So if you have C3C4 freeness inside J and the vertex of degree 3K, then again, you get a yes instance. So let me prove those two statements separately, because they will be basically what we need for the final theorem, for the final theorem. So the first lemma, as I told you, if H is epsilon sparse and has more than this many vertices, then it's a yes instance, because you have a case sized independent set in H. The idea of this proof is simple. It's a counting argument. And what you need to do basically first is to show that H must contain a vertex of degree less than an over K. And then basically you apply the standard greedy packing algorithm for constructing an independent set of size K. And the reason you show that, the way you show that H has a vertex of degree less than N over K is, again, standard counting argument and the hand shaking lemma. So if the minimum degree in H was at least N over K, then the number of edges would be at least N squared over 2K, which will only happen in an epsilon sparse graph when N is less than or equal to K to the power 1 over epsilon. And the rest of the proof is basically an induction on K. And so that shows you that when you do have an epsilon sparse graph with more than this many vertices, then we have a yes instance. All right, so how about the second part of the claim? So now what happens if we have a C3 C4 free J that has a vertex of degree 3K? Well, let's see what happens. So if we have a vertex of degree 3K, and I'm going to circle it here in yellow. So how can the neighborhood of that vertex look? Well, we know that J is C3 free. So the blue edges cannot exist, which means that the neighborhood of the yellow vertex is an independent set inside J, not in the whole graph. Well, in fact, in the whole well, no, because we're only talking about J as a sub graph. Right. So the blue edges cannot exist, because otherwise we will get a C3 inside J. All right. So now let's look at the other vertices in S-Union T. The other, the second observation that you need is that any vertex other than the yellow vertex can have at most one neighbor in common with the yellow vertex. Because if you do have two neighbors in common, then you will get a C4. So now what happens if we have 3K vertices in the neighborhood of the yellow vertex? Well, at most 2K of them can be connected to some vertex in S-Union T, and you will get at least K of them, some K of them here that are only connected to the yellow vertex. And so now basically, instead of using a buffer inside H, we have just found a buffer inside J, and we can use the same strategy. We can jump all the tokens here, starting of course by the yellow token, and then jump them to where they need to go. So now combining those two, observing lemmas together, if you will, we get the following theorem. So if H is alpha sparse, and J is C3, C4 free, then the problem admits a kernel on this many vertices. And it's basically a simple application of the previous two lemmas. If we have more than this many vertices in H, it's a trivial yes instance. If J has a vertex of degree 3K or more, it's a trivial yes instance. And now you combine all of this together. We know that S-Union T is of size at most 2K. We know that the neighborhood of S-Union T is of size at most 2K times 3K, which is roughly 6K squared. And now we know that the rest of the graph has at most that many vertices. So basically, you sum up those numbers, and you get this bound. All right. So how does this theorem imply the result that I promised you to start with? So that token jumping and token sliding admit kernel with order K squared vertices, I mean, it also holds for bipartite C4 free graphs, obviously, because they are C3, C4 free. So how do you get the kernel? Well, we know that J cannot contain more than 6K squared minus 2K vertices. And we know from another theorem from another paper that C3 free graphs with K squared over log K vertices must have an independent set of size at least K. And now we know that if H contains more than this many vertices, then we will get the yes instance as well. Right? So it becomes an immediate consequence of the previous theorem, but the previous theorem is even more general than this corollary. So this corollary does not really use the full power of this theorem. All right. That's it. I think I'm going to finish on time. If you have questions, I will take them now. It was 55 minutes, right, for the talk. I did not go under the time. It's fine. We usually allow plus minus 10 minutes. That's all right. So I have a question about token sliding. Yes. So how crucial, what happens if one does not restrict the independent sets during the configuration to be not of the same size? Is that very critical for the difficulty or the easiness of the problem? Well, you have to be careful how you define that because in token sliding, tokens cannot leave the graph. That's correct. But the independent set sequence, all the independent sets have to be the same size, right? Well, if not, some token disappeared at some point. And I'm not sure how it disappeared. Right? Because you start with something of size K and you're going to something of size K, you cannot leave the graph unless you define it in some way. So you will remain of size K throughout. But you can become slightly larger than K. But where does the new token come from? So there is a third rule that I did not tell you about, which is called token addition and removal. Under that rule, we actually allow you to remove vertices and add vertices as long as you remain an independent set of size at least K. Does that answer your question? Yeah. Yeah. Yeah. Yeah. But in fact, it was shown that it was shown that so addition and removal is equivalent to token jumping. I see. It doesn't, it never makes sense to add more tokens to your graph if you don't need them. You're only making your life harder, intuitively speaking. So the other question that I had is, I mean, I heard, I, so is it possible to view this whole problem on an exponential size graph where every vertex corresponds to an independent set in the original graph? And then you have edges between two vertices. If there is an edge between two vertices of the independent set, and now you are doing a reachability question, is that a meaningful way to think about this? But that's exactly what we're doing. The way you define your adjacency, I think, so you mean you define, you make two independent sets adjacent if one can be reached from the other via a single slide or a single jump. Exactly. Yeah. One edge. Yeah. There is one pair, U and B, which is adjacent. But that's exactly what we're doing. Okay. Yeah. Right. I mean, if you, because we're looking at algorithms here, we kind of forget the structural picture behind it. But this algorithm is finding a path in this graph that you're describing. Yeah. Yeah. That's it. And what we're saying is you can do it in FBT time or not, depending on the problem we're talking about. Hi, Amir. Hi. How are you? Yeah, I'm good. So I had a question. So do problems remain equally hard if we bound the, if we have a restriction on the number of times, we can move the token to a particular vertex. The number of times you can move a token to a particular vertex. Like the number of times the tokens can be moved to a vertex. Well, that's definitely going to change the complexity in, at least intuitively speaking, right? Because now you're saying maybe it will, if you're bounding that by a constant, then you might be saying that I'm not allowing exponentially large sequences anymore. But in terms of exactly how the complexity changes, I don't have answers. I think it's a very nice question to pose. Even in terms of non-parameterized complexity, standard complexity, I think that that would be a very interesting question because, because it will definitely affect the behavior. I'm not sure exactly how yet. I don't know of any results that ask this particular question. Okay. So I had one more question in the W hardness result that you presented. So do you know what is the length of the, the length of the changes, actually the number of changes or flips that you make in your independence set? This is just, yes. Yes. We do. So here the number of changes is going to be very, it's, it's, it's basically going to be the shortest possible sequence. So it's, it's, it's, it's, it's basically going to be, so if you think about the simple construction, this one, it's basically literally going to be, these guys are going to move here. So each is going to cost me one slide. And then they're all going to, and now this guy is going to move here. And now I will pay one slide for each one here. Now this is the simplified version of it. Once you go to the complete version of it, you have some extra slides within the path, but you can also count those. Okay. So, but does this mean that, so does this mean that at a particular vertex, we are placing the token at most once? In this case, yes. Okay. In this case, yes. Okay. So this problem should be hard even if we bound the number of times tokens can be moved to a vertex, right? Yes. Okay. Yes. So, so here in this case, yes. Absolutely. Okay. Thanks. So Akanshya, I might, I have a remark about your question. So if a vertex, if a vertex cannot get a token twice, then it somehow seems to be selecting disjoint independent sets, a sequence of them, and that may have some bearing on coloring, just a top level. So actually for the W hardness case that Amir presented, it is exactly the case, right? So we are not allowed to move the token like twice on the same vertex. Yeah. So I didn't get your point of moving. So getting this disjoint independent sets actually. Because if you say, if you think of it from my, the way I thought about it, right, that you are actually trying to find a path in a large graph where every vertex corresponds to an independent set and you move from one independent set to another. So, but we can only move from one independent set to the other if the changes is like in case of token sliding, it's one probably. Yeah. Exactly. So it looks to me that you're asking for a collection of independent sets which are vertex disjoint. If the token, a sequence of independent sets which are vertex disjoint. Yeah. So if I may, I think, I think a conscious question would be more relevant in a place where we don't have a monotone sequence, meaning a sequence. So we need a version of the problem or some cases of the problem where a vertex has to be visited multiple times to find solutions. And that is known to be the case for some versions or some statements of the problem. And in fact, I can just also, this is also, this was the crucial difference between piece-based completeness and NP completeness of sliding versus jumping in bipartite graphs. So it was because we were able to show that no vertex will be visited more than once. And the other problem. So that's why it's definitely an interesting question to pose, but you have to be careful in what context you pose it. Great. I don't know if that kind of settles, answers your question. Yes, yes, it does. All right. Thanks. You're welcome. Any more questions? I guess not. Yeah, I don't think there are any more questions. I will just once again announce the parameterized algorithm 301 workshop, which is going to happen in December in the link has been posted once again in the chat. Some advanced topics in parameterized complexity will be discussed. Those interested can have a look and register for it. And yeah, if there are any more questions, please ask away. So anyone can register for the school? Yes, yes, anyone can. Yeah, it's free and it's online and yeah, it's open to everyone. Awesome. So I can share it with my students as well. Of course, of course, please do. Yeah, that would be good. And we assume some basic understanding of parameterized algorithms, but we have already shared a link on the page where students can go and go through some previous lectures in parameterized algorithms if they wish to just brace up or revise stuff. All right, so I guess, okay, I don't think there are any more questions. So maybe this is a good time to wrap up. So thank you once again, Professor Amitro for agreeing to give the talk. It was really nice to have you and it was really good to have something different than what we usually hear in every parent-based complexity talk, at least most of them. So and yeah, these are really interesting problems to think upon. And thank you to the audience for being with us. And that's it for today. We wrap up. See you all next week. Thank you. Bye. Thank you. Bye.",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 8.040000000000001,
      "text": " So, hello everyone. Welcome to the PC seminar. Today we have with us Professor Amir Mohad",
      "tokens": [
        50364,
        407,
        11,
        7751,
        1518,
        13,
        4027,
        281,
        264,
        6465,
        29235,
        13,
        2692,
        321,
        362,
        365,
        505,
        8419,
        2012,
        347,
        16123,
        345,
        50766
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3334081566852072,
      "compression_ratio": 1.55859375,
      "no_speech_prob": 0.05658555403351784
    },
    {
      "id": 1,
      "seek": 0,
      "start": 8.040000000000001,
      "end": 12.72,
      "text": " from American University of Beirut and he'll be talking on the Goethe and Parameterized",
      "tokens": [
        50766,
        490,
        2665,
        3535,
        295,
        879,
        347,
        325,
        293,
        415,
        603,
        312,
        1417,
        322,
        264,
        1037,
        302,
        675,
        293,
        34882,
        2398,
        1602,
        51000
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3334081566852072,
      "compression_ratio": 1.55859375,
      "no_speech_prob": 0.05658555403351784
    },
    {
      "id": 2,
      "seek": 0,
      "start": 12.72,
      "end": 17.76,
      "text": " Complexity of Token Sliding and Token Jumping. Thank you for joining us Professor. Over to",
      "tokens": [
        51000,
        41184,
        507,
        295,
        314,
        8406,
        6187,
        2819,
        293,
        314,
        8406,
        18697,
        278,
        13,
        1044,
        291,
        337,
        5549,
        505,
        8419,
        13,
        4886,
        281,
        51252
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3334081566852072,
      "compression_ratio": 1.55859375,
      "no_speech_prob": 0.05658555403351784
    },
    {
      "id": 3,
      "seek": 0,
      "start": 17.76,
      "end": 21.240000000000002,
      "text": " you now. Thank you, Prasipatay. Thank you for having",
      "tokens": [
        51252,
        291,
        586,
        13,
        1044,
        291,
        11,
        2114,
        296,
        647,
        267,
        320,
        13,
        1044,
        291,
        337,
        1419,
        51426
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3334081566852072,
      "compression_ratio": 1.55859375,
      "no_speech_prob": 0.05658555403351784
    },
    {
      "id": 4,
      "seek": 0,
      "start": 21.240000000000002,
      "end": 28.88,
      "text": " me. It's a real pleasure to be here. So, all right, let's jump right into it.",
      "tokens": [
        51426,
        385,
        13,
        467,
        311,
        257,
        957,
        6834,
        281,
        312,
        510,
        13,
        407,
        11,
        439,
        558,
        11,
        718,
        311,
        3012,
        558,
        666,
        309,
        13,
        51808
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3334081566852072,
      "compression_ratio": 1.55859375,
      "no_speech_prob": 0.05658555403351784
    },
    {
      "id": 5,
      "seek": 2888,
      "start": 28.88,
      "end": 35.44,
      "text": " So, since I did not really know the audience too well, I made the assumption that many",
      "tokens": [
        50364,
        407,
        11,
        1670,
        286,
        630,
        406,
        534,
        458,
        264,
        4034,
        886,
        731,
        11,
        286,
        1027,
        264,
        15302,
        300,
        867,
        50692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10890918307834202,
      "compression_ratio": 1.6238938053097345,
      "no_speech_prob": 0.0016052386490628123
    },
    {
      "id": 6,
      "seek": 2888,
      "start": 35.44,
      "end": 44.28,
      "text": " of you maybe have not seen this area of combinatorial reconfiguration problems. So, I decided what",
      "tokens": [
        50692,
        295,
        291,
        1310,
        362,
        406,
        1612,
        341,
        1859,
        295,
        2512,
        31927,
        831,
        9993,
        20646,
        8167,
        2740,
        13,
        407,
        11,
        286,
        3047,
        437,
        51134
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10890918307834202,
      "compression_ratio": 1.6238938053097345,
      "no_speech_prob": 0.0016052386490628123
    },
    {
      "id": 7,
      "seek": 2888,
      "start": 44.28,
      "end": 48.599999999999994,
      "text": " I'm going to do is I'm going to give a gentle introduction to the area just to show you how",
      "tokens": [
        51134,
        286,
        478,
        516,
        281,
        360,
        307,
        286,
        478,
        516,
        281,
        976,
        257,
        6424,
        9339,
        281,
        264,
        1859,
        445,
        281,
        855,
        291,
        577,
        51350
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10890918307834202,
      "compression_ratio": 1.6238938053097345,
      "no_speech_prob": 0.0016052386490628123
    },
    {
      "id": 8,
      "seek": 2888,
      "start": 48.599999999999994,
      "end": 56.0,
      "text": " many exciting problems and open problems are there. And then I will talk more about token",
      "tokens": [
        51350,
        867,
        4670,
        2740,
        293,
        1269,
        2740,
        366,
        456,
        13,
        400,
        550,
        286,
        486,
        751,
        544,
        466,
        14862,
        51720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10890918307834202,
      "compression_ratio": 1.6238938053097345,
      "no_speech_prob": 0.0016052386490628123
    },
    {
      "id": 9,
      "seek": 5600,
      "start": 56.0,
      "end": 60.480000000000004,
      "text": " jumping and token sliding specifically, what we know about them, what we knew about",
      "tokens": [
        50364,
        11233,
        293,
        14862,
        21169,
        4682,
        11,
        437,
        321,
        458,
        466,
        552,
        11,
        437,
        321,
        2586,
        466,
        50588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17545673646122575,
      "compression_ratio": 1.6971153846153846,
      "no_speech_prob": 0.0138876186683774
    },
    {
      "id": 10,
      "seek": 5600,
      "start": 60.480000000000004,
      "end": 67.48,
      "text": " them before we started working on this project, what we managed to discover and the tons of",
      "tokens": [
        50588,
        552,
        949,
        321,
        1409,
        1364,
        322,
        341,
        1716,
        11,
        437,
        321,
        6453,
        281,
        4411,
        293,
        264,
        9131,
        295,
        50938
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17545673646122575,
      "compression_ratio": 1.6971153846153846,
      "no_speech_prob": 0.0138876186683774
    },
    {
      "id": 11,
      "seek": 5600,
      "start": 67.48,
      "end": 74.96000000000001,
      "text": " questions that remain to be answered. Right? And it's a really, I mean, the questions are",
      "tokens": [
        50938,
        1651,
        300,
        6222,
        281,
        312,
        10103,
        13,
        1779,
        30,
        400,
        309,
        311,
        257,
        534,
        11,
        286,
        914,
        11,
        264,
        1651,
        366,
        51312
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17545673646122575,
      "compression_ratio": 1.6971153846153846,
      "no_speech_prob": 0.0138876186683774
    },
    {
      "id": 12,
      "seek": 5600,
      "start": 74.96000000000001,
      "end": 80.52,
      "text": " so nice to state, so easy to state and they are accessible really to researchers at any",
      "tokens": [
        51312,
        370,
        1481,
        281,
        1785,
        11,
        370,
        1858,
        281,
        1785,
        293,
        436,
        366,
        9515,
        534,
        281,
        10309,
        412,
        604,
        51590
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17545673646122575,
      "compression_ratio": 1.6971153846153846,
      "no_speech_prob": 0.0138876186683774
    },
    {
      "id": 13,
      "seek": 8052,
      "start": 80.52,
      "end": 87.6,
      "text": " level, which is one of the reasons why I enjoy working on these problems. So, hopefully,",
      "tokens": [
        50364,
        1496,
        11,
        597,
        307,
        472,
        295,
        264,
        4112,
        983,
        286,
        2103,
        1364,
        322,
        613,
        2740,
        13,
        407,
        11,
        4696,
        11,
        50718
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2532358872263055,
      "compression_ratio": 1.4958333333333333,
      "no_speech_prob": 0.05038381740450859
    },
    {
      "id": 14,
      "seek": 8052,
      "start": 87.6,
      "end": 93.24,
      "text": " you'll get to enjoy them too. So, before I start, I should point out that this is joint",
      "tokens": [
        50718,
        291,
        603,
        483,
        281,
        2103,
        552,
        886,
        13,
        407,
        11,
        949,
        286,
        722,
        11,
        286,
        820,
        935,
        484,
        300,
        341,
        307,
        7225,
        51000
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2532358872263055,
      "compression_ratio": 1.4958333333333333,
      "no_speech_prob": 0.05038381740450859
    },
    {
      "id": 15,
      "seek": 8052,
      "start": 93.24,
      "end": 100.28,
      "text": " work that started back in the combinatorial reconfiguration workshop almost two years",
      "tokens": [
        51000,
        589,
        300,
        1409,
        646,
        294,
        264,
        2512,
        31927,
        831,
        9993,
        20646,
        8167,
        13541,
        1920,
        732,
        924,
        51352
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2532358872263055,
      "compression_ratio": 1.4958333333333333,
      "no_speech_prob": 0.05038381740450859
    },
    {
      "id": 16,
      "seek": 8052,
      "start": 100.28,
      "end": 107.64,
      "text": " ago. And it's joint work with Valentin Barche, Nicolas Busquet, Clement Dallard and Karl Lohmer,",
      "tokens": [
        51352,
        2057,
        13,
        400,
        309,
        311,
        7225,
        589,
        365,
        17961,
        259,
        4156,
        1876,
        11,
        38268,
        8006,
        19343,
        11,
        49517,
        413,
        336,
        515,
        293,
        20405,
        441,
        1445,
        936,
        11,
        51720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2532358872263055,
      "compression_ratio": 1.4958333333333333,
      "no_speech_prob": 0.05038381740450859
    },
    {
      "id": 17,
      "seek": 10764,
      "start": 107.64,
      "end": 116.64,
      "text": " who is my master's student. All right. So, the outline of the talk, it's going to be",
      "tokens": [
        50364,
        567,
        307,
        452,
        4505,
        311,
        3107,
        13,
        1057,
        558,
        13,
        407,
        11,
        264,
        16387,
        295,
        264,
        751,
        11,
        309,
        311,
        516,
        281,
        312,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.147743821144104,
      "compression_ratio": 1.5446808510638297,
      "no_speech_prob": 0.021780509501695633
    },
    {
      "id": 18,
      "seek": 10764,
      "start": 116.64,
      "end": 122.76,
      "text": " in four sections. I will give a gentle introduction to combinatorial reconfiguration because I",
      "tokens": [
        50814,
        294,
        1451,
        10863,
        13,
        286,
        486,
        976,
        257,
        6424,
        9339,
        281,
        2512,
        31927,
        831,
        9993,
        20646,
        8167,
        570,
        286,
        51120
      ],
      "temperature": 0.0,
      "avg_logprob": -0.147743821144104,
      "compression_ratio": 1.5446808510638297,
      "no_speech_prob": 0.021780509501695633
    },
    {
      "id": 19,
      "seek": 10764,
      "start": 122.76,
      "end": 131.12,
      "text": " know many of you might not have seen such problems. Then I will talk about token jumping",
      "tokens": [
        51120,
        458,
        867,
        295,
        291,
        1062,
        406,
        362,
        1612,
        1270,
        2740,
        13,
        1396,
        286,
        486,
        751,
        466,
        14862,
        11233,
        51538
      ],
      "temperature": 0.0,
      "avg_logprob": -0.147743821144104,
      "compression_ratio": 1.5446808510638297,
      "no_speech_prob": 0.021780509501695633
    },
    {
      "id": 20,
      "seek": 10764,
      "start": 131.12,
      "end": 136.8,
      "text": " and token sliding, what we know about them in terms of classical complexity or one-dimensional",
      "tokens": [
        51538,
        293,
        14862,
        21169,
        11,
        437,
        321,
        458,
        466,
        552,
        294,
        2115,
        295,
        13735,
        14024,
        420,
        472,
        12,
        18759,
        51822
      ],
      "temperature": 0.0,
      "avg_logprob": -0.147743821144104,
      "compression_ratio": 1.5446808510638297,
      "no_speech_prob": 0.021780509501695633
    },
    {
      "id": 21,
      "seek": 13680,
      "start": 136.8,
      "end": 142.64000000000001,
      "text": " complexity. Then I'll talk about the parametreous complexity of these two problems and what",
      "tokens": [
        50364,
        14024,
        13,
        1396,
        286,
        603,
        751,
        466,
        264,
        6220,
        302,
        265,
        563,
        14024,
        295,
        613,
        732,
        2740,
        293,
        437,
        50656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1370749208662245,
      "compression_ratio": 1.734375,
      "no_speech_prob": 0.01515507698059082
    },
    {
      "id": 22,
      "seek": 13680,
      "start": 142.64000000000001,
      "end": 149.36,
      "text": " we know as of today, as we speak, and what are the problems that remain to be solved.",
      "tokens": [
        50656,
        321,
        458,
        382,
        295,
        965,
        11,
        382,
        321,
        1710,
        11,
        293,
        437,
        366,
        264,
        2740,
        300,
        6222,
        281,
        312,
        13041,
        13,
        50992
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1370749208662245,
      "compression_ratio": 1.734375,
      "no_speech_prob": 0.01515507698059082
    },
    {
      "id": 23,
      "seek": 13680,
      "start": 149.36,
      "end": 153.44,
      "text": " And then the last part of the lecture is where I will put some of the technical stuff to show",
      "tokens": [
        50992,
        400,
        550,
        264,
        1036,
        644,
        295,
        264,
        7991,
        307,
        689,
        286,
        486,
        829,
        512,
        295,
        264,
        6191,
        1507,
        281,
        855,
        51196
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1370749208662245,
      "compression_ratio": 1.734375,
      "no_speech_prob": 0.01515507698059082
    },
    {
      "id": 24,
      "seek": 13680,
      "start": 153.44,
      "end": 159.16000000000003,
      "text": " you, to give you an idea about how we prove things when we deal with such problems and",
      "tokens": [
        51196,
        291,
        11,
        281,
        976,
        291,
        364,
        1558,
        466,
        577,
        321,
        7081,
        721,
        562,
        321,
        2028,
        365,
        1270,
        2740,
        293,
        51482
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1370749208662245,
      "compression_ratio": 1.734375,
      "no_speech_prob": 0.01515507698059082
    },
    {
      "id": 25,
      "seek": 13680,
      "start": 159.16000000000003,
      "end": 164.56,
      "text": " where are the difficulties and what kind of techniques have been developed. So, I try",
      "tokens": [
        51482,
        689,
        366,
        264,
        14399,
        293,
        437,
        733,
        295,
        7512,
        362,
        668,
        4743,
        13,
        407,
        11,
        286,
        853,
        51752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1370749208662245,
      "compression_ratio": 1.734375,
      "no_speech_prob": 0.01515507698059082
    },
    {
      "id": 26,
      "seek": 16456,
      "start": 164.64000000000001,
      "end": 170.8,
      "text": " to keep the technical part as light as I could so that really, I mean, I can focus on the",
      "tokens": [
        50368,
        281,
        1066,
        264,
        6191,
        644,
        382,
        1442,
        382,
        286,
        727,
        370,
        300,
        534,
        11,
        286,
        914,
        11,
        286,
        393,
        1879,
        322,
        264,
        50676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15545495059512077,
      "compression_ratio": 1.702290076335878,
      "no_speech_prob": 0.009567483328282833
    },
    {
      "id": 27,
      "seek": 16456,
      "start": 170.8,
      "end": 177.24,
      "text": " big picture and the questions to be asked and answered. So, if you have any questions",
      "tokens": [
        50676,
        955,
        3036,
        293,
        264,
        1651,
        281,
        312,
        2351,
        293,
        10103,
        13,
        407,
        11,
        498,
        291,
        362,
        604,
        1651,
        50998
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15545495059512077,
      "compression_ratio": 1.702290076335878,
      "no_speech_prob": 0.009567483328282833
    },
    {
      "id": 28,
      "seek": 16456,
      "start": 177.24,
      "end": 184.64000000000001,
      "text": " along the way, please feel free to interrupt me either in the chat or by unmuting yourselves.",
      "tokens": [
        50998,
        2051,
        264,
        636,
        11,
        1767,
        841,
        1737,
        281,
        12729,
        385,
        2139,
        294,
        264,
        5081,
        420,
        538,
        19334,
        10861,
        14791,
        13,
        51368
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15545495059512077,
      "compression_ratio": 1.702290076335878,
      "no_speech_prob": 0.009567483328282833
    },
    {
      "id": 29,
      "seek": 16456,
      "start": 184.64000000000001,
      "end": 189.92000000000002,
      "text": " So, don't worry about leaving the questions till the end. You can interrupt me whenever",
      "tokens": [
        51368,
        407,
        11,
        500,
        380,
        3292,
        466,
        5012,
        264,
        1651,
        4288,
        264,
        917,
        13,
        509,
        393,
        12729,
        385,
        5699,
        51632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15545495059512077,
      "compression_ratio": 1.702290076335878,
      "no_speech_prob": 0.009567483328282833
    },
    {
      "id": 30,
      "seek": 16456,
      "start": 189.92000000000002,
      "end": 194.36,
      "text": " you feel, whenever I say something that doesn't make sense. Hopefully, that won't happen",
      "tokens": [
        51632,
        291,
        841,
        11,
        5699,
        286,
        584,
        746,
        300,
        1177,
        380,
        652,
        2020,
        13,
        10429,
        11,
        300,
        1582,
        380,
        1051,
        51854
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15545495059512077,
      "compression_ratio": 1.702290076335878,
      "no_speech_prob": 0.009567483328282833
    },
    {
      "id": 31,
      "seek": 19436,
      "start": 194.36,
      "end": 201.56,
      "text": " too often. All right, so what is combinatorial reconfiguration? So, the best way, I think,",
      "tokens": [
        50364,
        886,
        2049,
        13,
        1057,
        558,
        11,
        370,
        437,
        307,
        2512,
        31927,
        831,
        9993,
        20646,
        8167,
        30,
        407,
        11,
        264,
        1151,
        636,
        11,
        286,
        519,
        11,
        50724
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16181349754333496,
      "compression_ratio": 1.5633187772925765,
      "no_speech_prob": 0.0014748282264918089
    },
    {
      "id": 32,
      "seek": 19436,
      "start": 201.56,
      "end": 208.52,
      "text": " to introduce is with a familiar example, which is one player games and the most common one",
      "tokens": [
        50724,
        281,
        5366,
        307,
        365,
        257,
        4963,
        1365,
        11,
        597,
        307,
        472,
        4256,
        2813,
        293,
        264,
        881,
        2689,
        472,
        51072
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16181349754333496,
      "compression_ratio": 1.5633187772925765,
      "no_speech_prob": 0.0014748282264918089
    },
    {
      "id": 33,
      "seek": 19436,
      "start": 208.52,
      "end": 213.56,
      "text": " that we use is the 15 puzzle game. So, for those of you who don't know the 15 puzzle",
      "tokens": [
        51072,
        300,
        321,
        764,
        307,
        264,
        2119,
        12805,
        1216,
        13,
        407,
        11,
        337,
        729,
        295,
        291,
        567,
        500,
        380,
        458,
        264,
        2119,
        12805,
        51324
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16181349754333496,
      "compression_ratio": 1.5633187772925765,
      "no_speech_prob": 0.0014748282264918089
    },
    {
      "id": 34,
      "seek": 19436,
      "start": 213.56,
      "end": 221.0,
      "text": " game, so you're given like a four by four grid and you have one empty square and basically,",
      "tokens": [
        51324,
        1216,
        11,
        370,
        291,
        434,
        2212,
        411,
        257,
        1451,
        538,
        1451,
        10748,
        293,
        291,
        362,
        472,
        6707,
        3732,
        293,
        1936,
        11,
        51696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16181349754333496,
      "compression_ratio": 1.5633187772925765,
      "no_speech_prob": 0.0014748282264918089
    },
    {
      "id": 35,
      "seek": 22100,
      "start": 221.08,
      "end": 226.36,
      "text": " you have all the remaining 15 squares are numbered from 1 to 15 and they come in some",
      "tokens": [
        50368,
        291,
        362,
        439,
        264,
        8877,
        2119,
        19368,
        366,
        40936,
        490,
        502,
        281,
        2119,
        293,
        436,
        808,
        294,
        512,
        50632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11664690142092497,
      "compression_ratio": 1.736842105263158,
      "no_speech_prob": 0.0012436857214197516
    },
    {
      "id": 36,
      "seek": 22100,
      "start": 226.36,
      "end": 232.36,
      "text": " ordering and your job is to basically move the squares around so that all the numbers become",
      "tokens": [
        50632,
        21739,
        293,
        428,
        1691,
        307,
        281,
        1936,
        1286,
        264,
        19368,
        926,
        370,
        300,
        439,
        264,
        3547,
        1813,
        50932
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11664690142092497,
      "compression_ratio": 1.736842105263158,
      "no_speech_prob": 0.0012436857214197516
    },
    {
      "id": 37,
      "seek": 22100,
      "start": 232.36,
      "end": 238.6,
      "text": " ordered. So, it's a byro, so they have to be ordered this way. So, if you notice in this",
      "tokens": [
        50932,
        8866,
        13,
        407,
        11,
        309,
        311,
        257,
        538,
        340,
        11,
        370,
        436,
        362,
        281,
        312,
        8866,
        341,
        636,
        13,
        407,
        11,
        498,
        291,
        3449,
        294,
        341,
        51244
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11664690142092497,
      "compression_ratio": 1.736842105263158,
      "no_speech_prob": 0.0012436857214197516
    },
    {
      "id": 38,
      "seek": 22100,
      "start": 238.6,
      "end": 245.08,
      "text": " figure, the only problem is that 14 and 15 are reversed, but the only moves that you're allowed",
      "tokens": [
        51244,
        2573,
        11,
        264,
        787,
        1154,
        307,
        300,
        3499,
        293,
        2119,
        366,
        30563,
        11,
        457,
        264,
        787,
        6067,
        300,
        291,
        434,
        4350,
        51568
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11664690142092497,
      "compression_ratio": 1.736842105263158,
      "no_speech_prob": 0.0012436857214197516
    },
    {
      "id": 39,
      "seek": 24508,
      "start": 245.08,
      "end": 253.16000000000003,
      "text": " to do is to basically move a number into the empty square and basically, you have to do a",
      "tokens": [
        50364,
        281,
        360,
        307,
        281,
        1936,
        1286,
        257,
        1230,
        666,
        264,
        6707,
        3732,
        293,
        1936,
        11,
        291,
        362,
        281,
        360,
        257,
        50768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0902262913812067,
      "compression_ratio": 1.6816143497757847,
      "no_speech_prob": 0.0013959624338895082
    },
    {
      "id": 40,
      "seek": 24508,
      "start": 253.16000000000003,
      "end": 259.0,
      "text": " sequence of moves so that you get all of the numbers in order. And for those of you who know",
      "tokens": [
        50768,
        8310,
        295,
        6067,
        370,
        300,
        291,
        483,
        439,
        295,
        264,
        3547,
        294,
        1668,
        13,
        400,
        337,
        729,
        295,
        291,
        567,
        458,
        51060
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0902262913812067,
      "compression_ratio": 1.6816143497757847,
      "no_speech_prob": 0.0013959624338895082
    },
    {
      "id": 41,
      "seek": 24508,
      "start": 259.0,
      "end": 267.0,
      "text": " this game, this example that I have on the slide is actually unsolvable. There is no way you can",
      "tokens": [
        51060,
        341,
        1216,
        11,
        341,
        1365,
        300,
        286,
        362,
        322,
        264,
        4137,
        307,
        767,
        2693,
        401,
        17915,
        13,
        821,
        307,
        572,
        636,
        291,
        393,
        51460
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0902262913812067,
      "compression_ratio": 1.6816143497757847,
      "no_speech_prob": 0.0013959624338895082
    },
    {
      "id": 42,
      "seek": 24508,
      "start": 267.0,
      "end": 274.2,
      "text": " flip the order of 14 and 15 in this puzzle. And I have a link here if you want to actually play",
      "tokens": [
        51460,
        7929,
        264,
        1668,
        295,
        3499,
        293,
        2119,
        294,
        341,
        12805,
        13,
        400,
        286,
        362,
        257,
        2113,
        510,
        498,
        291,
        528,
        281,
        767,
        862,
        51820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0902262913812067,
      "compression_ratio": 1.6816143497757847,
      "no_speech_prob": 0.0013959624338895082
    },
    {
      "id": 43,
      "seek": 27420,
      "start": 274.2,
      "end": 281.71999999999997,
      "text": " the puzzle online, which is pretty fun. So, why do I do I start my talk by talking about 15 puzzle?",
      "tokens": [
        50364,
        264,
        12805,
        2950,
        11,
        597,
        307,
        1238,
        1019,
        13,
        407,
        11,
        983,
        360,
        286,
        360,
        286,
        722,
        452,
        751,
        538,
        1417,
        466,
        2119,
        12805,
        30,
        50740
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08375087011428106,
      "compression_ratio": 1.737991266375546,
      "no_speech_prob": 0.0009046336053870618
    },
    {
      "id": 44,
      "seek": 27420,
      "start": 281.71999999999997,
      "end": 288.68,
      "text": " It's because it's really, I mean, the way you solve the 15 puzzle tells you a lot about the area",
      "tokens": [
        50740,
        467,
        311,
        570,
        309,
        311,
        534,
        11,
        286,
        914,
        11,
        264,
        636,
        291,
        5039,
        264,
        2119,
        12805,
        5112,
        291,
        257,
        688,
        466,
        264,
        1859,
        51088
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08375087011428106,
      "compression_ratio": 1.737991266375546,
      "no_speech_prob": 0.0009046336053870618
    },
    {
      "id": 45,
      "seek": 27420,
      "start": 288.68,
      "end": 296.12,
      "text": " of combinatorial reconfiguration. So, the standard way we would think about the 15 puzzle is by looking",
      "tokens": [
        51088,
        295,
        2512,
        31927,
        831,
        9993,
        20646,
        8167,
        13,
        407,
        11,
        264,
        3832,
        636,
        321,
        576,
        519,
        466,
        264,
        2119,
        12805,
        307,
        538,
        1237,
        51460
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08375087011428106,
      "compression_ratio": 1.737991266375546,
      "no_speech_prob": 0.0009046336053870618
    },
    {
      "id": 46,
      "seek": 27420,
      "start": 296.12,
      "end": 302.12,
      "text": " at the state space or what we call the reconfiguration graph of the 15 puzzle. So, what does that",
      "tokens": [
        51460,
        412,
        264,
        1785,
        1901,
        420,
        437,
        321,
        818,
        264,
        9993,
        20646,
        8167,
        4295,
        295,
        264,
        2119,
        12805,
        13,
        407,
        11,
        437,
        775,
        300,
        51760
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08375087011428106,
      "compression_ratio": 1.737991266375546,
      "no_speech_prob": 0.0009046336053870618
    },
    {
      "id": 47,
      "seek": 30212,
      "start": 302.2,
      "end": 310.04,
      "text": " graph consist of? Well, we have one vertex or one node in this graph for each possible configuration",
      "tokens": [
        50368,
        4295,
        4603,
        295,
        30,
        1042,
        11,
        321,
        362,
        472,
        28162,
        420,
        472,
        9984,
        294,
        341,
        4295,
        337,
        1184,
        1944,
        11694,
        50760
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06892524676376514,
      "compression_ratio": 1.6651982378854626,
      "no_speech_prob": 0.0005151998484507203
    },
    {
      "id": 48,
      "seek": 30212,
      "start": 310.04,
      "end": 316.12,
      "text": " of the puzzle. So, basically, each possible configuration, so it would be a possible permutation",
      "tokens": [
        50760,
        295,
        264,
        12805,
        13,
        407,
        11,
        1936,
        11,
        1184,
        1944,
        11694,
        11,
        370,
        309,
        576,
        312,
        257,
        1944,
        4784,
        11380,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06892524676376514,
      "compression_ratio": 1.6651982378854626,
      "no_speech_prob": 0.0005151998484507203
    },
    {
      "id": 49,
      "seek": 30212,
      "start": 316.12,
      "end": 322.12,
      "text": " of the 15 numbers in addition to where you're going to put the empty square. Each one of those",
      "tokens": [
        51064,
        295,
        264,
        2119,
        3547,
        294,
        4500,
        281,
        689,
        291,
        434,
        516,
        281,
        829,
        264,
        6707,
        3732,
        13,
        6947,
        472,
        295,
        729,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06892524676376514,
      "compression_ratio": 1.6651982378854626,
      "no_speech_prob": 0.0005151998484507203
    },
    {
      "id": 50,
      "seek": 30212,
      "start": 322.12,
      "end": 328.68,
      "text": " will be a vertex in the graph. And now we connect two vertices in that graph whenever",
      "tokens": [
        51364,
        486,
        312,
        257,
        28162,
        294,
        264,
        4295,
        13,
        400,
        586,
        321,
        1745,
        732,
        32053,
        294,
        300,
        4295,
        5699,
        51692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06892524676376514,
      "compression_ratio": 1.6651982378854626,
      "no_speech_prob": 0.0005151998484507203
    },
    {
      "id": 51,
      "seek": 32868,
      "start": 329.32,
      "end": 334.84000000000003,
      "text": " one can be reached from the other by a single move. And what do we mean here by a single move",
      "tokens": [
        50396,
        472,
        393,
        312,
        6488,
        490,
        264,
        661,
        538,
        257,
        2167,
        1286,
        13,
        400,
        437,
        360,
        321,
        914,
        510,
        538,
        257,
        2167,
        1286,
        50672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.04808083733359536,
      "compression_ratio": 1.6872037914691944,
      "no_speech_prob": 0.0004961416125297546
    },
    {
      "id": 52,
      "seek": 32868,
      "start": 334.84000000000003,
      "end": 341.40000000000003,
      "text": " where it's basically just moving a number into the empty square? So, if you look at the top",
      "tokens": [
        50672,
        689,
        309,
        311,
        1936,
        445,
        2684,
        257,
        1230,
        666,
        264,
        6707,
        3732,
        30,
        407,
        11,
        498,
        291,
        574,
        412,
        264,
        1192,
        51000
      ],
      "temperature": 0.0,
      "avg_logprob": -0.04808083733359536,
      "compression_ratio": 1.6872037914691944,
      "no_speech_prob": 0.0004961416125297546
    },
    {
      "id": 53,
      "seek": 32868,
      "start": 341.40000000000003,
      "end": 347.0,
      "text": " node here in this graph, there are four possibilities that you can do in one move,",
      "tokens": [
        51000,
        9984,
        510,
        294,
        341,
        4295,
        11,
        456,
        366,
        1451,
        12178,
        300,
        291,
        393,
        360,
        294,
        472,
        1286,
        11,
        51280
      ],
      "temperature": 0.0,
      "avg_logprob": -0.04808083733359536,
      "compression_ratio": 1.6872037914691944,
      "no_speech_prob": 0.0004961416125297546
    },
    {
      "id": 54,
      "seek": 32868,
      "start": 347.0,
      "end": 351.8,
      "text": " which we call a reconfiguration step, which is you can move nine into the empty square,",
      "tokens": [
        51280,
        597,
        321,
        818,
        257,
        9993,
        20646,
        8167,
        1823,
        11,
        597,
        307,
        291,
        393,
        1286,
        4949,
        666,
        264,
        6707,
        3732,
        11,
        51520
      ],
      "temperature": 0.0,
      "avg_logprob": -0.04808083733359536,
      "compression_ratio": 1.6872037914691944,
      "no_speech_prob": 0.0004961416125297546
    },
    {
      "id": 55,
      "seek": 35180,
      "start": 351.8,
      "end": 358.92,
      "text": " you can move three into the empty square, 12 or 15. And that gives us basically four neighbors",
      "tokens": [
        50364,
        291,
        393,
        1286,
        1045,
        666,
        264,
        6707,
        3732,
        11,
        2272,
        420,
        2119,
        13,
        400,
        300,
        2709,
        505,
        1936,
        1451,
        12512,
        50720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08996468004973038,
      "compression_ratio": 1.6666666666666667,
      "no_speech_prob": 0.00022771368094254285
    },
    {
      "id": 56,
      "seek": 35180,
      "start": 358.92,
      "end": 366.04,
      "text": " of that vertex in the graph. Okay, and we call this whole graph the reconfiguration graph or the",
      "tokens": [
        50720,
        295,
        300,
        28162,
        294,
        264,
        4295,
        13,
        1033,
        11,
        293,
        321,
        818,
        341,
        1379,
        4295,
        264,
        9993,
        20646,
        8167,
        4295,
        420,
        264,
        51076
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08996468004973038,
      "compression_ratio": 1.6666666666666667,
      "no_speech_prob": 0.00022771368094254285
    },
    {
      "id": 57,
      "seek": 35180,
      "start": 366.04,
      "end": 373.0,
      "text": " state space if you're more comfortable thinking about states, the states of the game. So, now,",
      "tokens": [
        51076,
        1785,
        1901,
        498,
        291,
        434,
        544,
        4619,
        1953,
        466,
        4368,
        11,
        264,
        4368,
        295,
        264,
        1216,
        13,
        407,
        11,
        586,
        11,
        51424
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08996468004973038,
      "compression_ratio": 1.6666666666666667,
      "no_speech_prob": 0.00022771368094254285
    },
    {
      "id": 58,
      "seek": 35180,
      "start": 373.0,
      "end": 378.6,
      "text": " given this graph, the reconfiguration graph, there are tons of very interesting questions that you",
      "tokens": [
        51424,
        2212,
        341,
        4295,
        11,
        264,
        9993,
        20646,
        8167,
        4295,
        11,
        456,
        366,
        9131,
        295,
        588,
        1880,
        1651,
        300,
        291,
        51704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08996468004973038,
      "compression_ratio": 1.6666666666666667,
      "no_speech_prob": 0.00022771368094254285
    },
    {
      "id": 59,
      "seek": 37860,
      "start": 378.6,
      "end": 384.92,
      "text": " can ask about it. There are structural questions and there are algorithmic questions. And these are",
      "tokens": [
        50364,
        393,
        1029,
        466,
        309,
        13,
        821,
        366,
        15067,
        1651,
        293,
        456,
        366,
        9284,
        299,
        1651,
        13,
        400,
        613,
        366,
        50680
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09995654571888059,
      "compression_ratio": 1.7339449541284404,
      "no_speech_prob": 0.00017164082964882255
    },
    {
      "id": 60,
      "seek": 37860,
      "start": 384.92,
      "end": 391.24,
      "text": " typically the types of questions that we're interested in in this area of combinatorially",
      "tokens": [
        50680,
        5850,
        264,
        3467,
        295,
        1651,
        300,
        321,
        434,
        3102,
        294,
        294,
        341,
        1859,
        295,
        2512,
        31927,
        2270,
        50996
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09995654571888059,
      "compression_ratio": 1.7339449541284404,
      "no_speech_prob": 0.00017164082964882255
    },
    {
      "id": 61,
      "seek": 37860,
      "start": 391.24,
      "end": 398.36,
      "text": " configuration. So, a couple of examples of structural questions would be, well, the simplest one would",
      "tokens": [
        50996,
        11694,
        13,
        407,
        11,
        257,
        1916,
        295,
        5110,
        295,
        15067,
        1651,
        576,
        312,
        11,
        731,
        11,
        264,
        22811,
        472,
        576,
        51352
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09995654571888059,
      "compression_ratio": 1.7339449541284404,
      "no_speech_prob": 0.00017164082964882255
    },
    {
      "id": 62,
      "seek": 37860,
      "start": 398.36,
      "end": 403.64000000000004,
      "text": " be how big is this reconfiguration graph, right? How many vertices or how many edges?",
      "tokens": [
        51352,
        312,
        577,
        955,
        307,
        341,
        9993,
        20646,
        8167,
        4295,
        11,
        558,
        30,
        1012,
        867,
        32053,
        420,
        577,
        867,
        8819,
        30,
        51616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09995654571888059,
      "compression_ratio": 1.7339449541284404,
      "no_speech_prob": 0.00017164082964882255
    },
    {
      "id": 63,
      "seek": 40364,
      "start": 404.59999999999997,
      "end": 410.2,
      "text": " And that's usually not a very hard question to answer in terms of upper and lower bounds.",
      "tokens": [
        50412,
        400,
        300,
        311,
        2673,
        406,
        257,
        588,
        1152,
        1168,
        281,
        1867,
        294,
        2115,
        295,
        6597,
        293,
        3126,
        29905,
        13,
        50692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1662090908397328,
      "compression_ratio": 1.5627705627705628,
      "no_speech_prob": 0.0003028052451554686
    },
    {
      "id": 64,
      "seek": 40364,
      "start": 411.32,
      "end": 416.76,
      "text": " More interestingly, you could ask, is this reconfiguration graph connected, right? Or",
      "tokens": [
        50748,
        5048,
        25873,
        11,
        291,
        727,
        1029,
        11,
        307,
        341,
        9993,
        20646,
        8167,
        4295,
        4582,
        11,
        558,
        30,
        1610,
        51020
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1662090908397328,
      "compression_ratio": 1.5627705627705628,
      "no_speech_prob": 0.0003028052451554686
    },
    {
      "id": 65,
      "seek": 40364,
      "start": 416.76,
      "end": 423.64,
      "text": " is, can I reach any state starting from any other state by a sequence of legal moves? And as I",
      "tokens": [
        51020,
        307,
        11,
        393,
        286,
        2524,
        604,
        1785,
        2891,
        490,
        604,
        661,
        1785,
        538,
        257,
        8310,
        295,
        5089,
        6067,
        30,
        400,
        382,
        286,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1662090908397328,
      "compression_ratio": 1.5627705627705628,
      "no_speech_prob": 0.0003028052451554686
    },
    {
      "id": 66,
      "seek": 40364,
      "start": 424.44,
      "end": 429.71999999999997,
      "text": " told you before, for the 15 puzzle, the reconfiguration graph is definitely not connected,",
      "tokens": [
        51404,
        1907,
        291,
        949,
        11,
        337,
        264,
        2119,
        12805,
        11,
        264,
        9993,
        20646,
        8167,
        4295,
        307,
        2138,
        406,
        4582,
        11,
        51668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1662090908397328,
      "compression_ratio": 1.5627705627705628,
      "no_speech_prob": 0.0003028052451554686
    },
    {
      "id": 67,
      "seek": 42972,
      "start": 429.8,
      "end": 435.16,
      "text": " because there was no way to reverse 14 and 15 in the previous example that I showed you,",
      "tokens": [
        50368,
        570,
        456,
        390,
        572,
        636,
        281,
        9943,
        3499,
        293,
        2119,
        294,
        264,
        3894,
        1365,
        300,
        286,
        4712,
        291,
        11,
        50636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07617773802384087,
      "compression_ratio": 1.7472924187725631,
      "no_speech_prob": 0.0002626748173497617
    },
    {
      "id": 68,
      "seek": 42972,
      "start": 435.16,
      "end": 440.44000000000005,
      "text": " and you can easily prove that, by the way. So, when it's not connected, another question would be,",
      "tokens": [
        50636,
        293,
        291,
        393,
        3612,
        7081,
        300,
        11,
        538,
        264,
        636,
        13,
        407,
        11,
        562,
        309,
        311,
        406,
        4582,
        11,
        1071,
        1168,
        576,
        312,
        11,
        50900
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07617773802384087,
      "compression_ratio": 1.7472924187725631,
      "no_speech_prob": 0.0002626748173497617
    },
    {
      "id": 69,
      "seek": 42972,
      "start": 440.44000000000005,
      "end": 448.6,
      "text": " how many components does it have? Is there some sort of nice structure to the components of this",
      "tokens": [
        50900,
        577,
        867,
        6677,
        775,
        309,
        362,
        30,
        1119,
        456,
        512,
        1333,
        295,
        1481,
        3877,
        281,
        264,
        6677,
        295,
        341,
        51308
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07617773802384087,
      "compression_ratio": 1.7472924187725631,
      "no_speech_prob": 0.0002626748173497617
    },
    {
      "id": 70,
      "seek": 42972,
      "start": 448.6,
      "end": 455.0,
      "text": " graph? And then another question would be, what is the diameter of this reconfiguration graph or",
      "tokens": [
        51308,
        4295,
        30,
        400,
        550,
        1071,
        1168,
        576,
        312,
        11,
        437,
        307,
        264,
        14196,
        295,
        341,
        9993,
        20646,
        8167,
        4295,
        420,
        51628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07617773802384087,
      "compression_ratio": 1.7472924187725631,
      "no_speech_prob": 0.0002626748173497617
    },
    {
      "id": 71,
      "seek": 42972,
      "start": 455.0,
      "end": 459.56,
      "text": " of each one of its components? And that's usually a very important question to ask when you're dealing",
      "tokens": [
        51628,
        295,
        1184,
        472,
        295,
        1080,
        6677,
        30,
        400,
        300,
        311,
        2673,
        257,
        588,
        1021,
        1168,
        281,
        1029,
        562,
        291,
        434,
        6260,
        51856
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07617773802384087,
      "compression_ratio": 1.7472924187725631,
      "no_speech_prob": 0.0002626748173497617
    },
    {
      "id": 72,
      "seek": 45956,
      "start": 459.56,
      "end": 466.92,
      "text": " with one-player games, because this could tell you what would be the worst possible shortest path",
      "tokens": [
        50364,
        365,
        472,
        12,
        19125,
        2813,
        11,
        570,
        341,
        727,
        980,
        291,
        437,
        576,
        312,
        264,
        5855,
        1944,
        31875,
        3100,
        50732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07615812526029699,
      "compression_ratio": 1.654867256637168,
      "no_speech_prob": 0.0009779639076441526
    },
    {
      "id": 73,
      "seek": 45956,
      "start": 466.92,
      "end": 472.6,
      "text": " to reach a target configuration or to solve your game, to win your game, for example. And in the",
      "tokens": [
        50732,
        281,
        2524,
        257,
        3779,
        11694,
        420,
        281,
        5039,
        428,
        1216,
        11,
        281,
        1942,
        428,
        1216,
        11,
        337,
        1365,
        13,
        400,
        294,
        264,
        51016
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07615812526029699,
      "compression_ratio": 1.654867256637168,
      "no_speech_prob": 0.0009779639076441526
    },
    {
      "id": 74,
      "seek": 45956,
      "start": 472.6,
      "end": 478.28,
      "text": " literature, this is sometimes known as God's number, which would be the diameter of the",
      "tokens": [
        51016,
        10394,
        11,
        341,
        307,
        2171,
        2570,
        382,
        1265,
        311,
        1230,
        11,
        597,
        576,
        312,
        264,
        14196,
        295,
        264,
        51300
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07615812526029699,
      "compression_ratio": 1.654867256637168,
      "no_speech_prob": 0.0009779639076441526
    },
    {
      "id": 75,
      "seek": 45956,
      "start": 478.28,
      "end": 485.8,
      "text": " reconfiguration graph. And these are all very interesting structural questions to ask about",
      "tokens": [
        51300,
        9993,
        20646,
        8167,
        4295,
        13,
        400,
        613,
        366,
        439,
        588,
        1880,
        15067,
        1651,
        281,
        1029,
        466,
        51676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07615812526029699,
      "compression_ratio": 1.654867256637168,
      "no_speech_prob": 0.0009779639076441526
    },
    {
      "id": 76,
      "seek": 48580,
      "start": 485.8,
      "end": 491.72,
      "text": " this reconfiguration graph. Now, on the algorithmic side or the computational side,",
      "tokens": [
        50364,
        341,
        9993,
        20646,
        8167,
        4295,
        13,
        823,
        11,
        322,
        264,
        9284,
        299,
        1252,
        420,
        264,
        28270,
        1252,
        11,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06728590618480336,
      "compression_ratio": 1.8300395256916997,
      "no_speech_prob": 0.001083924900740385
    },
    {
      "id": 77,
      "seek": 48580,
      "start": 491.72,
      "end": 497.72,
      "text": " there's the obvious question of, if I'm given a starting state and some ending state or target",
      "tokens": [
        50660,
        456,
        311,
        264,
        6322,
        1168,
        295,
        11,
        498,
        286,
        478,
        2212,
        257,
        2891,
        1785,
        293,
        512,
        8121,
        1785,
        420,
        3779,
        50960
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06728590618480336,
      "compression_ratio": 1.8300395256916997,
      "no_speech_prob": 0.001083924900740385
    },
    {
      "id": 78,
      "seek": 48580,
      "start": 497.72,
      "end": 503.40000000000003,
      "text": " state, like in the case of the puzzle game, that I'm given some starting state and we know what",
      "tokens": [
        50960,
        1785,
        11,
        411,
        294,
        264,
        1389,
        295,
        264,
        12805,
        1216,
        11,
        300,
        286,
        478,
        2212,
        512,
        2891,
        1785,
        293,
        321,
        458,
        437,
        51244
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06728590618480336,
      "compression_ratio": 1.8300395256916997,
      "no_speech_prob": 0.001083924900740385
    },
    {
      "id": 79,
      "seek": 48580,
      "start": 503.40000000000003,
      "end": 508.68,
      "text": " the goal state is. So, here one decision problem would be to answer the question whether it's",
      "tokens": [
        51244,
        264,
        3387,
        1785,
        307,
        13,
        407,
        11,
        510,
        472,
        3537,
        1154,
        576,
        312,
        281,
        1867,
        264,
        1168,
        1968,
        309,
        311,
        51508
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06728590618480336,
      "compression_ratio": 1.8300395256916997,
      "no_speech_prob": 0.001083924900740385
    },
    {
      "id": 80,
      "seek": 48580,
      "start": 508.68,
      "end": 514.36,
      "text": " possible to get to the target state starting from some initial state that is also given to me.",
      "tokens": [
        51508,
        1944,
        281,
        483,
        281,
        264,
        3779,
        1785,
        2891,
        490,
        512,
        5883,
        1785,
        300,
        307,
        611,
        2212,
        281,
        385,
        13,
        51792
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06728590618480336,
      "compression_ratio": 1.8300395256916997,
      "no_speech_prob": 0.001083924900740385
    },
    {
      "id": 81,
      "seek": 51580,
      "start": 515.88,
      "end": 520.4399999999999,
      "text": " So, you could decide to solve this problem either as a decision problem or as a search problem,",
      "tokens": [
        50368,
        407,
        11,
        291,
        727,
        4536,
        281,
        5039,
        341,
        1154,
        2139,
        382,
        257,
        3537,
        1154,
        420,
        382,
        257,
        3164,
        1154,
        11,
        50596
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0822535825062947,
      "compression_ratio": 1.6808510638297873,
      "no_speech_prob": 0.00018748217553365976
    },
    {
      "id": 82,
      "seek": 51580,
      "start": 520.4399999999999,
      "end": 526.04,
      "text": " which would give you the actual sequence of steps that will take you from a state to the target state.",
      "tokens": [
        50596,
        597,
        576,
        976,
        291,
        264,
        3539,
        8310,
        295,
        4439,
        300,
        486,
        747,
        291,
        490,
        257,
        1785,
        281,
        264,
        3779,
        1785,
        13,
        50876
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0822535825062947,
      "compression_ratio": 1.6808510638297873,
      "no_speech_prob": 0.00018748217553365976
    },
    {
      "id": 83,
      "seek": 51580,
      "start": 529.8,
      "end": 535.4,
      "text": " Other interesting computational problems, is it always possible to go from one configuration",
      "tokens": [
        51064,
        5358,
        1880,
        28270,
        2740,
        11,
        307,
        309,
        1009,
        1944,
        281,
        352,
        490,
        472,
        11694,
        51344
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0822535825062947,
      "compression_ratio": 1.6808510638297873,
      "no_speech_prob": 0.00018748217553365976
    },
    {
      "id": 84,
      "seek": 51580,
      "start": 535.4,
      "end": 541.24,
      "text": " to any other? And this is basically also related to the structural question about connected components.",
      "tokens": [
        51344,
        281,
        604,
        661,
        30,
        400,
        341,
        307,
        1936,
        611,
        4077,
        281,
        264,
        15067,
        1168,
        466,
        4582,
        6677,
        13,
        51636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0822535825062947,
      "compression_ratio": 1.6808510638297873,
      "no_speech_prob": 0.00018748217553365976
    },
    {
      "id": 85,
      "seek": 54124,
      "start": 541.32,
      "end": 549.32,
      "text": " And the last question that I will mention, which is also interesting, is how fast can you go from",
      "tokens": [
        50368,
        400,
        264,
        1036,
        1168,
        300,
        286,
        486,
        2152,
        11,
        597,
        307,
        611,
        1880,
        11,
        307,
        577,
        2370,
        393,
        291,
        352,
        490,
        50768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23667820862361363,
      "compression_ratio": 1.4557823129251701,
      "no_speech_prob": 0.0017247877549380064
    },
    {
      "id": 86,
      "seek": 54124,
      "start": 549.32,
      "end": 553.72,
      "text": " one configuration to another? Meaning, can you do it in at most case steps?",
      "tokens": [
        50768,
        472,
        11694,
        281,
        1071,
        30,
        19948,
        11,
        393,
        291,
        360,
        309,
        294,
        412,
        881,
        1389,
        4439,
        30,
        50988
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23667820862361363,
      "compression_ratio": 1.4557823129251701,
      "no_speech_prob": 0.0017247877549380064
    },
    {
      "id": 87,
      "seek": 54124,
      "start": 556.52,
      "end": 560.44,
      "text": " There is a question I should wait or no?",
      "tokens": [
        51128,
        821,
        307,
        257,
        1168,
        286,
        820,
        1699,
        420,
        572,
        30,
        51324
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23667820862361363,
      "compression_ratio": 1.4557823129251701,
      "no_speech_prob": 0.0017247877549380064
    },
    {
      "id": 88,
      "seek": 56044,
      "start": 560.44,
      "end": 573.32,
      "text": " Okay. All right. So, think about all of these questions that we paused using the simple 15 puzzle",
      "tokens": [
        50364,
        1033,
        13,
        1057,
        558,
        13,
        407,
        11,
        519,
        466,
        439,
        295,
        613,
        1651,
        300,
        321,
        46860,
        1228,
        264,
        2199,
        2119,
        12805,
        51008
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1619632134070763,
      "compression_ratio": 1.4696132596685083,
      "no_speech_prob": 0.0026269364170730114
    },
    {
      "id": 89,
      "seek": 56044,
      "start": 573.32,
      "end": 580.12,
      "text": " game. And now we're going to look at a lot of other possible problems where the same",
      "tokens": [
        51008,
        1216,
        13,
        400,
        586,
        321,
        434,
        516,
        281,
        574,
        412,
        257,
        688,
        295,
        661,
        1944,
        2740,
        689,
        264,
        912,
        51348
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1619632134070763,
      "compression_ratio": 1.4696132596685083,
      "no_speech_prob": 0.0026269364170730114
    },
    {
      "id": 90,
      "seek": 56044,
      "start": 580.12,
      "end": 585.8800000000001,
      "text": " any configuration graph can be extracted. And we can ask the same set of questions.",
      "tokens": [
        51348,
        604,
        11694,
        4295,
        393,
        312,
        34086,
        13,
        400,
        321,
        393,
        1029,
        264,
        912,
        992,
        295,
        1651,
        13,
        51636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1619632134070763,
      "compression_ratio": 1.4696132596685083,
      "no_speech_prob": 0.0026269364170730114
    },
    {
      "id": 91,
      "seek": 58588,
      "start": 586.84,
      "end": 592.4399999999999,
      "text": " So, all of you here are familiar with the KSAT problem. So, you're given a Boolean formula and",
      "tokens": [
        50412,
        407,
        11,
        439,
        295,
        291,
        510,
        366,
        4963,
        365,
        264,
        591,
        50,
        2218,
        1154,
        13,
        407,
        11,
        291,
        434,
        2212,
        257,
        23351,
        28499,
        8513,
        293,
        50692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09883656832251218,
      "compression_ratio": 1.6223175965665235,
      "no_speech_prob": 0.0008887816802598536
    },
    {
      "id": 92,
      "seek": 58588,
      "start": 592.4399999999999,
      "end": 599.0,
      "text": " you want to know if you can satisfy this formula by assigning values to the variables. And we know",
      "tokens": [
        50692,
        291,
        528,
        281,
        458,
        498,
        291,
        393,
        19319,
        341,
        8513,
        538,
        49602,
        4190,
        281,
        264,
        9102,
        13,
        400,
        321,
        458,
        51020
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09883656832251218,
      "compression_ratio": 1.6223175965665235,
      "no_speech_prob": 0.0008887816802598536
    },
    {
      "id": 93,
      "seek": 58588,
      "start": 599.0,
      "end": 604.92,
      "text": " that this is NP-complete for K greater than or equal to three. So, now how can you transform this",
      "tokens": [
        51020,
        300,
        341,
        307,
        38611,
        12,
        1112,
        17220,
        337,
        591,
        5044,
        813,
        420,
        2681,
        281,
        1045,
        13,
        407,
        11,
        586,
        577,
        393,
        291,
        4088,
        341,
        51316
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09883656832251218,
      "compression_ratio": 1.6223175965665235,
      "no_speech_prob": 0.0008887816802598536
    },
    {
      "id": 94,
      "seek": 58588,
      "start": 604.92,
      "end": 610.04,
      "text": " into a reconfiguration problem? Well, it's very simple. So, now you're given a formula",
      "tokens": [
        51316,
        666,
        257,
        9993,
        20646,
        8167,
        1154,
        30,
        1042,
        11,
        309,
        311,
        588,
        2199,
        13,
        407,
        11,
        586,
        291,
        434,
        2212,
        257,
        8513,
        51572
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09883656832251218,
      "compression_ratio": 1.6223175965665235,
      "no_speech_prob": 0.0008887816802598536
    },
    {
      "id": 95,
      "seek": 61004,
      "start": 610.36,
      "end": 616.76,
      "text": " and you're given two satisfying assignments. So, you can think of those satisfying assignments as",
      "tokens": [
        50380,
        293,
        291,
        434,
        2212,
        732,
        18348,
        22546,
        13,
        407,
        11,
        291,
        393,
        519,
        295,
        729,
        18348,
        22546,
        382,
        50700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09320679832907285,
      "compression_ratio": 1.8365384615384615,
      "no_speech_prob": 0.0011886667925864458
    },
    {
      "id": 96,
      "seek": 61004,
      "start": 616.76,
      "end": 623.88,
      "text": " bit vectors. And so, now the question that you can ask is, can I go from the first satisfying",
      "tokens": [
        50700,
        857,
        18875,
        13,
        400,
        370,
        11,
        586,
        264,
        1168,
        300,
        291,
        393,
        1029,
        307,
        11,
        393,
        286,
        352,
        490,
        264,
        700,
        18348,
        51056
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09320679832907285,
      "compression_ratio": 1.8365384615384615,
      "no_speech_prob": 0.0011886667925864458
    },
    {
      "id": 97,
      "seek": 61004,
      "start": 623.88,
      "end": 632.36,
      "text": " assignment to the next one by basically flipping one bit at a time under the condition that I",
      "tokens": [
        51056,
        15187,
        281,
        264,
        958,
        472,
        538,
        1936,
        26886,
        472,
        857,
        412,
        257,
        565,
        833,
        264,
        4188,
        300,
        286,
        51480
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09320679832907285,
      "compression_ratio": 1.8365384615384615,
      "no_speech_prob": 0.0011886667925864458
    },
    {
      "id": 98,
      "seek": 61004,
      "start": 632.36,
      "end": 638.76,
      "text": " remain a satisfying assignment at all times? And notice that without this condition, the problem",
      "tokens": [
        51480,
        6222,
        257,
        18348,
        15187,
        412,
        439,
        1413,
        30,
        400,
        3449,
        300,
        1553,
        341,
        4188,
        11,
        264,
        1154,
        51800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09320679832907285,
      "compression_ratio": 1.8365384615384615,
      "no_speech_prob": 0.0011886667925864458
    },
    {
      "id": 99,
      "seek": 63876,
      "start": 638.76,
      "end": 647.0,
      "text": " is trivial. So, you can basically just flip the bits however you like and reach S from T or T from S.",
      "tokens": [
        50364,
        307,
        26703,
        13,
        407,
        11,
        291,
        393,
        1936,
        445,
        7929,
        264,
        9239,
        4461,
        291,
        411,
        293,
        2524,
        318,
        490,
        314,
        420,
        314,
        490,
        318,
        13,
        50776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1109494703361787,
      "compression_ratio": 1.6681818181818182,
      "no_speech_prob": 0.0004547557618934661
    },
    {
      "id": 100,
      "seek": 63876,
      "start": 647.64,
      "end": 654.2,
      "text": " But once you add this constraint of you should remain a satisfying assignment, the problem becomes",
      "tokens": [
        50808,
        583,
        1564,
        291,
        909,
        341,
        25534,
        295,
        291,
        820,
        6222,
        257,
        18348,
        15187,
        11,
        264,
        1154,
        3643,
        51136
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1109494703361787,
      "compression_ratio": 1.6681818181818182,
      "no_speech_prob": 0.0004547557618934661
    },
    {
      "id": 101,
      "seek": 63876,
      "start": 654.2,
      "end": 660.04,
      "text": " way more interesting. And you can think of this problem again as walking in the solution space",
      "tokens": [
        51136,
        636,
        544,
        1880,
        13,
        400,
        291,
        393,
        519,
        295,
        341,
        1154,
        797,
        382,
        4494,
        294,
        264,
        3827,
        1901,
        51428
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1109494703361787,
      "compression_ratio": 1.6681818181818182,
      "no_speech_prob": 0.0004547557618934661
    },
    {
      "id": 102,
      "seek": 63876,
      "start": 660.84,
      "end": 665.56,
      "text": " of the given formula of all the satisfying assignment of the formula F.",
      "tokens": [
        51468,
        295,
        264,
        2212,
        8513,
        295,
        439,
        264,
        18348,
        15187,
        295,
        264,
        8513,
        479,
        13,
        51704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1109494703361787,
      "compression_ratio": 1.6681818181818182,
      "no_speech_prob": 0.0004547557618934661
    },
    {
      "id": 103,
      "seek": 66876,
      "start": 669.08,
      "end": 674.52,
      "text": " All right, so that's the SAT reconfiguration problem. Let's look at another example.",
      "tokens": [
        50380,
        1057,
        558,
        11,
        370,
        300,
        311,
        264,
        31536,
        9993,
        20646,
        8167,
        1154,
        13,
        961,
        311,
        574,
        412,
        1071,
        1365,
        13,
        50652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12029286793300084,
      "compression_ratio": 1.5957446808510638,
      "no_speech_prob": 0.00013153557665646076
    },
    {
      "id": 104,
      "seek": 66876,
      "start": 675.8,
      "end": 683.64,
      "text": " Graph coloring. We all know it, we all love it. You're given a graph and some integer K and you are",
      "tokens": [
        50716,
        21884,
        23198,
        13,
        492,
        439,
        458,
        309,
        11,
        321,
        439,
        959,
        309,
        13,
        509,
        434,
        2212,
        257,
        4295,
        293,
        512,
        24922,
        591,
        293,
        291,
        366,
        51108
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12029286793300084,
      "compression_ratio": 1.5957446808510638,
      "no_speech_prob": 0.00013153557665646076
    },
    {
      "id": 105,
      "seek": 66876,
      "start": 683.64,
      "end": 689.24,
      "text": " asked whether you can properly K color the graph G. And we know again that this is NP-complete for",
      "tokens": [
        51108,
        2351,
        1968,
        291,
        393,
        6108,
        591,
        2017,
        264,
        4295,
        460,
        13,
        400,
        321,
        458,
        797,
        300,
        341,
        307,
        38611,
        12,
        1112,
        17220,
        337,
        51388
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12029286793300084,
      "compression_ratio": 1.5957446808510638,
      "no_speech_prob": 0.00013153557665646076
    },
    {
      "id": 106,
      "seek": 66876,
      "start": 689.24,
      "end": 694.2,
      "text": " K greater than or equal to three. How do you transform that into a reconfiguration problem?",
      "tokens": [
        51388,
        591,
        5044,
        813,
        420,
        2681,
        281,
        1045,
        13,
        1012,
        360,
        291,
        4088,
        300,
        666,
        257,
        9993,
        20646,
        8167,
        1154,
        30,
        51636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12029286793300084,
      "compression_ratio": 1.5957446808510638,
      "no_speech_prob": 0.00013153557665646076
    },
    {
      "id": 107,
      "seek": 69420,
      "start": 694.2,
      "end": 701.24,
      "text": " Well, now you're given a graph, you're given two colorings of the graph, alpha and beta. And the",
      "tokens": [
        50364,
        1042,
        11,
        586,
        291,
        434,
        2212,
        257,
        4295,
        11,
        291,
        434,
        2212,
        732,
        2017,
        1109,
        295,
        264,
        4295,
        11,
        8961,
        293,
        9861,
        13,
        400,
        264,
        50716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10750190734863281,
      "compression_ratio": 1.76036866359447,
      "no_speech_prob": 0.00016896553279366344
    },
    {
      "id": 108,
      "seek": 69420,
      "start": 701.24,
      "end": 709.24,
      "text": " question is, can you recolor alpha to get the, to beta? But you need to recolor one vertex at a time",
      "tokens": [
        50716,
        1168,
        307,
        11,
        393,
        291,
        850,
        36182,
        8961,
        281,
        483,
        264,
        11,
        281,
        9861,
        30,
        583,
        291,
        643,
        281,
        850,
        36182,
        472,
        28162,
        412,
        257,
        565,
        51116
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10750190734863281,
      "compression_ratio": 1.76036866359447,
      "no_speech_prob": 0.00016896553279366344
    },
    {
      "id": 109,
      "seek": 69420,
      "start": 709.24,
      "end": 716.2800000000001,
      "text": " and you need to remain a proper K coloring throughout. Same idea again leads us to this",
      "tokens": [
        51116,
        293,
        291,
        643,
        281,
        6222,
        257,
        2296,
        591,
        23198,
        3710,
        13,
        10635,
        1558,
        797,
        6689,
        505,
        281,
        341,
        51468
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10750190734863281,
      "compression_ratio": 1.76036866359447,
      "no_speech_prob": 0.00016896553279366344
    },
    {
      "id": 110,
      "seek": 69420,
      "start": 716.2800000000001,
      "end": 722.2800000000001,
      "text": " notion of the reconfiguration space where we are looking at the K colorings of the graph and how",
      "tokens": [
        51468,
        10710,
        295,
        264,
        9993,
        20646,
        8167,
        1901,
        689,
        321,
        366,
        1237,
        412,
        264,
        591,
        2017,
        1109,
        295,
        264,
        4295,
        293,
        577,
        51768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10750190734863281,
      "compression_ratio": 1.76036866359447,
      "no_speech_prob": 0.00016896553279366344
    },
    {
      "id": 111,
      "seek": 72228,
      "start": 722.28,
      "end": 729.3199999999999,
      "text": " they are connected under this adjacent simulation that we define, which is a single vertex recoloring.",
      "tokens": [
        50364,
        436,
        366,
        4582,
        833,
        341,
        24441,
        16575,
        300,
        321,
        6964,
        11,
        597,
        307,
        257,
        2167,
        28162,
        850,
        401,
        3662,
        13,
        50716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09237332966016687,
      "compression_ratio": 1.685589519650655,
      "no_speech_prob": 7.00658856658265e-05
    },
    {
      "id": 112,
      "seek": 72228,
      "start": 731.9599999999999,
      "end": 736.92,
      "text": " The final example that I will mention, which will be basically what we will focus on in the",
      "tokens": [
        50848,
        440,
        2572,
        1365,
        300,
        286,
        486,
        2152,
        11,
        597,
        486,
        312,
        1936,
        437,
        321,
        486,
        1879,
        322,
        294,
        264,
        51096
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09237332966016687,
      "compression_ratio": 1.685589519650655,
      "no_speech_prob": 7.00658856658265e-05
    },
    {
      "id": 113,
      "seek": 72228,
      "start": 736.92,
      "end": 742.8399999999999,
      "text": " rest of the talk is a token placement, I call it, but as you will all guess, this is the famous",
      "tokens": [
        51096,
        1472,
        295,
        264,
        751,
        307,
        257,
        14862,
        17257,
        11,
        286,
        818,
        309,
        11,
        457,
        382,
        291,
        486,
        439,
        2041,
        11,
        341,
        307,
        264,
        4618,
        51392
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09237332966016687,
      "compression_ratio": 1.685589519650655,
      "no_speech_prob": 7.00658856658265e-05
    },
    {
      "id": 114,
      "seek": 72228,
      "start": 742.8399999999999,
      "end": 748.8399999999999,
      "text": " independent set problem. But we will look at it as a token placement problem because it will be",
      "tokens": [
        51392,
        6695,
        992,
        1154,
        13,
        583,
        321,
        486,
        574,
        412,
        309,
        382,
        257,
        14862,
        17257,
        1154,
        570,
        309,
        486,
        312,
        51692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09237332966016687,
      "compression_ratio": 1.685589519650655,
      "no_speech_prob": 7.00658856658265e-05
    },
    {
      "id": 115,
      "seek": 74884,
      "start": 748.84,
      "end": 753.96,
      "text": " more useful for the rest of the talk. So you're given a graph G and an integer K. And the question",
      "tokens": [
        50364,
        544,
        4420,
        337,
        264,
        1472,
        295,
        264,
        751,
        13,
        407,
        291,
        434,
        2212,
        257,
        4295,
        460,
        293,
        364,
        24922,
        591,
        13,
        400,
        264,
        1168,
        50620
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06866263889131091,
      "compression_ratio": 1.6485355648535565,
      "no_speech_prob": 0.0005270365509204566
    },
    {
      "id": 116,
      "seek": 74884,
      "start": 753.96,
      "end": 760.0400000000001,
      "text": " is, can you place K tokens on your graph, K black tokens, so that no two of these tokens share an",
      "tokens": [
        50620,
        307,
        11,
        393,
        291,
        1081,
        591,
        22667,
        322,
        428,
        4295,
        11,
        591,
        2211,
        22667,
        11,
        370,
        300,
        572,
        732,
        295,
        613,
        22667,
        2073,
        364,
        50924
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06866263889131091,
      "compression_ratio": 1.6485355648535565,
      "no_speech_prob": 0.0005270365509204566
    },
    {
      "id": 117,
      "seek": 74884,
      "start": 760.0400000000001,
      "end": 766.52,
      "text": " edge? And of course, we all know that this is an NP-complete problem. So how can you transform",
      "tokens": [
        50924,
        4691,
        30,
        400,
        295,
        1164,
        11,
        321,
        439,
        458,
        300,
        341,
        307,
        364,
        38611,
        12,
        1112,
        17220,
        1154,
        13,
        407,
        577,
        393,
        291,
        4088,
        51248
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06866263889131091,
      "compression_ratio": 1.6485355648535565,
      "no_speech_prob": 0.0005270365509204566
    },
    {
      "id": 118,
      "seek": 74884,
      "start": 766.52,
      "end": 772.2,
      "text": " this problem into a reconfiguration problem? Again, now I'm given a graph, two independent sets of the",
      "tokens": [
        51248,
        341,
        1154,
        666,
        257,
        9993,
        20646,
        8167,
        1154,
        30,
        3764,
        11,
        586,
        286,
        478,
        2212,
        257,
        4295,
        11,
        732,
        6695,
        6352,
        295,
        264,
        51532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06866263889131091,
      "compression_ratio": 1.6485355648535565,
      "no_speech_prob": 0.0005270365509204566
    },
    {
      "id": 119,
      "seek": 77220,
      "start": 772.2,
      "end": 778.76,
      "text": " graph, each of size K. And the question is, can I go from one independent set to the other",
      "tokens": [
        50364,
        4295,
        11,
        1184,
        295,
        2744,
        591,
        13,
        400,
        264,
        1168,
        307,
        11,
        393,
        286,
        352,
        490,
        472,
        6695,
        992,
        281,
        264,
        661,
        50692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06679704022961994,
      "compression_ratio": 1.6488888888888888,
      "no_speech_prob": 0.0018681101500988007
    },
    {
      "id": 120,
      "seek": 77220,
      "start": 780.36,
      "end": 786.84,
      "text": " under what rule? So here defining the rule for independent set, how can I go between",
      "tokens": [
        50772,
        833,
        437,
        4978,
        30,
        407,
        510,
        17827,
        264,
        4978,
        337,
        6695,
        992,
        11,
        577,
        393,
        286,
        352,
        1296,
        51096
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06679704022961994,
      "compression_ratio": 1.6488888888888888,
      "no_speech_prob": 0.0018681101500988007
    },
    {
      "id": 121,
      "seek": 77220,
      "start": 786.84,
      "end": 793.5600000000001,
      "text": " consecutive independent sets becomes a little bit less obvious. And there are two main strategies",
      "tokens": [
        51096,
        30497,
        6695,
        6352,
        3643,
        257,
        707,
        857,
        1570,
        6322,
        13,
        400,
        456,
        366,
        732,
        2135,
        9029,
        51432
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06679704022961994,
      "compression_ratio": 1.6488888888888888,
      "no_speech_prob": 0.0018681101500988007
    },
    {
      "id": 122,
      "seek": 77220,
      "start": 793.5600000000001,
      "end": 800.5200000000001,
      "text": " that people have attempted. So the first rule is what we call token jumping. So you are basically",
      "tokens": [
        51432,
        300,
        561,
        362,
        18997,
        13,
        407,
        264,
        700,
        4978,
        307,
        437,
        321,
        818,
        14862,
        11233,
        13,
        407,
        291,
        366,
        1936,
        51780
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06679704022961994,
      "compression_ratio": 1.6488888888888888,
      "no_speech_prob": 0.0018681101500988007
    },
    {
      "id": 123,
      "seek": 80052,
      "start": 800.52,
      "end": 807.4,
      "text": " allowed to take any token on your graph and jump it to any other vertex on the graph, assuming that",
      "tokens": [
        50364,
        4350,
        281,
        747,
        604,
        14862,
        322,
        428,
        4295,
        293,
        3012,
        309,
        281,
        604,
        661,
        28162,
        322,
        264,
        4295,
        11,
        11926,
        300,
        50708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0760914005645334,
      "compression_ratio": 1.6519337016574585,
      "no_speech_prob": 0.0009204497910104692
    },
    {
      "id": 124,
      "seek": 80052,
      "start": 807.4,
      "end": 814.36,
      "text": " it doesn't have a token and that you maintain an independent set at all times. So for example, in this",
      "tokens": [
        50708,
        309,
        1177,
        380,
        362,
        257,
        14862,
        293,
        300,
        291,
        6909,
        364,
        6695,
        992,
        412,
        439,
        1413,
        13,
        407,
        337,
        1365,
        11,
        294,
        341,
        51056
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0760914005645334,
      "compression_ratio": 1.6519337016574585,
      "no_speech_prob": 0.0009204497910104692
    },
    {
      "id": 125,
      "seek": 80052,
      "start": 815.0799999999999,
      "end": 821.16,
      "text": " example that I have here, it would be perfectly okay to take this token here and jump it to this",
      "tokens": [
        51092,
        1365,
        300,
        286,
        362,
        510,
        11,
        309,
        576,
        312,
        6239,
        1392,
        281,
        747,
        341,
        14862,
        510,
        293,
        3012,
        309,
        281,
        341,
        51396
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0760914005645334,
      "compression_ratio": 1.6519337016574585,
      "no_speech_prob": 0.0009204497910104692
    },
    {
      "id": 126,
      "seek": 82116,
      "start": 821.16,
      "end": 831.7199999999999,
      "text": " vertex here. Or I could also take this token here and jump it to this vertex here. So that no,",
      "tokens": [
        50364,
        28162,
        510,
        13,
        1610,
        286,
        727,
        611,
        747,
        341,
        14862,
        510,
        293,
        3012,
        309,
        281,
        341,
        28162,
        510,
        13,
        407,
        300,
        572,
        11,
        50892
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1043089838588939,
      "compression_ratio": 1.680232558139535,
      "no_speech_prob": 0.000758527428843081
    },
    {
      "id": 127,
      "seek": 82116,
      "start": 831.7199999999999,
      "end": 837.88,
      "text": " actually that would violate the independence. So you can jump to any other vertex as long as you",
      "tokens": [
        50892,
        767,
        300,
        576,
        37478,
        264,
        14640,
        13,
        407,
        291,
        393,
        3012,
        281,
        604,
        661,
        28162,
        382,
        938,
        382,
        291,
        51200
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1043089838588939,
      "compression_ratio": 1.680232558139535,
      "no_speech_prob": 0.000758527428843081
    },
    {
      "id": 128,
      "seek": 82116,
      "start": 837.88,
      "end": 844.76,
      "text": " maintain independence. And we call that the token jumping rule. The other rule is basically token",
      "tokens": [
        51200,
        6909,
        14640,
        13,
        400,
        321,
        818,
        300,
        264,
        14862,
        11233,
        4978,
        13,
        440,
        661,
        4978,
        307,
        1936,
        14862,
        51544
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1043089838588939,
      "compression_ratio": 1.680232558139535,
      "no_speech_prob": 0.000758527428843081
    },
    {
      "id": 129,
      "seek": 84476,
      "start": 844.76,
      "end": 850.04,
      "text": " sliding. So in this case, we only allow a token to slide along edges of the graph.",
      "tokens": [
        50364,
        21169,
        13,
        407,
        294,
        341,
        1389,
        11,
        321,
        787,
        2089,
        257,
        14862,
        281,
        4137,
        2051,
        8819,
        295,
        264,
        4295,
        13,
        50628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07135046323140462,
      "compression_ratio": 1.853658536585366,
      "no_speech_prob": 0.001481608022004366
    },
    {
      "id": 130,
      "seek": 84476,
      "start": 851.48,
      "end": 860.12,
      "text": " So a token can only move to an adjacent vertex, assuming of course this does not violate independence.",
      "tokens": [
        50700,
        407,
        257,
        14862,
        393,
        787,
        1286,
        281,
        364,
        24441,
        28162,
        11,
        11926,
        295,
        1164,
        341,
        775,
        406,
        37478,
        14640,
        13,
        51132
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07135046323140462,
      "compression_ratio": 1.853658536585366,
      "no_speech_prob": 0.001481608022004366
    },
    {
      "id": 131,
      "seek": 84476,
      "start": 860.92,
      "end": 865.8,
      "text": " So now we have two different reconfiguration graphs we can think about. We can think about the",
      "tokens": [
        51172,
        407,
        586,
        321,
        362,
        732,
        819,
        9993,
        20646,
        8167,
        24877,
        321,
        393,
        519,
        466,
        13,
        492,
        393,
        519,
        466,
        264,
        51416
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07135046323140462,
      "compression_ratio": 1.853658536585366,
      "no_speech_prob": 0.001481608022004366
    },
    {
      "id": 132,
      "seek": 84476,
      "start": 865.8,
      "end": 871.3199999999999,
      "text": " reconfiguration graph under the token jumping adjacency. And we can think about the reconfiguration",
      "tokens": [
        51416,
        9993,
        20646,
        8167,
        4295,
        833,
        264,
        14862,
        11233,
        22940,
        3020,
        13,
        400,
        321,
        393,
        519,
        466,
        264,
        9993,
        20646,
        8167,
        51692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07135046323140462,
      "compression_ratio": 1.853658536585366,
      "no_speech_prob": 0.001481608022004366
    },
    {
      "id": 133,
      "seek": 87132,
      "start": 871.32,
      "end": 877.4000000000001,
      "text": " graph under the token sliding adjacency. And we're going to talk about these two different",
      "tokens": [
        50364,
        4295,
        833,
        264,
        14862,
        21169,
        22940,
        3020,
        13,
        400,
        321,
        434,
        516,
        281,
        751,
        466,
        613,
        732,
        819,
        50668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08915099643525623,
      "compression_ratio": 1.6538461538461537,
      "no_speech_prob": 0.00038984918501228094
    },
    {
      "id": 134,
      "seek": 87132,
      "start": 877.4000000000001,
      "end": 883.72,
      "text": " problems because they do actually behave quite differently and they produce quite interesting",
      "tokens": [
        50668,
        2740,
        570,
        436,
        360,
        767,
        15158,
        1596,
        7614,
        293,
        436,
        5258,
        1596,
        1880,
        50984
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08915099643525623,
      "compression_ratio": 1.6538461538461537,
      "no_speech_prob": 0.00038984918501228094
    },
    {
      "id": 135,
      "seek": 87132,
      "start": 883.72,
      "end": 888.84,
      "text": " results. Like the difference between the two, we don't fully understand yet, but we kind of know",
      "tokens": [
        50984,
        3542,
        13,
        1743,
        264,
        2649,
        1296,
        264,
        732,
        11,
        321,
        500,
        380,
        4498,
        1223,
        1939,
        11,
        457,
        321,
        733,
        295,
        458,
        51240
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08915099643525623,
      "compression_ratio": 1.6538461538461537,
      "no_speech_prob": 0.00038984918501228094
    },
    {
      "id": 136,
      "seek": 87132,
      "start": 888.84,
      "end": 895.6400000000001,
      "text": " that token sliding can be harder than token jumping. But there's still a lot of questions to be answered.",
      "tokens": [
        51240,
        300,
        14862,
        21169,
        393,
        312,
        6081,
        813,
        14862,
        11233,
        13,
        583,
        456,
        311,
        920,
        257,
        688,
        295,
        1651,
        281,
        312,
        10103,
        13,
        51580
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08915099643525623,
      "compression_ratio": 1.6538461538461537,
      "no_speech_prob": 0.00038984918501228094
    },
    {
      "id": 137,
      "seek": 89564,
      "start": 896.28,
      "end": 903.3199999999999,
      "text": " All right. So some of you might be asking, why do we care about studying such problems? There's a lot",
      "tokens": [
        50396,
        1057,
        558,
        13,
        407,
        512,
        295,
        291,
        1062,
        312,
        3365,
        11,
        983,
        360,
        321,
        1127,
        466,
        7601,
        1270,
        2740,
        30,
        821,
        311,
        257,
        688,
        50748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16720953295307775,
      "compression_ratio": 1.652542372881356,
      "no_speech_prob": 0.0004332499811425805
    },
    {
      "id": 138,
      "seek": 89564,
      "start": 903.3199999999999,
      "end": 911.3199999999999,
      "text": " of motivations out there. I mean, as sometimes I would say you don't need motivation. They're",
      "tokens": [
        50748,
        295,
        39034,
        484,
        456,
        13,
        286,
        914,
        11,
        382,
        2171,
        286,
        576,
        584,
        291,
        500,
        380,
        643,
        12335,
        13,
        814,
        434,
        51148
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16720953295307775,
      "compression_ratio": 1.652542372881356,
      "no_speech_prob": 0.0004332499811425805
    },
    {
      "id": 139,
      "seek": 89564,
      "start": 911.3199999999999,
      "end": 916.6,
      "text": " interesting. There's a lot of open questions that we need to answer. But you can also think about",
      "tokens": [
        51148,
        1880,
        13,
        821,
        311,
        257,
        688,
        295,
        1269,
        1651,
        300,
        321,
        643,
        281,
        1867,
        13,
        583,
        291,
        393,
        611,
        519,
        466,
        51412
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16720953295307775,
      "compression_ratio": 1.652542372881356,
      "no_speech_prob": 0.0004332499811425805
    },
    {
      "id": 140,
      "seek": 89564,
      "start": 916.6,
      "end": 922.84,
      "text": " reconfiguration problems as another way of modeling real world algorithmic problems. Because you",
      "tokens": [
        51412,
        9993,
        20646,
        8167,
        2740,
        382,
        1071,
        636,
        295,
        15983,
        957,
        1002,
        9284,
        299,
        2740,
        13,
        1436,
        291,
        51724
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16720953295307775,
      "compression_ratio": 1.652542372881356,
      "no_speech_prob": 0.0004332499811425805
    },
    {
      "id": 141,
      "seek": 92284,
      "start": 922.84,
      "end": 927.88,
      "text": " usually never start from scratch. When you're trying to solve real world problems, you usually",
      "tokens": [
        50364,
        2673,
        1128,
        722,
        490,
        8459,
        13,
        1133,
        291,
        434,
        1382,
        281,
        5039,
        957,
        1002,
        2740,
        11,
        291,
        2673,
        50616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2693069076538086,
      "compression_ratio": 1.724264705882353,
      "no_speech_prob": 0.0012035260442644358
    },
    {
      "id": 142,
      "seek": 92284,
      "start": 927.88,
      "end": 933.0,
      "text": " start from something and you're trying to prove it or make it better or change it to something",
      "tokens": [
        50616,
        722,
        490,
        746,
        293,
        291,
        434,
        1382,
        281,
        7081,
        309,
        420,
        652,
        309,
        1101,
        420,
        1319,
        309,
        281,
        746,
        50872
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2693069076538086,
      "compression_ratio": 1.724264705882353,
      "no_speech_prob": 0.0012035260442644358
    },
    {
      "id": 143,
      "seek": 92284,
      "start": 933.0,
      "end": 940.6800000000001,
      "text": " more appropriate. Another very good application of studying these problems is that they give you a",
      "tokens": [
        50872,
        544,
        6854,
        13,
        3996,
        588,
        665,
        3861,
        295,
        7601,
        613,
        2740,
        307,
        300,
        436,
        976,
        291,
        257,
        51256
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2693069076538086,
      "compression_ratio": 1.724264705882353,
      "no_speech_prob": 0.0012035260442644358
    },
    {
      "id": 144,
      "seek": 92284,
      "start": 940.6800000000001,
      "end": 946.0400000000001,
      "text": " better understanding of solution spaces, which can be very important for other areas as well.",
      "tokens": [
        51256,
        1101,
        3701,
        295,
        3827,
        7673,
        11,
        597,
        393,
        312,
        588,
        1021,
        337,
        661,
        3179,
        382,
        731,
        13,
        51524
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2693069076538086,
      "compression_ratio": 1.724264705882353,
      "no_speech_prob": 0.0012035260442644358
    },
    {
      "id": 145,
      "seek": 92284,
      "start": 946.36,
      "end": 951.24,
      "text": " And they have been used in statistical physics, quantum computing, and in the field of",
      "tokens": [
        51540,
        400,
        436,
        362,
        668,
        1143,
        294,
        22820,
        10649,
        11,
        13018,
        15866,
        11,
        293,
        294,
        264,
        2519,
        295,
        51784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2693069076538086,
      "compression_ratio": 1.724264705882353,
      "no_speech_prob": 0.0012035260442644358
    },
    {
      "id": 146,
      "seek": 95124,
      "start": 951.8,
      "end": 957.08,
      "text": " physics, quantum computing, and in complexity theory, combinatorics, and robotics, and hopefully",
      "tokens": [
        50392,
        10649,
        11,
        13018,
        15866,
        11,
        293,
        294,
        14024,
        5261,
        11,
        2512,
        31927,
        1167,
        11,
        293,
        34145,
        11,
        293,
        4696,
        50656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1507774879192484,
      "compression_ratio": 1.6753246753246753,
      "no_speech_prob": 0.0018164520151913166
    },
    {
      "id": 147,
      "seek": 95124,
      "start": 957.08,
      "end": 962.6800000000001,
      "text": " many more applications to come. But what I would tell you is that there are so many very interesting",
      "tokens": [
        50656,
        867,
        544,
        5821,
        281,
        808,
        13,
        583,
        437,
        286,
        576,
        980,
        291,
        307,
        300,
        456,
        366,
        370,
        867,
        588,
        1880,
        50936
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1507774879192484,
      "compression_ratio": 1.6753246753246753,
      "no_speech_prob": 0.0018164520151913166
    },
    {
      "id": 148,
      "seek": 95124,
      "start": 962.6800000000001,
      "end": 968.6,
      "text": " problems that are so easy to start thinking about without having too much background, which is why",
      "tokens": [
        50936,
        2740,
        300,
        366,
        370,
        1858,
        281,
        722,
        1953,
        466,
        1553,
        1419,
        886,
        709,
        3678,
        11,
        597,
        307,
        983,
        51232
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1507774879192484,
      "compression_ratio": 1.6753246753246753,
      "no_speech_prob": 0.0018164520151913166
    },
    {
      "id": 149,
      "seek": 95124,
      "start": 968.6,
      "end": 975.24,
      "text": " I think this is a very nice area to start working on at any level in your research career.",
      "tokens": [
        51232,
        286,
        519,
        341,
        307,
        257,
        588,
        1481,
        1859,
        281,
        722,
        1364,
        322,
        412,
        604,
        1496,
        294,
        428,
        2132,
        3988,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1507774879192484,
      "compression_ratio": 1.6753246753246753,
      "no_speech_prob": 0.0018164520151913166
    },
    {
      "id": 150,
      "seek": 97524,
      "start": 975.8,
      "end": 984.76,
      "text": " All right, so I'll take a break here and take questions if there are any. And then we will dive",
      "tokens": [
        50392,
        1057,
        558,
        11,
        370,
        286,
        603,
        747,
        257,
        1821,
        510,
        293,
        747,
        1651,
        498,
        456,
        366,
        604,
        13,
        400,
        550,
        321,
        486,
        9192,
        50840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13680085268887607,
      "compression_ratio": 1.6111111111111112,
      "no_speech_prob": 0.0008546765893697739
    },
    {
      "id": 151,
      "seek": 97524,
      "start": 984.76,
      "end": 989.96,
      "text": " into the token jumping and token sliding problems, what we know about them,",
      "tokens": [
        50840,
        666,
        264,
        14862,
        11233,
        293,
        14862,
        21169,
        2740,
        11,
        437,
        321,
        458,
        466,
        552,
        11,
        51100
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13680085268887607,
      "compression_ratio": 1.6111111111111112,
      "no_speech_prob": 0.0008546765893697739
    },
    {
      "id": 152,
      "seek": 97524,
      "start": 990.6800000000001,
      "end": 995.4,
      "text": " in terms of classical complexity, and what was basically the starting point for the project",
      "tokens": [
        51136,
        294,
        2115,
        295,
        13735,
        14024,
        11,
        293,
        437,
        390,
        1936,
        264,
        2891,
        935,
        337,
        264,
        1716,
        51372
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13680085268887607,
      "compression_ratio": 1.6111111111111112,
      "no_speech_prob": 0.0008546765893697739
    },
    {
      "id": 153,
      "seek": 97524,
      "start": 995.4,
      "end": 1001.88,
      "text": " that led us to this paper. Any questions at this point?",
      "tokens": [
        51372,
        300,
        4684,
        505,
        281,
        341,
        3035,
        13,
        2639,
        1651,
        412,
        341,
        935,
        30,
        51696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13680085268887607,
      "compression_ratio": 1.6111111111111112,
      "no_speech_prob": 0.0008546765893697739
    },
    {
      "id": 154,
      "seek": 100188,
      "start": 1002.84,
      "end": 1010.68,
      "text": " I apologize for the small context which I am interrupting here. So this is just to announce",
      "tokens": [
        50412,
        286,
        12328,
        337,
        264,
        1359,
        4319,
        597,
        286,
        669,
        49455,
        510,
        13,
        407,
        341,
        307,
        445,
        281,
        7478,
        50804
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2394135172774152,
      "compression_ratio": 1.5714285714285714,
      "no_speech_prob": 0.0009521102765575051
    },
    {
      "id": 155,
      "seek": 100188,
      "start": 1010.68,
      "end": 1016.6,
      "text": " for the PC 301 workshop that will be happening in December end. And this will be slightly different",
      "tokens": [
        50804,
        337,
        264,
        6465,
        2217,
        16,
        13541,
        300,
        486,
        312,
        2737,
        294,
        7687,
        917,
        13,
        400,
        341,
        486,
        312,
        4748,
        819,
        51100
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2394135172774152,
      "compression_ratio": 1.5714285714285714,
      "no_speech_prob": 0.0009521102765575051
    },
    {
      "id": 156,
      "seek": 100188,
      "start": 1016.6,
      "end": 1021.88,
      "text": " from the previous two workshops. First major difference, this will be online. Second is",
      "tokens": [
        51100,
        490,
        264,
        3894,
        732,
        19162,
        13,
        2386,
        2563,
        2649,
        11,
        341,
        486,
        312,
        2950,
        13,
        5736,
        307,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2394135172774152,
      "compression_ratio": 1.5714285714285714,
      "no_speech_prob": 0.0009521102765575051
    },
    {
      "id": 157,
      "seek": 100188,
      "start": 1022.36,
      "end": 1030.36,
      "text": " some advanced topics will be discussed. So anyone who intends to explore somewhat more complex",
      "tokens": [
        51388,
        512,
        7339,
        8378,
        486,
        312,
        7152,
        13,
        407,
        2878,
        567,
        560,
        2581,
        281,
        6839,
        8344,
        544,
        3997,
        51788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2394135172774152,
      "compression_ratio": 1.5714285714285714,
      "no_speech_prob": 0.0009521102765575051
    },
    {
      "id": 158,
      "seek": 103036,
      "start": 1030.76,
      "end": 1037.24,
      "text": " topics in parameterized algorithms is invited to have a check. They can look at the website that",
      "tokens": [
        50384,
        8378,
        294,
        13075,
        1602,
        14642,
        307,
        9185,
        281,
        362,
        257,
        1520,
        13,
        814,
        393,
        574,
        412,
        264,
        3144,
        300,
        50708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28904681486241957,
      "compression_ratio": 1.5570776255707763,
      "no_speech_prob": 0.0021583593916147947
    },
    {
      "id": 159,
      "seek": 103036,
      "start": 1037.24,
      "end": 1042.52,
      "text": " has been shared on the chat. And if you wish, you can register simply by filling a form that is",
      "tokens": [
        50708,
        575,
        668,
        5507,
        322,
        264,
        5081,
        13,
        400,
        498,
        291,
        3172,
        11,
        291,
        393,
        7280,
        2935,
        538,
        10623,
        257,
        1254,
        300,
        307,
        50972
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28904681486241957,
      "compression_ratio": 1.5570776255707763,
      "no_speech_prob": 0.0021583593916147947
    },
    {
      "id": 160,
      "seek": 103036,
      "start": 1043.1599999999999,
      "end": 1049.32,
      "text": " linked at the bottom of the webpage. So just to inform you all about it and sorry for the",
      "tokens": [
        51004,
        9408,
        412,
        264,
        2767,
        295,
        264,
        37852,
        13,
        407,
        445,
        281,
        1356,
        291,
        439,
        466,
        309,
        293,
        2597,
        337,
        264,
        51312
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28904681486241957,
      "compression_ratio": 1.5570776255707763,
      "no_speech_prob": 0.0021583593916147947
    },
    {
      "id": 161,
      "seek": 103036,
      "start": 1049.32,
      "end": 1053.9599999999998,
      "text": " interruption professor. Now you can come to us. All right.",
      "tokens": [
        51312,
        728,
        11266,
        8304,
        13,
        823,
        291,
        393,
        808,
        281,
        505,
        13,
        1057,
        558,
        13,
        51544
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28904681486241957,
      "compression_ratio": 1.5570776255707763,
      "no_speech_prob": 0.0021583593916147947
    },
    {
      "id": 162,
      "seek": 105396,
      "start": 1054.68,
      "end": 1063.8,
      "text": " All right. So let's start talking about token jumping, token sliding, and a little bit about",
      "tokens": [
        50400,
        1057,
        558,
        13,
        407,
        718,
        311,
        722,
        1417,
        466,
        14862,
        11233,
        11,
        14862,
        21169,
        11,
        293,
        257,
        707,
        857,
        466,
        50856
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1111561490088394,
      "compression_ratio": 1.6085106382978724,
      "no_speech_prob": 0.0023386036045849323
    },
    {
      "id": 163,
      "seek": 105396,
      "start": 1065.08,
      "end": 1070.28,
      "text": " classical complexity. I know everybody here knows about P and NP. So I'm not going to talk about",
      "tokens": [
        50920,
        13735,
        14024,
        13,
        286,
        458,
        2201,
        510,
        3255,
        466,
        430,
        293,
        38611,
        13,
        407,
        286,
        478,
        406,
        516,
        281,
        751,
        466,
        51180
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1111561490088394,
      "compression_ratio": 1.6085106382978724,
      "no_speech_prob": 0.0023386036045849323
    },
    {
      "id": 164,
      "seek": 105396,
      "start": 1070.28,
      "end": 1076.3600000000001,
      "text": " this. Some of you might not be familiar with the PSPACE class. So just a quick note that's as much",
      "tokens": [
        51180,
        341,
        13,
        2188,
        295,
        291,
        1062,
        406,
        312,
        4963,
        365,
        264,
        8168,
        47,
        23866,
        1508,
        13,
        407,
        445,
        257,
        1702,
        3637,
        300,
        311,
        382,
        709,
        51484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1111561490088394,
      "compression_ratio": 1.6085106382978724,
      "no_speech_prob": 0.0023386036045849323
    },
    {
      "id": 165,
      "seek": 105396,
      "start": 1076.3600000000001,
      "end": 1081.96,
      "text": " as you will need to know for this talk is that PSPACE is the set of all decision problems",
      "tokens": [
        51484,
        382,
        291,
        486,
        643,
        281,
        458,
        337,
        341,
        751,
        307,
        300,
        8168,
        47,
        23866,
        307,
        264,
        992,
        295,
        439,
        3537,
        2740,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1111561490088394,
      "compression_ratio": 1.6085106382978724,
      "no_speech_prob": 0.0023386036045849323
    },
    {
      "id": 166,
      "seek": 108196,
      "start": 1082.6000000000001,
      "end": 1088.68,
      "text": " that can be solved using a polynomial amount of space. And the reason why I mentioned this class",
      "tokens": [
        50396,
        300,
        393,
        312,
        13041,
        1228,
        257,
        26110,
        2372,
        295,
        1901,
        13,
        400,
        264,
        1778,
        983,
        286,
        2835,
        341,
        1508,
        50700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10002391603257921,
      "compression_ratio": 1.5707964601769913,
      "no_speech_prob": 0.00039128484786488116
    },
    {
      "id": 167,
      "seek": 108196,
      "start": 1088.68,
      "end": 1095.24,
      "text": " is because many, many, many, many reconfiguration problems actually are PSPACE complete.",
      "tokens": [
        50700,
        307,
        570,
        867,
        11,
        867,
        11,
        867,
        11,
        867,
        9993,
        20646,
        8167,
        2740,
        767,
        366,
        8168,
        47,
        23866,
        3566,
        13,
        51028
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10002391603257921,
      "compression_ratio": 1.5707964601769913,
      "no_speech_prob": 0.00039128484786488116
    },
    {
      "id": 168,
      "seek": 108196,
      "start": 1096.1200000000001,
      "end": 1102.44,
      "text": " Okay. And so what we know, the standard inclusion is we know that P is contained in NP,",
      "tokens": [
        51072,
        1033,
        13,
        400,
        370,
        437,
        321,
        458,
        11,
        264,
        3832,
        15874,
        307,
        321,
        458,
        300,
        430,
        307,
        16212,
        294,
        38611,
        11,
        51388
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10002391603257921,
      "compression_ratio": 1.5707964601769913,
      "no_speech_prob": 0.00039128484786488116
    },
    {
      "id": 169,
      "seek": 108196,
      "start": 1102.44,
      "end": 1107.56,
      "text": " which is contained in PSPACE. But a very useful thing about PSPACE is that Savage",
      "tokens": [
        51388,
        597,
        307,
        16212,
        294,
        8168,
        47,
        23866,
        13,
        583,
        257,
        588,
        4420,
        551,
        466,
        8168,
        47,
        23866,
        307,
        300,
        46699,
        51644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10002391603257921,
      "compression_ratio": 1.5707964601769913,
      "no_speech_prob": 0.00039128484786488116
    },
    {
      "id": 170,
      "seek": 110756,
      "start": 1107.56,
      "end": 1113.48,
      "text": " proved that it's equal to NP SPACE. So polynomial space and non-deterministic",
      "tokens": [
        50364,
        14617,
        300,
        309,
        311,
        2681,
        281,
        38611,
        8420,
        23866,
        13,
        407,
        26110,
        1901,
        293,
        2107,
        12,
        49136,
        259,
        3142,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12500603993733725,
      "compression_ratio": 1.6863636363636363,
      "no_speech_prob": 0.00034621634404174984
    },
    {
      "id": 171,
      "seek": 110756,
      "start": 1113.48,
      "end": 1120.84,
      "text": " polynomial space are the same class, basically. And that's extremely useful when you start to think",
      "tokens": [
        50660,
        26110,
        1901,
        366,
        264,
        912,
        1508,
        11,
        1936,
        13,
        400,
        300,
        311,
        4664,
        4420,
        562,
        291,
        722,
        281,
        519,
        51028
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12500603993733725,
      "compression_ratio": 1.6863636363636363,
      "no_speech_prob": 0.00034621634404174984
    },
    {
      "id": 172,
      "seek": 110756,
      "start": 1120.84,
      "end": 1124.6799999999998,
      "text": " about reconfiguration problems. Because if you think about a reconfiguration problem where you're",
      "tokens": [
        51028,
        466,
        9993,
        20646,
        8167,
        2740,
        13,
        1436,
        498,
        291,
        519,
        466,
        257,
        9993,
        20646,
        8167,
        1154,
        689,
        291,
        434,
        51220
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12500603993733725,
      "compression_ratio": 1.6863636363636363,
      "no_speech_prob": 0.00034621634404174984
    },
    {
      "id": 173,
      "seek": 110756,
      "start": 1124.6799999999998,
      "end": 1132.44,
      "text": " given some state and you want to reach the other one. So basically you can solve that easily in",
      "tokens": [
        51220,
        2212,
        512,
        1785,
        293,
        291,
        528,
        281,
        2524,
        264,
        661,
        472,
        13,
        407,
        1936,
        291,
        393,
        5039,
        300,
        3612,
        294,
        51608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12500603993733725,
      "compression_ratio": 1.6863636363636363,
      "no_speech_prob": 0.00034621634404174984
    },
    {
      "id": 174,
      "seek": 113244,
      "start": 1132.44,
      "end": 1138.92,
      "text": " non-deterministic polynomial space, which basically implies that they are in PSPACE.",
      "tokens": [
        50364,
        2107,
        12,
        49136,
        259,
        3142,
        26110,
        1901,
        11,
        597,
        1936,
        18779,
        300,
        436,
        366,
        294,
        8168,
        47,
        23866,
        13,
        50688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08598972956339518,
      "compression_ratio": 1.7619047619047619,
      "no_speech_prob": 0.00081936817150563
    },
    {
      "id": 175,
      "seek": 113244,
      "start": 1140.8400000000001,
      "end": 1146.3600000000001,
      "text": " But actually you can show a lot more than that. You can show that many, really many reconfiguration",
      "tokens": [
        50784,
        583,
        767,
        291,
        393,
        855,
        257,
        688,
        544,
        813,
        300,
        13,
        509,
        393,
        855,
        300,
        867,
        11,
        534,
        867,
        9993,
        20646,
        8167,
        51060
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08598972956339518,
      "compression_ratio": 1.7619047619047619,
      "no_speech_prob": 0.00081936817150563
    },
    {
      "id": 176,
      "seek": 113244,
      "start": 1146.3600000000001,
      "end": 1152.28,
      "text": " problems are actually PSPACE complete, which is not surprising. The fact that many of these",
      "tokens": [
        51060,
        2740,
        366,
        767,
        8168,
        47,
        23866,
        3566,
        11,
        597,
        307,
        406,
        8830,
        13,
        440,
        1186,
        300,
        867,
        295,
        613,
        51356
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08598972956339518,
      "compression_ratio": 1.7619047619047619,
      "no_speech_prob": 0.00081936817150563
    },
    {
      "id": 177,
      "seek": 113244,
      "start": 1152.28,
      "end": 1161.48,
      "text": " reconfiguration problems are PSPACE complete is not very surprising. And them not being in NP",
      "tokens": [
        51356,
        9993,
        20646,
        8167,
        2740,
        366,
        8168,
        47,
        23866,
        3566,
        307,
        406,
        588,
        8830,
        13,
        400,
        552,
        406,
        885,
        294,
        38611,
        51816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08598972956339518,
      "compression_ratio": 1.7619047619047619,
      "no_speech_prob": 0.00081936817150563
    },
    {
      "id": 178,
      "seek": 116148,
      "start": 1161.48,
      "end": 1166.52,
      "text": " is because they don't always have polynomial size certificates, which also makes sense. Because",
      "tokens": [
        50364,
        307,
        570,
        436,
        500,
        380,
        1009,
        362,
        26110,
        2744,
        32941,
        11,
        597,
        611,
        1669,
        2020,
        13,
        1436,
        50616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06423808560513034,
      "compression_ratio": 1.6317689530685922,
      "no_speech_prob": 0.0002430010645184666
    },
    {
      "id": 179,
      "seek": 116148,
      "start": 1166.52,
      "end": 1171.8,
      "text": " sometimes the number of steps that you need to take to go from one configuration to the other",
      "tokens": [
        50616,
        2171,
        264,
        1230,
        295,
        4439,
        300,
        291,
        643,
        281,
        747,
        281,
        352,
        490,
        472,
        11694,
        281,
        264,
        661,
        50880
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06423808560513034,
      "compression_ratio": 1.6317689530685922,
      "no_speech_prob": 0.0002430010645184666
    },
    {
      "id": 180,
      "seek": 116148,
      "start": 1171.8,
      "end": 1178.1200000000001,
      "text": " might very well be exponential in the graph size. But there are also some extremely surprising",
      "tokens": [
        50880,
        1062,
        588,
        731,
        312,
        21510,
        294,
        264,
        4295,
        2744,
        13,
        583,
        456,
        366,
        611,
        512,
        4664,
        8830,
        51196
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06423808560513034,
      "compression_ratio": 1.6317689530685922,
      "no_speech_prob": 0.0002430010645184666
    },
    {
      "id": 181,
      "seek": 116148,
      "start": 1178.1200000000001,
      "end": 1182.84,
      "text": " results. And these are some of the results, some of my favorite results in the area.",
      "tokens": [
        51196,
        3542,
        13,
        400,
        613,
        366,
        512,
        295,
        264,
        3542,
        11,
        512,
        295,
        452,
        2954,
        3542,
        294,
        264,
        1859,
        13,
        51432
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06423808560513034,
      "compression_ratio": 1.6317689530685922,
      "no_speech_prob": 0.0002430010645184666
    },
    {
      "id": 182,
      "seek": 116148,
      "start": 1183.88,
      "end": 1189.56,
      "text": " So for example, you all know that coloring is NP complete even for K equals three.",
      "tokens": [
        51484,
        407,
        337,
        1365,
        11,
        291,
        439,
        458,
        300,
        23198,
        307,
        38611,
        3566,
        754,
        337,
        591,
        6915,
        1045,
        13,
        51768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06423808560513034,
      "compression_ratio": 1.6317689530685922,
      "no_speech_prob": 0.0002430010645184666
    },
    {
      "id": 183,
      "seek": 118956,
      "start": 1190.36,
      "end": 1196.6799999999998,
      "text": " However, it turns out that if you try to solve the recoloring problem for K equals three,",
      "tokens": [
        50404,
        2908,
        11,
        309,
        4523,
        484,
        300,
        498,
        291,
        853,
        281,
        5039,
        264,
        850,
        401,
        3662,
        1154,
        337,
        591,
        6915,
        1045,
        11,
        50720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09964988629023235,
      "compression_ratio": 1.7476635514018692,
      "no_speech_prob": 0.00028694875072687864
    },
    {
      "id": 184,
      "seek": 118956,
      "start": 1197.32,
      "end": 1203.3999999999999,
      "text": " it's actually polynomial time solvable. So if I give you two, three colorings of a graph and I ask you,",
      "tokens": [
        50752,
        309,
        311,
        767,
        26110,
        565,
        1404,
        17915,
        13,
        407,
        498,
        286,
        976,
        291,
        732,
        11,
        1045,
        2017,
        1109,
        295,
        257,
        4295,
        293,
        286,
        1029,
        291,
        11,
        51056
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09964988629023235,
      "compression_ratio": 1.7476635514018692,
      "no_speech_prob": 0.00028694875072687864
    },
    {
      "id": 185,
      "seek": 118956,
      "start": 1204.04,
      "end": 1210.9199999999998,
      "text": " is there a path between them that recolors one vertex at a time and is always a valid three",
      "tokens": [
        51088,
        307,
        456,
        257,
        3100,
        1296,
        552,
        300,
        850,
        401,
        830,
        472,
        28162,
        412,
        257,
        565,
        293,
        307,
        1009,
        257,
        7363,
        1045,
        51432
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09964988629023235,
      "compression_ratio": 1.7476635514018692,
      "no_speech_prob": 0.00028694875072687864
    },
    {
      "id": 186,
      "seek": 118956,
      "start": 1210.9199999999998,
      "end": 1216.36,
      "text": " coloring, then this problem can be solved in polynomial time. And the recoloring problem",
      "tokens": [
        51432,
        23198,
        11,
        550,
        341,
        1154,
        393,
        312,
        13041,
        294,
        26110,
        565,
        13,
        400,
        264,
        850,
        401,
        3662,
        1154,
        51704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09964988629023235,
      "compression_ratio": 1.7476635514018692,
      "no_speech_prob": 0.00028694875072687864
    },
    {
      "id": 187,
      "seek": 121636,
      "start": 1216.36,
      "end": 1219.56,
      "text": " only becomes PSPACE complete for K equal four and more.",
      "tokens": [
        50364,
        787,
        3643,
        8168,
        47,
        23866,
        3566,
        337,
        591,
        2681,
        1451,
        293,
        544,
        13,
        50524
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09342228111467864,
      "compression_ratio": 1.4951923076923077,
      "no_speech_prob": 0.00036785678821615875
    },
    {
      "id": 188,
      "seek": 121636,
      "start": 1221.9599999999998,
      "end": 1227.6399999999999,
      "text": " Right. So that's the first surprising result. Another very surprising result is that",
      "tokens": [
        50644,
        1779,
        13,
        407,
        300,
        311,
        264,
        700,
        8830,
        1874,
        13,
        3996,
        588,
        8830,
        1874,
        307,
        300,
        50928
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09342228111467864,
      "compression_ratio": 1.4951923076923077,
      "no_speech_prob": 0.00036785678821615875
    },
    {
      "id": 189,
      "seek": 121636,
      "start": 1228.52,
      "end": 1234.84,
      "text": " as your old FPT experts here, I know that you're all familiar with the fact that usually",
      "tokens": [
        50972,
        382,
        428,
        1331,
        36655,
        51,
        8572,
        510,
        11,
        286,
        458,
        300,
        291,
        434,
        439,
        4963,
        365,
        264,
        1186,
        300,
        2673,
        51288
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09342228111467864,
      "compression_ratio": 1.4951923076923077,
      "no_speech_prob": 0.00036785678821615875
    },
    {
      "id": 190,
      "seek": 121636,
      "start": 1234.84,
      "end": 1239.0,
      "text": " when we study problems on graphs of bounded bucket width, path width, tree width,",
      "tokens": [
        51288,
        562,
        321,
        2979,
        2740,
        322,
        24877,
        295,
        37498,
        13058,
        11402,
        11,
        3100,
        11402,
        11,
        4230,
        11402,
        11,
        51496
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09342228111467864,
      "compression_ratio": 1.4951923076923077,
      "no_speech_prob": 0.00036785678821615875
    },
    {
      "id": 191,
      "seek": 123900,
      "start": 1239.72,
      "end": 1247.8,
      "text": " they tend to become easier. It turns out that that's not really the case for reconfiguration",
      "tokens": [
        50400,
        436,
        3928,
        281,
        1813,
        3571,
        13,
        467,
        4523,
        484,
        300,
        300,
        311,
        406,
        534,
        264,
        1389,
        337,
        9993,
        20646,
        8167,
        50804
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06924825364893133,
      "compression_ratio": 1.6486486486486487,
      "no_speech_prob": 0.0005896866205148399
    },
    {
      "id": 192,
      "seek": 123900,
      "start": 1247.8,
      "end": 1252.2,
      "text": " problems, at least for token sliding and jumping, which is the two problems that are related to",
      "tokens": [
        50804,
        2740,
        11,
        412,
        1935,
        337,
        14862,
        21169,
        293,
        11233,
        11,
        597,
        307,
        264,
        732,
        2740,
        300,
        366,
        4077,
        281,
        51024
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06924825364893133,
      "compression_ratio": 1.6486486486486487,
      "no_speech_prob": 0.0005896866205148399
    },
    {
      "id": 193,
      "seek": 123900,
      "start": 1252.2,
      "end": 1258.04,
      "text": " independent set. It turns out that those two problems remain PSPACE complete even if you",
      "tokens": [
        51024,
        6695,
        992,
        13,
        467,
        4523,
        484,
        300,
        729,
        732,
        2740,
        6222,
        8168,
        47,
        23866,
        3566,
        754,
        498,
        291,
        51316
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06924825364893133,
      "compression_ratio": 1.6486486486486487,
      "no_speech_prob": 0.0005896866205148399
    },
    {
      "id": 194,
      "seek": 123900,
      "start": 1258.04,
      "end": 1263.72,
      "text": " have a graph of constant tree width or path width or even bucket width. So a very, very,",
      "tokens": [
        51316,
        362,
        257,
        4295,
        295,
        5754,
        4230,
        11402,
        420,
        3100,
        11402,
        420,
        754,
        13058,
        11402,
        13,
        407,
        257,
        588,
        11,
        588,
        11,
        51600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06924825364893133,
      "compression_ratio": 1.6486486486486487,
      "no_speech_prob": 0.0005896866205148399
    },
    {
      "id": 195,
      "seek": 126372,
      "start": 1263.72,
      "end": 1268.68,
      "text": " very simple graph structure. Still the problem remains hard.",
      "tokens": [
        50364,
        588,
        2199,
        4295,
        3877,
        13,
        8291,
        264,
        1154,
        7023,
        1152,
        13,
        50612
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11743372839850348,
      "compression_ratio": 1.5348837209302326,
      "no_speech_prob": 0.0003514776472002268
    },
    {
      "id": 196,
      "seek": 126372,
      "start": 1271.16,
      "end": 1279.16,
      "text": " All right. And finally, the last theorem that I also like a lot shows you basically that sliding",
      "tokens": [
        50736,
        1057,
        558,
        13,
        400,
        2721,
        11,
        264,
        1036,
        20904,
        300,
        286,
        611,
        411,
        257,
        688,
        3110,
        291,
        1936,
        300,
        21169,
        51136
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11743372839850348,
      "compression_ratio": 1.5348837209302326,
      "no_speech_prob": 0.0003514776472002268
    },
    {
      "id": 197,
      "seek": 126372,
      "start": 1279.16,
      "end": 1287.56,
      "text": " and jumping behave differently. And it was shown that if you restrict yourself to bipartite graphs,",
      "tokens": [
        51136,
        293,
        11233,
        15158,
        7614,
        13,
        400,
        309,
        390,
        4898,
        300,
        498,
        291,
        7694,
        1803,
        281,
        28741,
        642,
        24877,
        11,
        51556
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11743372839850348,
      "compression_ratio": 1.5348837209302326,
      "no_speech_prob": 0.0003514776472002268
    },
    {
      "id": 198,
      "seek": 126372,
      "start": 1287.56,
      "end": 1291.4,
      "text": " where we know that max independent set can be solved in polynomial time,",
      "tokens": [
        51556,
        689,
        321,
        458,
        300,
        11469,
        6695,
        992,
        393,
        312,
        13041,
        294,
        26110,
        565,
        11,
        51748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11743372839850348,
      "compression_ratio": 1.5348837209302326,
      "no_speech_prob": 0.0003514776472002268
    },
    {
      "id": 199,
      "seek": 129140,
      "start": 1292.2800000000002,
      "end": 1296.0400000000002,
      "text": " if you restrict yourself to those graphs, it turns out that token jumping",
      "tokens": [
        50408,
        498,
        291,
        7694,
        1803,
        281,
        729,
        24877,
        11,
        309,
        4523,
        484,
        300,
        14862,
        11233,
        50596
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1086987058321635,
      "compression_ratio": 1.3945578231292517,
      "no_speech_prob": 0.00016218348173424602
    },
    {
      "id": 200,
      "seek": 129140,
      "start": 1297.4,
      "end": 1306.44,
      "text": " is NP complete, whereas token sliding is PSPACE complete, which is a strange",
      "tokens": [
        50664,
        307,
        38611,
        3566,
        11,
        9735,
        14862,
        21169,
        307,
        8168,
        47,
        23866,
        3566,
        11,
        597,
        307,
        257,
        5861,
        51116
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1086987058321635,
      "compression_ratio": 1.3945578231292517,
      "no_speech_prob": 0.00016218348173424602
    },
    {
      "id": 201,
      "seek": 129140,
      "start": 1308.44,
      "end": 1310.92,
      "text": " difference between the behavior of those two problems.",
      "tokens": [
        51216,
        2649,
        1296,
        264,
        5223,
        295,
        729,
        732,
        2740,
        13,
        51340
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1086987058321635,
      "compression_ratio": 1.3945578231292517,
      "no_speech_prob": 0.00016218348173424602
    },
    {
      "id": 202,
      "seek": 131092,
      "start": 1311.88,
      "end": 1322.52,
      "text": " All right. So in fact, we know a lot more about token sliding and token jumping. These",
      "tokens": [
        50412,
        1057,
        558,
        13,
        407,
        294,
        1186,
        11,
        321,
        458,
        257,
        688,
        544,
        466,
        14862,
        21169,
        293,
        14862,
        11233,
        13,
        1981,
        50944
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12887986046927316,
      "compression_ratio": 1.521505376344086,
      "no_speech_prob": 0.000345281237969175
    },
    {
      "id": 203,
      "seek": 131092,
      "start": 1323.16,
      "end": 1328.04,
      "text": " problems have been at the heart of the area of combinatorial reconfiguration. They have been",
      "tokens": [
        50976,
        2740,
        362,
        668,
        412,
        264,
        1917,
        295,
        264,
        1859,
        295,
        2512,
        31927,
        831,
        9993,
        20646,
        8167,
        13,
        814,
        362,
        668,
        51220
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12887986046927316,
      "compression_ratio": 1.521505376344086,
      "no_speech_prob": 0.000345281237969175
    },
    {
      "id": 204,
      "seek": 131092,
      "start": 1328.04,
      "end": 1335.72,
      "text": " studied so much. And we know so much about them, at least in terms of standard or classical complexity.",
      "tokens": [
        51220,
        9454,
        370,
        709,
        13,
        400,
        321,
        458,
        370,
        709,
        466,
        552,
        11,
        412,
        1935,
        294,
        2115,
        295,
        3832,
        420,
        13735,
        14024,
        13,
        51604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12887986046927316,
      "compression_ratio": 1.521505376344086,
      "no_speech_prob": 0.000345281237969175
    },
    {
      "id": 205,
      "seek": 133572,
      "start": 1335.72,
      "end": 1342.2,
      "text": " So some of the important results for our paper that we're going to focus on",
      "tokens": [
        50364,
        407,
        512,
        295,
        264,
        1021,
        3542,
        337,
        527,
        3035,
        300,
        321,
        434,
        516,
        281,
        1879,
        322,
        50688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11484303928556897,
      "compression_ratio": 1.669811320754717,
      "no_speech_prob": 0.00022577386698685586
    },
    {
      "id": 206,
      "seek": 133572,
      "start": 1343.88,
      "end": 1350.52,
      "text": " is this result. So that's going to be the starting point of the results that we will discuss next",
      "tokens": [
        50772,
        307,
        341,
        1874,
        13,
        407,
        300,
        311,
        516,
        281,
        312,
        264,
        2891,
        935,
        295,
        264,
        3542,
        300,
        321,
        486,
        2248,
        958,
        51104
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11484303928556897,
      "compression_ratio": 1.669811320754717,
      "no_speech_prob": 0.00022577386698685586
    },
    {
      "id": 207,
      "seek": 133572,
      "start": 1350.52,
      "end": 1355.16,
      "text": " when we move to parametrize complexity. So the fact that token sliding and token jumping,",
      "tokens": [
        51104,
        562,
        321,
        1286,
        281,
        6220,
        302,
        470,
        1381,
        14024,
        13,
        407,
        264,
        1186,
        300,
        14862,
        21169,
        293,
        14862,
        11233,
        11,
        51336
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11484303928556897,
      "compression_ratio": 1.669811320754717,
      "no_speech_prob": 0.00022577386698685586
    },
    {
      "id": 208,
      "seek": 133572,
      "start": 1356.68,
      "end": 1361.64,
      "text": " our PSPACE complete and then NP complete respectively on bipartite graphs was the starting",
      "tokens": [
        51412,
        527,
        8168,
        47,
        23866,
        3566,
        293,
        550,
        38611,
        3566,
        25009,
        322,
        28741,
        642,
        24877,
        390,
        264,
        2891,
        51660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11484303928556897,
      "compression_ratio": 1.669811320754717,
      "no_speech_prob": 0.00022577386698685586
    },
    {
      "id": 209,
      "seek": 136164,
      "start": 1361.64,
      "end": 1366.1200000000001,
      "text": " point of our next paper. But there are some very interesting results here that are also",
      "tokens": [
        50364,
        935,
        295,
        527,
        958,
        3035,
        13,
        583,
        456,
        366,
        512,
        588,
        1880,
        3542,
        510,
        300,
        366,
        611,
        50588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06818420931978046,
      "compression_ratio": 1.7575757575757576,
      "no_speech_prob": 0.003597786882892251
    },
    {
      "id": 210,
      "seek": 136164,
      "start": 1366.1200000000001,
      "end": 1371.64,
      "text": " worth mentioning. So for example, for even whole field graphs, we know how to solve token jumping",
      "tokens": [
        50588,
        3163,
        18315,
        13,
        407,
        337,
        1365,
        11,
        337,
        754,
        1379,
        2519,
        24877,
        11,
        321,
        458,
        577,
        281,
        5039,
        14862,
        11233,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06818420931978046,
      "compression_ratio": 1.7575757575757576,
      "no_speech_prob": 0.003597786882892251
    },
    {
      "id": 211,
      "seek": 136164,
      "start": 1371.64,
      "end": 1377.88,
      "text": " in polynomial time. But the complexity of independent set even remains open on this class",
      "tokens": [
        50864,
        294,
        26110,
        565,
        13,
        583,
        264,
        14024,
        295,
        6695,
        992,
        754,
        7023,
        1269,
        322,
        341,
        1508,
        51176
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06818420931978046,
      "compression_ratio": 1.7575757575757576,
      "no_speech_prob": 0.003597786882892251
    },
    {
      "id": 212,
      "seek": 136164,
      "start": 1377.88,
      "end": 1385.0,
      "text": " of graphs. And the complexity of token sliding also remains open. So we don't know how to check if",
      "tokens": [
        51176,
        295,
        24877,
        13,
        400,
        264,
        14024,
        295,
        14862,
        21169,
        611,
        7023,
        1269,
        13,
        407,
        321,
        500,
        380,
        458,
        577,
        281,
        1520,
        498,
        51532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06818420931978046,
      "compression_ratio": 1.7575757575757576,
      "no_speech_prob": 0.003597786882892251
    },
    {
      "id": 213,
      "seek": 136164,
      "start": 1385.0,
      "end": 1390.92,
      "text": " given two independent sets, I can slide one to the other. Can you answer that question in",
      "tokens": [
        51532,
        2212,
        732,
        6695,
        6352,
        11,
        286,
        393,
        4137,
        472,
        281,
        264,
        661,
        13,
        1664,
        291,
        1867,
        300,
        1168,
        294,
        51828
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06818420931978046,
      "compression_ratio": 1.7575757575757576,
      "no_speech_prob": 0.003597786882892251
    },
    {
      "id": 214,
      "seek": 139092,
      "start": 1390.92,
      "end": 1398.92,
      "text": " polynomial time for even whole free graphs? For split graphs and chordal graphs, they also behave",
      "tokens": [
        50364,
        26110,
        565,
        337,
        754,
        1379,
        1737,
        24877,
        30,
        1171,
        7472,
        24877,
        293,
        14137,
        304,
        24877,
        11,
        436,
        611,
        15158,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10262138502938407,
      "compression_ratio": 1.826086956521739,
      "no_speech_prob": 0.0001202281127916649
    },
    {
      "id": 215,
      "seek": 139092,
      "start": 1398.92,
      "end": 1405.0800000000002,
      "text": " extremely differently, token sliding and token jumping. So token sliding is PSPACE complete",
      "tokens": [
        50764,
        4664,
        7614,
        11,
        14862,
        21169,
        293,
        14862,
        11233,
        13,
        407,
        14862,
        21169,
        307,
        8168,
        47,
        23866,
        3566,
        51072
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10262138502938407,
      "compression_ratio": 1.826086956521739,
      "no_speech_prob": 0.0001202281127916649
    },
    {
      "id": 216,
      "seek": 139092,
      "start": 1405.0800000000002,
      "end": 1412.04,
      "text": " on split graphs and chordal graphs while token jumping is polynomial time. And that is some",
      "tokens": [
        51072,
        322,
        7472,
        24877,
        293,
        14137,
        304,
        24877,
        1339,
        14862,
        11233,
        307,
        26110,
        565,
        13,
        400,
        300,
        307,
        512,
        51420
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10262138502938407,
      "compression_ratio": 1.826086956521739,
      "no_speech_prob": 0.0001202281127916649
    },
    {
      "id": 217,
      "seek": 139092,
      "start": 1412.04,
      "end": 1418.68,
      "text": " of the reasons why we feel that token sliding is harder usually than token jumping. But it's not",
      "tokens": [
        51420,
        295,
        264,
        4112,
        983,
        321,
        841,
        300,
        14862,
        21169,
        307,
        6081,
        2673,
        813,
        14862,
        11233,
        13,
        583,
        309,
        311,
        406,
        51752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10262138502938407,
      "compression_ratio": 1.826086956521739,
      "no_speech_prob": 0.0001202281127916649
    },
    {
      "id": 218,
      "seek": 141868,
      "start": 1418.76,
      "end": 1432.1200000000001,
      "text": " always the case. All right. So that's it for classical complexity. So now let's move on to",
      "tokens": [
        50368,
        1009,
        264,
        1389,
        13,
        1057,
        558,
        13,
        407,
        300,
        311,
        309,
        337,
        13735,
        14024,
        13,
        407,
        586,
        718,
        311,
        1286,
        322,
        281,
        51036
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08760202794835187,
      "compression_ratio": 1.5593220338983051,
      "no_speech_prob": 0.0002959815028589219
    },
    {
      "id": 219,
      "seek": 141868,
      "start": 1432.1200000000001,
      "end": 1437.96,
      "text": " parametrize complexity. And let's basically think about how you can parametrize those two",
      "tokens": [
        51036,
        6220,
        302,
        470,
        1381,
        14024,
        13,
        400,
        718,
        311,
        1936,
        519,
        466,
        577,
        291,
        393,
        6220,
        302,
        470,
        1381,
        729,
        732,
        51328
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08760202794835187,
      "compression_ratio": 1.5593220338983051,
      "no_speech_prob": 0.0002959815028589219
    },
    {
      "id": 220,
      "seek": 141868,
      "start": 1437.96,
      "end": 1444.6000000000001,
      "text": " problems, token jumping and token sliding. So there's the obvious parameter would be the number",
      "tokens": [
        51328,
        2740,
        11,
        14862,
        11233,
        293,
        14862,
        21169,
        13,
        407,
        456,
        311,
        264,
        6322,
        13075,
        576,
        312,
        264,
        1230,
        51660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08760202794835187,
      "compression_ratio": 1.5593220338983051,
      "no_speech_prob": 0.0002959815028589219
    },
    {
      "id": 221,
      "seek": 144460,
      "start": 1444.6,
      "end": 1451.08,
      "text": " of tokens. Right. So one of the obvious parameters would be the number of tokens. So and we're going",
      "tokens": [
        50364,
        295,
        22667,
        13,
        1779,
        13,
        407,
        472,
        295,
        264,
        6322,
        9834,
        576,
        312,
        264,
        1230,
        295,
        22667,
        13,
        407,
        293,
        321,
        434,
        516,
        50688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09881699210719058,
      "compression_ratio": 1.6359832635983265,
      "no_speech_prob": 0.0021148305386304855
    },
    {
      "id": 222,
      "seek": 144460,
      "start": 1451.08,
      "end": 1456.6,
      "text": " to denote that by K. Another parameter would be the length of the sequence, like how many steps",
      "tokens": [
        50688,
        281,
        45708,
        300,
        538,
        591,
        13,
        3996,
        13075,
        576,
        312,
        264,
        4641,
        295,
        264,
        8310,
        11,
        411,
        577,
        867,
        4439,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09881699210719058,
      "compression_ratio": 1.6359832635983265,
      "no_speech_prob": 0.0021148305386304855
    },
    {
      "id": 223,
      "seek": 144460,
      "start": 1456.6,
      "end": 1462.52,
      "text": " does it take to go from one independent set to the other? You can also obviously parametrize",
      "tokens": [
        50964,
        775,
        309,
        747,
        281,
        352,
        490,
        472,
        6695,
        992,
        281,
        264,
        661,
        30,
        509,
        393,
        611,
        2745,
        6220,
        302,
        470,
        1381,
        51260
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09881699210719058,
      "compression_ratio": 1.6359832635983265,
      "no_speech_prob": 0.0021148305386304855
    },
    {
      "id": 224,
      "seek": 144460,
      "start": 1462.52,
      "end": 1468.9199999999998,
      "text": " by tree width or path width or any combination of the above. When we started working on this problem,",
      "tokens": [
        51260,
        538,
        4230,
        11402,
        420,
        3100,
        11402,
        420,
        604,
        6562,
        295,
        264,
        3673,
        13,
        1133,
        321,
        1409,
        1364,
        322,
        341,
        1154,
        11,
        51580
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09881699210719058,
      "compression_ratio": 1.6359832635983265,
      "no_speech_prob": 0.0021148305386304855
    },
    {
      "id": 225,
      "seek": 146892,
      "start": 1469.5600000000002,
      "end": 1475.96,
      "text": " our initial aim was to basically study the parametrized complexity of token sliding and token",
      "tokens": [
        50396,
        527,
        5883,
        5939,
        390,
        281,
        1936,
        2979,
        264,
        6220,
        302,
        470,
        11312,
        14024,
        295,
        14862,
        21169,
        293,
        14862,
        50716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22835371711037375,
      "compression_ratio": 1.695067264573991,
      "no_speech_prob": 0.0006213475717231631
    },
    {
      "id": 226,
      "seek": 146892,
      "start": 1475.96,
      "end": 1483.5600000000002,
      "text": " jumping on bipartite graphs using the parameter K number of tokens. Right. Because remember,",
      "tokens": [
        50716,
        11233,
        322,
        28741,
        642,
        24877,
        1228,
        264,
        13075,
        591,
        1230,
        295,
        22667,
        13,
        1779,
        13,
        1436,
        1604,
        11,
        51096
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22835371711037375,
      "compression_ratio": 1.695067264573991,
      "no_speech_prob": 0.0006213475717231631
    },
    {
      "id": 227,
      "seek": 146892,
      "start": 1483.5600000000002,
      "end": 1489.3200000000002,
      "text": " we saw that token sliding is PSPACE complete on bipartite graphs and token jumping is NP-com.",
      "tokens": [
        51096,
        321,
        1866,
        300,
        14862,
        21169,
        307,
        8168,
        47,
        23866,
        3566,
        322,
        28741,
        642,
        24877,
        293,
        14862,
        11233,
        307,
        38611,
        12,
        1112,
        13,
        51384
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22835371711037375,
      "compression_ratio": 1.695067264573991,
      "no_speech_prob": 0.0006213475717231631
    },
    {
      "id": 228,
      "seek": 146892,
      "start": 1490.2,
      "end": 1496.3600000000001,
      "text": " So you were interested to see if basically this is going to give us W1 hardness for token sliding",
      "tokens": [
        51428,
        407,
        291,
        645,
        3102,
        281,
        536,
        498,
        1936,
        341,
        307,
        516,
        281,
        976,
        505,
        343,
        16,
        44019,
        337,
        14862,
        21169,
        51736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22835371711037375,
      "compression_ratio": 1.695067264573991,
      "no_speech_prob": 0.0006213475717231631
    },
    {
      "id": 229,
      "seek": 149636,
      "start": 1497.24,
      "end": 1504.76,
      "text": " and FPTNES for token jumping. Or at least that was the initial hope. That's why we started working",
      "tokens": [
        50408,
        293,
        36655,
        51,
        45,
        2358,
        337,
        14862,
        11233,
        13,
        1610,
        412,
        1935,
        300,
        390,
        264,
        5883,
        1454,
        13,
        663,
        311,
        983,
        321,
        1409,
        1364,
        50784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12758285120913856,
      "compression_ratio": 1.5502645502645502,
      "no_speech_prob": 0.0005319630727171898
    },
    {
      "id": 230,
      "seek": 149636,
      "start": 1504.76,
      "end": 1511.3999999999999,
      "text": " on this project. We weren't able to answer the two questions. So we were able to answer one side",
      "tokens": [
        50784,
        322,
        341,
        1716,
        13,
        492,
        4999,
        380,
        1075,
        281,
        1867,
        264,
        732,
        1651,
        13,
        407,
        321,
        645,
        1075,
        281,
        1867,
        472,
        1252,
        51116
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12758285120913856,
      "compression_ratio": 1.5502645502645502,
      "no_speech_prob": 0.0005319630727171898
    },
    {
      "id": 231,
      "seek": 149636,
      "start": 1511.3999999999999,
      "end": 1519.9599999999998,
      "text": " of the question, which is we were able to show that on bipartite graphs, token sliding is in fact",
      "tokens": [
        51116,
        295,
        264,
        1168,
        11,
        597,
        307,
        321,
        645,
        1075,
        281,
        855,
        300,
        322,
        28741,
        642,
        24877,
        11,
        14862,
        21169,
        307,
        294,
        1186,
        51544
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12758285120913856,
      "compression_ratio": 1.5502645502645502,
      "no_speech_prob": 0.0005319630727171898
    },
    {
      "id": 232,
      "seek": 151996,
      "start": 1519.96,
      "end": 1528.2,
      "text": " W1 hard. So token sliding parametrized by the number of tokens on bipartite graphs is W1 hard.",
      "tokens": [
        50364,
        343,
        16,
        1152,
        13,
        407,
        14862,
        21169,
        6220,
        302,
        470,
        11312,
        538,
        264,
        1230,
        295,
        22667,
        322,
        28741,
        642,
        24877,
        307,
        343,
        16,
        1152,
        13,
        50776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07441469863220886,
      "compression_ratio": 1.7168949771689497,
      "no_speech_prob": 0.0010937495389953256
    },
    {
      "id": 233,
      "seek": 151996,
      "start": 1528.76,
      "end": 1535.16,
      "text": " We were not able to answer the question for token jumping. So that is still an open question.",
      "tokens": [
        50804,
        492,
        645,
        406,
        1075,
        281,
        1867,
        264,
        1168,
        337,
        14862,
        11233,
        13,
        407,
        300,
        307,
        920,
        364,
        1269,
        1168,
        13,
        51124
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07441469863220886,
      "compression_ratio": 1.7168949771689497,
      "no_speech_prob": 0.0010937495389953256
    },
    {
      "id": 234,
      "seek": 151996,
      "start": 1537.08,
      "end": 1542.44,
      "text": " So we haven't answered that question and failed on the next question. We started thinking about",
      "tokens": [
        51220,
        407,
        321,
        2378,
        380,
        10103,
        300,
        1168,
        293,
        7612,
        322,
        264,
        958,
        1168,
        13,
        492,
        1409,
        1953,
        466,
        51488
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07441469863220886,
      "compression_ratio": 1.7168949771689497,
      "no_speech_prob": 0.0010937495389953256
    },
    {
      "id": 235,
      "seek": 151996,
      "start": 1542.44,
      "end": 1549.32,
      "text": " ways to basically simplify a little bit some of these questions. So the next thing we asked",
      "tokens": [
        51488,
        2098,
        281,
        1936,
        20460,
        257,
        707,
        857,
        512,
        295,
        613,
        1651,
        13,
        407,
        264,
        958,
        551,
        321,
        2351,
        51832
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07441469863220886,
      "compression_ratio": 1.7168949771689497,
      "no_speech_prob": 0.0010937495389953256
    },
    {
      "id": 236,
      "seek": 154932,
      "start": 1549.32,
      "end": 1556.36,
      "text": " ourselves, so there are two directions where you can try and simplify. So the next thing we asked",
      "tokens": [
        50364,
        4175,
        11,
        370,
        456,
        366,
        732,
        11095,
        689,
        291,
        393,
        853,
        293,
        20460,
        13,
        407,
        264,
        958,
        551,
        321,
        2351,
        50716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08629163343514969,
      "compression_ratio": 1.5080213903743316,
      "no_speech_prob": 0.0004167162987869233
    },
    {
      "id": 237,
      "seek": 154932,
      "start": 1556.36,
      "end": 1562.52,
      "text": " ourselves was, okay, so from bipartite graphs, how can I go to other classes of graphs",
      "tokens": [
        50716,
        4175,
        390,
        11,
        1392,
        11,
        370,
        490,
        28741,
        642,
        24877,
        11,
        577,
        393,
        286,
        352,
        281,
        661,
        5359,
        295,
        24877,
        51024
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08629163343514969,
      "compression_ratio": 1.5080213903743316,
      "no_speech_prob": 0.0004167162987869233
    },
    {
      "id": 238,
      "seek": 154932,
      "start": 1564.28,
      "end": 1571.24,
      "text": " and see where token jumping becomes hard or easy? And it turned out that if you basically exclude",
      "tokens": [
        51112,
        293,
        536,
        689,
        14862,
        11233,
        3643,
        1152,
        420,
        1858,
        30,
        400,
        309,
        3574,
        484,
        300,
        498,
        291,
        1936,
        33536,
        51460
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08629163343514969,
      "compression_ratio": 1.5080213903743316,
      "no_speech_prob": 0.0004167162987869233
    },
    {
      "id": 239,
      "seek": 157124,
      "start": 1571.24,
      "end": 1581.16,
      "text": " only C4 from your graph, right? And so because in bipartite graphs, you're excluding all odd cycles.",
      "tokens": [
        50364,
        787,
        383,
        19,
        490,
        428,
        4295,
        11,
        558,
        30,
        400,
        370,
        570,
        294,
        28741,
        642,
        24877,
        11,
        291,
        434,
        49999,
        439,
        7401,
        17796,
        13,
        50860
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1636403901236398,
      "compression_ratio": 1.5265957446808511,
      "no_speech_prob": 0.0016498543554916978
    },
    {
      "id": 240,
      "seek": 157124,
      "start": 1582.68,
      "end": 1588.6,
      "text": " Right? So we started thinking about what kinds of cycles affect the behavior of those problems.",
      "tokens": [
        50936,
        1779,
        30,
        407,
        321,
        1409,
        1953,
        466,
        437,
        3685,
        295,
        17796,
        3345,
        264,
        5223,
        295,
        729,
        2740,
        13,
        51232
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1636403901236398,
      "compression_ratio": 1.5265957446808511,
      "no_speech_prob": 0.0016498543554916978
    },
    {
      "id": 241,
      "seek": 157124,
      "start": 1589.4,
      "end": 1594.04,
      "text": " So the first question was, what about C4 free graphs? And it turned out that both problems",
      "tokens": [
        51272,
        407,
        264,
        700,
        1168,
        390,
        11,
        437,
        466,
        383,
        19,
        1737,
        24877,
        30,
        400,
        309,
        3574,
        484,
        300,
        1293,
        2740,
        51504
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1636403901236398,
      "compression_ratio": 1.5265957446808511,
      "no_speech_prob": 0.0016498543554916978
    },
    {
      "id": 242,
      "seek": 159404,
      "start": 1594.04,
      "end": 1603.56,
      "text": " remain W1 hard on C4 free graphs. Now, if you exclude C3 and C4, it turns out that token jumping",
      "tokens": [
        50364,
        6222,
        343,
        16,
        1152,
        322,
        383,
        19,
        1737,
        24877,
        13,
        823,
        11,
        498,
        291,
        33536,
        383,
        18,
        293,
        383,
        19,
        11,
        309,
        4523,
        484,
        300,
        14862,
        11233,
        50840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11973832845687866,
      "compression_ratio": 1.4328358208955223,
      "no_speech_prob": 0.0004474095767363906
    },
    {
      "id": 243,
      "seek": 159404,
      "start": 1603.56,
      "end": 1611.3999999999999,
      "text": " becomes FPD, has an order K squared kernel. But for token sliding, we were not able to determine the",
      "tokens": [
        50840,
        3643,
        479,
        17349,
        11,
        575,
        364,
        1668,
        591,
        8889,
        28256,
        13,
        583,
        337,
        14862,
        21169,
        11,
        321,
        645,
        406,
        1075,
        281,
        6997,
        264,
        51232
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11973832845687866,
      "compression_ratio": 1.4328358208955223,
      "no_speech_prob": 0.0004474095767363906
    },
    {
      "id": 244,
      "seek": 159404,
      "start": 1611.3999999999999,
      "end": 1620.6,
      "text": " complexity. Now, if you go to the other side of that, so what if we enforce both bipartite",
      "tokens": [
        51232,
        14024,
        13,
        823,
        11,
        498,
        291,
        352,
        281,
        264,
        661,
        1252,
        295,
        300,
        11,
        370,
        437,
        498,
        321,
        24825,
        1293,
        28741,
        642,
        51692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11973832845687866,
      "compression_ratio": 1.4328358208955223,
      "no_speech_prob": 0.0004474095767363906
    },
    {
      "id": 245,
      "seek": 162060,
      "start": 1621.1599999999999,
      "end": 1629.6399999999999,
      "text": " as well as C4 freeness? So in that case, we were able to show that both problems became FPD.",
      "tokens": [
        50392,
        382,
        731,
        382,
        383,
        19,
        1737,
        1287,
        30,
        407,
        294,
        300,
        1389,
        11,
        321,
        645,
        1075,
        281,
        855,
        300,
        1293,
        2740,
        3062,
        479,
        17349,
        13,
        50816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10528888021196638,
      "compression_ratio": 1.4491978609625669,
      "no_speech_prob": 0.00047645182348787785
    },
    {
      "id": 246,
      "seek": 162060,
      "start": 1633.8799999999999,
      "end": 1638.52,
      "text": " Okay, and basically the bipartite bounded degree graphs was just a stepping stone",
      "tokens": [
        51028,
        1033,
        11,
        293,
        1936,
        264,
        28741,
        642,
        37498,
        4314,
        24877,
        390,
        445,
        257,
        16821,
        7581,
        51260
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10528888021196638,
      "compression_ratio": 1.4491978609625669,
      "no_speech_prob": 0.00047645182348787785
    },
    {
      "id": 247,
      "seek": 162060,
      "start": 1638.52,
      "end": 1646.76,
      "text": " to get to the bipartite C4 free graph result. So let me repeat that maybe slightly more clearly.",
      "tokens": [
        51260,
        281,
        483,
        281,
        264,
        28741,
        642,
        383,
        19,
        1737,
        4295,
        1874,
        13,
        407,
        718,
        385,
        7149,
        300,
        1310,
        4748,
        544,
        4448,
        13,
        51672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10528888021196638,
      "compression_ratio": 1.4491978609625669,
      "no_speech_prob": 0.00047645182348787785
    },
    {
      "id": 248,
      "seek": 164676,
      "start": 1646.84,
      "end": 1652.28,
      "text": " So after basically answering the first question, which was bipartite graphs, we were able to show",
      "tokens": [
        50368,
        407,
        934,
        1936,
        13430,
        264,
        700,
        1168,
        11,
        597,
        390,
        28741,
        642,
        24877,
        11,
        321,
        645,
        1075,
        281,
        855,
        50640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08902516695532468,
      "compression_ratio": 1.737991266375546,
      "no_speech_prob": 0.0003154633450321853
    },
    {
      "id": 249,
      "seek": 164676,
      "start": 1652.28,
      "end": 1657.8799999999999,
      "text": " that token sliding was W1 hard, but we were not able to determine the complexity of token jumping.",
      "tokens": [
        50640,
        300,
        14862,
        21169,
        390,
        343,
        16,
        1152,
        11,
        457,
        321,
        645,
        406,
        1075,
        281,
        6997,
        264,
        14024,
        295,
        14862,
        11233,
        13,
        50920
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08902516695532468,
      "compression_ratio": 1.737991266375546,
      "no_speech_prob": 0.0003154633450321853
    },
    {
      "id": 250,
      "seek": 164676,
      "start": 1658.68,
      "end": 1665.08,
      "text": " So then we went to C4 free graphs, and we were able to show that both problems are actually W1 hard.",
      "tokens": [
        50960,
        407,
        550,
        321,
        1437,
        281,
        383,
        19,
        1737,
        24877,
        11,
        293,
        321,
        645,
        1075,
        281,
        855,
        300,
        1293,
        2740,
        366,
        767,
        343,
        16,
        1152,
        13,
        51280
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08902516695532468,
      "compression_ratio": 1.737991266375546,
      "no_speech_prob": 0.0003154633450321853
    },
    {
      "id": 251,
      "seek": 164676,
      "start": 1666.12,
      "end": 1673.32,
      "text": " Then if we added one more constraint, which was C3 C4 free graphs, we got FPDness for token jumping,",
      "tokens": [
        51332,
        1396,
        498,
        321,
        3869,
        472,
        544,
        25534,
        11,
        597,
        390,
        383,
        18,
        383,
        19,
        1737,
        24877,
        11,
        321,
        658,
        479,
        17349,
        1287,
        337,
        14862,
        11233,
        11,
        51692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08902516695532468,
      "compression_ratio": 1.737991266375546,
      "no_speech_prob": 0.0003154633450321853
    },
    {
      "id": 252,
      "seek": 167332,
      "start": 1673.32,
      "end": 1680.28,
      "text": " but it remained open for token sliding. And on the other side of the spectrum, so if we keep",
      "tokens": [
        50364,
        457,
        309,
        12780,
        1269,
        337,
        14862,
        21169,
        13,
        400,
        322,
        264,
        661,
        1252,
        295,
        264,
        11143,
        11,
        370,
        498,
        321,
        1066,
        50712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06790708488141986,
      "compression_ratio": 1.4715909090909092,
      "no_speech_prob": 0.0003943716874346137
    },
    {
      "id": 253,
      "seek": 167332,
      "start": 1680.28,
      "end": 1685.24,
      "text": " bipartite and enforce the C4 freeness, we get FPD for both problems.",
      "tokens": [
        50712,
        28741,
        642,
        293,
        24825,
        264,
        383,
        19,
        1737,
        1287,
        11,
        321,
        483,
        479,
        17349,
        337,
        1293,
        2740,
        13,
        50960
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06790708488141986,
      "compression_ratio": 1.4715909090909092,
      "no_speech_prob": 0.0003943716874346137
    },
    {
      "id": 254,
      "seek": 167332,
      "start": 1688.28,
      "end": 1696.28,
      "text": " And as a side note, this blue result is not part of our paper. This was known prior to our paper.",
      "tokens": [
        51112,
        400,
        382,
        257,
        1252,
        3637,
        11,
        341,
        3344,
        1874,
        307,
        406,
        644,
        295,
        527,
        3035,
        13,
        639,
        390,
        2570,
        4059,
        281,
        527,
        3035,
        13,
        51512
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06790708488141986,
      "compression_ratio": 1.4715909090909092,
      "no_speech_prob": 0.0003943716874346137
    },
    {
      "id": 255,
      "seek": 169628,
      "start": 1696.84,
      "end": 1704.84,
      "text": " So any questions about the results?",
      "tokens": [
        50392,
        407,
        604,
        1651,
        466,
        264,
        3542,
        30,
        50792
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4243987401326497,
      "compression_ratio": 1.0,
      "no_speech_prob": 0.0012929887743666768
    },
    {
      "id": 256,
      "seek": 169628,
      "start": 1719.24,
      "end": 1720.84,
      "text": " No questions. All right, cool.",
      "tokens": [
        51512,
        883,
        1651,
        13,
        1057,
        558,
        11,
        1627,
        13,
        51592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4243987401326497,
      "compression_ratio": 1.0,
      "no_speech_prob": 0.0012929887743666768
    },
    {
      "id": 257,
      "seek": 172084,
      "start": 1721.3999999999999,
      "end": 1732.6799999999998,
      "text": " So lots of open problems. The first and obvious one is what is the pattern? Is token jumping FPD",
      "tokens": [
        50392,
        407,
        3195,
        295,
        1269,
        2740,
        13,
        440,
        700,
        293,
        6322,
        472,
        307,
        437,
        307,
        264,
        5102,
        30,
        1119,
        14862,
        11233,
        479,
        17349,
        50956
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23402233866902142,
      "compression_ratio": 1.4328358208955223,
      "no_speech_prob": 0.0014476001961156726
    },
    {
      "id": 258,
      "seek": 172084,
      "start": 1732.6799999999998,
      "end": 1738.52,
      "text": " paramptres by K on bipartite graphs? And that's really, I mean, that was the initial question that",
      "tokens": [
        50956,
        6220,
        662,
        495,
        538,
        591,
        322,
        28741,
        642,
        24877,
        30,
        400,
        300,
        311,
        534,
        11,
        286,
        914,
        11,
        300,
        390,
        264,
        5883,
        1168,
        300,
        51248
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23402233866902142,
      "compression_ratio": 1.4328358208955223,
      "no_speech_prob": 0.0014476001961156726
    },
    {
      "id": 259,
      "seek": 172084,
      "start": 1738.52,
      "end": 1750.6,
      "text": " we set out to answer and couldn't. So that remains open. And so I will not be going over the",
      "tokens": [
        51248,
        321,
        992,
        484,
        281,
        1867,
        293,
        2809,
        380,
        13,
        407,
        300,
        7023,
        1269,
        13,
        400,
        370,
        286,
        486,
        406,
        312,
        516,
        670,
        264,
        51852
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23402233866902142,
      "compression_ratio": 1.4328358208955223,
      "no_speech_prob": 0.0014476001961156726
    },
    {
      "id": 260,
      "seek": 175060,
      "start": 1750.6,
      "end": 1755.6399999999999,
      "text": " hardness reduction for token sliding on bipartite graphs because it's quite technical. I don't feel",
      "tokens": [
        50364,
        44019,
        11004,
        337,
        14862,
        21169,
        322,
        28741,
        642,
        24877,
        570,
        309,
        311,
        1596,
        6191,
        13,
        286,
        500,
        380,
        841,
        50616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13317697388785227,
      "compression_ratio": 1.5829596412556053,
      "no_speech_prob": 0.0010666267480701208
    },
    {
      "id": 261,
      "seek": 175060,
      "start": 1756.28,
      "end": 1763.48,
      "text": " a talk is the right place to go over it. But if you go over the reduction, you will see that",
      "tokens": [
        50648,
        257,
        751,
        307,
        264,
        558,
        1081,
        281,
        352,
        670,
        309,
        13,
        583,
        498,
        291,
        352,
        670,
        264,
        11004,
        11,
        291,
        486,
        536,
        300,
        51008
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13317697388785227,
      "compression_ratio": 1.5829596412556053,
      "no_speech_prob": 0.0010666267480701208
    },
    {
      "id": 262,
      "seek": 175060,
      "start": 1763.48,
      "end": 1770.4399999999998,
      "text": " that it's the two problems really behave differently. And there doesn't seem to be a",
      "tokens": [
        51008,
        300,
        309,
        311,
        264,
        732,
        2740,
        534,
        15158,
        7614,
        13,
        400,
        456,
        1177,
        380,
        1643,
        281,
        312,
        257,
        51356
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13317697388785227,
      "compression_ratio": 1.5829596412556053,
      "no_speech_prob": 0.0010666267480701208
    },
    {
      "id": 263,
      "seek": 175060,
      "start": 1770.4399999999998,
      "end": 1774.76,
      "text": " chance to basically make the same type of reduction work for token jumping.",
      "tokens": [
        51356,
        2931,
        281,
        1936,
        652,
        264,
        912,
        2010,
        295,
        11004,
        589,
        337,
        14862,
        11233,
        13,
        51572
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13317697388785227,
      "compression_ratio": 1.5829596412556053,
      "no_speech_prob": 0.0010666267480701208
    },
    {
      "id": 264,
      "seek": 177476,
      "start": 1775.72,
      "end": 1782.28,
      "text": " So the second interesting open question is how about token jumping parametrized by K on triangle",
      "tokens": [
        50412,
        407,
        264,
        1150,
        1880,
        1269,
        1168,
        307,
        577,
        466,
        14862,
        11233,
        6220,
        302,
        470,
        11312,
        538,
        591,
        322,
        13369,
        50740
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13262044299732556,
      "compression_ratio": 1.6425531914893616,
      "no_speech_prob": 0.00019604967383202165
    },
    {
      "id": 265,
      "seek": 177476,
      "start": 1782.28,
      "end": 1790.04,
      "text": " free graphs? That's basically even more general than question one. Right? So and the reason why I",
      "tokens": [
        50740,
        1737,
        24877,
        30,
        663,
        311,
        1936,
        754,
        544,
        2674,
        813,
        1168,
        472,
        13,
        1779,
        30,
        407,
        293,
        264,
        1778,
        983,
        286,
        51128
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13262044299732556,
      "compression_ratio": 1.6425531914893616,
      "no_speech_prob": 0.00019604967383202165
    },
    {
      "id": 266,
      "seek": 177476,
      "start": 1790.04,
      "end": 1796.12,
      "text": " mentioned this question separately is because almost every reduction that I know of includes",
      "tokens": [
        51128,
        2835,
        341,
        1168,
        14759,
        307,
        570,
        1920,
        633,
        11004,
        300,
        286,
        458,
        295,
        5974,
        51432
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13262044299732556,
      "compression_ratio": 1.6425531914893616,
      "no_speech_prob": 0.00019604967383202165
    },
    {
      "id": 267,
      "seek": 177476,
      "start": 1796.12,
      "end": 1802.68,
      "text": " large cliques. So you need to use large cliques in your reductions. So how about if we don't allow",
      "tokens": [
        51432,
        2416,
        596,
        4911,
        13,
        407,
        291,
        643,
        281,
        764,
        2416,
        596,
        4911,
        294,
        428,
        40296,
        13,
        407,
        577,
        466,
        498,
        321,
        500,
        380,
        2089,
        51760
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13262044299732556,
      "compression_ratio": 1.6425531914893616,
      "no_speech_prob": 0.00019604967383202165
    },
    {
      "id": 268,
      "seek": 180268,
      "start": 1802.68,
      "end": 1808.2,
      "text": " triangles and large cliques? So can we then say something about the problem?",
      "tokens": [
        50364,
        29896,
        293,
        2416,
        596,
        4911,
        30,
        407,
        393,
        321,
        550,
        584,
        746,
        466,
        264,
        1154,
        30,
        50640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12289883228058511,
      "compression_ratio": 1.5954545454545455,
      "no_speech_prob": 0.0001973524922505021
    },
    {
      "id": 269,
      "seek": 180268,
      "start": 1809.96,
      "end": 1816.44,
      "text": " So that's for token jumping. Now when you go to token sliding, so the open problem is",
      "tokens": [
        50728,
        407,
        300,
        311,
        337,
        14862,
        11233,
        13,
        823,
        562,
        291,
        352,
        281,
        14862,
        21169,
        11,
        370,
        264,
        1269,
        1154,
        307,
        51052
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12289883228058511,
      "compression_ratio": 1.5954545454545455,
      "no_speech_prob": 0.0001973524922505021
    },
    {
      "id": 270,
      "seek": 180268,
      "start": 1817.3200000000002,
      "end": 1824.6000000000001,
      "text": " what happens for token sliding on graphs of girth at least five? So if they are C3, C4 free. Or you",
      "tokens": [
        51096,
        437,
        2314,
        337,
        14862,
        21169,
        322,
        24877,
        295,
        14703,
        392,
        412,
        1935,
        1732,
        30,
        407,
        498,
        436,
        366,
        383,
        18,
        11,
        383,
        19,
        1737,
        13,
        1610,
        291,
        51460
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12289883228058511,
      "compression_ratio": 1.5954545454545455,
      "no_speech_prob": 0.0001973524922505021
    },
    {
      "id": 271,
      "seek": 180268,
      "start": 1824.6000000000001,
      "end": 1831.4,
      "text": " can even make that a bit weaker and ask for any girth of at least P for some constant P.",
      "tokens": [
        51460,
        393,
        754,
        652,
        300,
        257,
        857,
        24286,
        293,
        1029,
        337,
        604,
        14703,
        392,
        295,
        412,
        1935,
        430,
        337,
        512,
        5754,
        430,
        13,
        51800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12289883228058511,
      "compression_ratio": 1.5954545454545455,
      "no_speech_prob": 0.0001973524922505021
    },
    {
      "id": 272,
      "seek": 183268,
      "start": 1833.64,
      "end": 1840.04,
      "text": " And for all of these questions, of course, polynomial kernels would be interesting as well,",
      "tokens": [
        50412,
        400,
        337,
        439,
        295,
        613,
        1651,
        11,
        295,
        1164,
        11,
        26110,
        23434,
        1625,
        576,
        312,
        1880,
        382,
        731,
        11,
        50732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2357319019458912,
      "compression_ratio": 1.525179856115108,
      "no_speech_prob": 0.0003536963486112654
    },
    {
      "id": 273,
      "seek": 183268,
      "start": 1840.04,
      "end": 1844.92,
      "text": " because in our case, we do get polynomial kernels for the FPT.",
      "tokens": [
        50732,
        570,
        294,
        527,
        1389,
        11,
        321,
        360,
        483,
        26110,
        23434,
        1625,
        337,
        264,
        36655,
        51,
        13,
        50976
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2357319019458912,
      "compression_ratio": 1.525179856115108,
      "no_speech_prob": 0.0003536963486112654
    },
    {
      "id": 274,
      "seek": 183268,
      "start": 1847.8,
      "end": 1853.3200000000002,
      "text": " The polynomials are not great, but polynomial regardless.",
      "tokens": [
        51120,
        440,
        22560,
        12356,
        366,
        406,
        869,
        11,
        457,
        26110,
        10060,
        13,
        51396
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2357319019458912,
      "compression_ratio": 1.525179856115108,
      "no_speech_prob": 0.0003536963486112654
    },
    {
      "id": 275,
      "seek": 185332,
      "start": 1854.28,
      "end": 1861.6399999999999,
      "text": " All right. So in the rest of the talk, I will try to cover some of the technical stuff. And as",
      "tokens": [
        50412,
        1057,
        558,
        13,
        407,
        294,
        264,
        1472,
        295,
        264,
        751,
        11,
        286,
        486,
        853,
        281,
        2060,
        512,
        295,
        264,
        6191,
        1507,
        13,
        400,
        382,
        50780
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14337767725405487,
      "compression_ratio": 1.7069767441860466,
      "no_speech_prob": 0.0006831888458691537
    },
    {
      "id": 276,
      "seek": 185332,
      "start": 1861.6399999999999,
      "end": 1867.24,
      "text": " promised, I will try to keep it as light as possible so that I can give you some of a lot of",
      "tokens": [
        50780,
        10768,
        11,
        286,
        486,
        853,
        281,
        1066,
        309,
        382,
        1442,
        382,
        1944,
        370,
        300,
        286,
        393,
        976,
        291,
        512,
        295,
        257,
        688,
        295,
        51060
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14337767725405487,
      "compression_ratio": 1.7069767441860466,
      "no_speech_prob": 0.0006831888458691537
    },
    {
      "id": 277,
      "seek": 185332,
      "start": 1867.24,
      "end": 1873.32,
      "text": " the intuition and techniques that are used in this paper and that are generally used when",
      "tokens": [
        51060,
        264,
        24002,
        293,
        7512,
        300,
        366,
        1143,
        294,
        341,
        3035,
        293,
        300,
        366,
        5101,
        1143,
        562,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14337767725405487,
      "compression_ratio": 1.7069767441860466,
      "no_speech_prob": 0.0006831888458691537
    },
    {
      "id": 278,
      "seek": 185332,
      "start": 1873.32,
      "end": 1879.08,
      "text": " dealing with reconfiguration problems. So the first result that we will go over is this W",
      "tokens": [
        51364,
        6260,
        365,
        9993,
        20646,
        8167,
        2740,
        13,
        407,
        264,
        700,
        1874,
        300,
        321,
        486,
        352,
        670,
        307,
        341,
        343,
        51652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14337767725405487,
      "compression_ratio": 1.7069767441860466,
      "no_speech_prob": 0.0006831888458691537
    },
    {
      "id": 279,
      "seek": 187908,
      "start": 1879.32,
      "end": 1885.48,
      "text": " hardness on C4 free graphs, right? For both token sliding and token jumping. It's the same reduction",
      "tokens": [
        50376,
        44019,
        322,
        383,
        19,
        1737,
        24877,
        11,
        558,
        30,
        1171,
        1293,
        14862,
        21169,
        293,
        14862,
        11233,
        13,
        467,
        311,
        264,
        912,
        11004,
        50684
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20512166837366616,
      "compression_ratio": 1.7004608294930876,
      "no_speech_prob": 0.0002526217431295663
    },
    {
      "id": 280,
      "seek": 187908,
      "start": 1885.48,
      "end": 1895.1599999999999,
      "text": " and you will get both results because we will be using maximum independent sets. So if you're trying",
      "tokens": [
        50684,
        293,
        291,
        486,
        483,
        1293,
        3542,
        570,
        321,
        486,
        312,
        1228,
        6674,
        6695,
        6352,
        13,
        407,
        498,
        291,
        434,
        1382,
        51168
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20512166837366616,
      "compression_ratio": 1.7004608294930876,
      "no_speech_prob": 0.0002526217431295663
    },
    {
      "id": 281,
      "seek": 187908,
      "start": 1895.1599999999999,
      "end": 1902.52,
      "text": " to basically do token sliding from one maximum independent set to the other or token jumping,",
      "tokens": [
        51168,
        281,
        1936,
        360,
        14862,
        21169,
        490,
        472,
        6674,
        6695,
        992,
        281,
        264,
        661,
        420,
        14862,
        11233,
        11,
        51536
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20512166837366616,
      "compression_ratio": 1.7004608294930876,
      "no_speech_prob": 0.0002526217431295663
    },
    {
      "id": 282,
      "seek": 187908,
      "start": 1902.52,
      "end": 1906.52,
      "text": " these two rules become equivalent. Jumping becomes equivalent to sliding.",
      "tokens": [
        51536,
        613,
        732,
        4474,
        1813,
        10344,
        13,
        18697,
        278,
        3643,
        10344,
        281,
        21169,
        13,
        51736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20512166837366616,
      "compression_ratio": 1.7004608294930876,
      "no_speech_prob": 0.0002526217431295663
    },
    {
      "id": 283,
      "seek": 190652,
      "start": 1907.16,
      "end": 1912.28,
      "text": " Jumping becomes equivalent to sliding. So when you're dealing with maximum independent sets,",
      "tokens": [
        50396,
        18697,
        278,
        3643,
        10344,
        281,
        21169,
        13,
        407,
        562,
        291,
        434,
        6260,
        365,
        6674,
        6695,
        6352,
        11,
        50652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11947830687177942,
      "compression_ratio": 1.6200873362445414,
      "no_speech_prob": 0.0003522433980833739
    },
    {
      "id": 284,
      "seek": 190652,
      "start": 1912.28,
      "end": 1917.6399999999999,
      "text": " these two basically rules are the same. And that's what we're going to do. But what we're",
      "tokens": [
        50652,
        613,
        732,
        1936,
        4474,
        366,
        264,
        912,
        13,
        400,
        300,
        311,
        437,
        321,
        434,
        516,
        281,
        360,
        13,
        583,
        437,
        321,
        434,
        50920
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11947830687177942,
      "compression_ratio": 1.6200873362445414,
      "no_speech_prob": 0.0003522433980833739
    },
    {
      "id": 285,
      "seek": 190652,
      "start": 1917.6399999999999,
      "end": 1923.24,
      "text": " going to prove actually is a stronger theorem. What we're going to prove is the following theorem.",
      "tokens": [
        50920,
        516,
        281,
        7081,
        767,
        307,
        257,
        7249,
        20904,
        13,
        708,
        321,
        434,
        516,
        281,
        7081,
        307,
        264,
        3480,
        20904,
        13,
        51200
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11947830687177942,
      "compression_ratio": 1.6200873362445414,
      "no_speech_prob": 0.0003522433980833739
    },
    {
      "id": 286,
      "seek": 190652,
      "start": 1923.24,
      "end": 1932.04,
      "text": " If you take any P greater than or equal to four, then both problems are W hard on C4, C5,",
      "tokens": [
        51200,
        759,
        291,
        747,
        604,
        430,
        5044,
        813,
        420,
        2681,
        281,
        1451,
        11,
        550,
        1293,
        2740,
        366,
        343,
        1152,
        322,
        383,
        19,
        11,
        383,
        20,
        11,
        51640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11947830687177942,
      "compression_ratio": 1.6200873362445414,
      "no_speech_prob": 0.0003522433980833739
    },
    {
      "id": 287,
      "seek": 193204,
      "start": 1932.68,
      "end": 1939.48,
      "text": " dot, dot, dot, up to Cp free graphs, which implies of course C4 free graphs.",
      "tokens": [
        50396,
        5893,
        11,
        5893,
        11,
        5893,
        11,
        493,
        281,
        383,
        79,
        1737,
        24877,
        11,
        597,
        18779,
        295,
        1164,
        383,
        19,
        1737,
        24877,
        13,
        50736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15016073650783962,
      "compression_ratio": 1.4175824175824177,
      "no_speech_prob": 0.0010213586501777172
    },
    {
      "id": 288,
      "seek": 193204,
      "start": 1940.92,
      "end": 1949.48,
      "text": " But you can basically exclude any cycles from C4 up to Cp for constant P and the problems will",
      "tokens": [
        50808,
        583,
        291,
        393,
        1936,
        33536,
        604,
        17796,
        490,
        383,
        19,
        493,
        281,
        383,
        79,
        337,
        5754,
        430,
        293,
        264,
        2740,
        486,
        51236
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15016073650783962,
      "compression_ratio": 1.4175824175824177,
      "no_speech_prob": 0.0010213586501777172
    },
    {
      "id": 289,
      "seek": 193204,
      "start": 1949.48,
      "end": 1961.8,
      "text": " remain W1 hard. So how do we prove this result? In fact, we use a known reduction from",
      "tokens": [
        51236,
        6222,
        343,
        16,
        1152,
        13,
        407,
        577,
        360,
        321,
        7081,
        341,
        1874,
        30,
        682,
        1186,
        11,
        321,
        764,
        257,
        2570,
        11004,
        490,
        51852
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15016073650783962,
      "compression_ratio": 1.4175824175824177,
      "no_speech_prob": 0.0010213586501777172
    },
    {
      "id": 290,
      "seek": 196204,
      "start": 1962.04,
      "end": 1969.6399999999999,
      "text": " a problem known as grid tiling, which is a W1 hard problem. And grid tiling is reduced",
      "tokens": [
        50364,
        257,
        1154,
        2570,
        382,
        10748,
        256,
        4883,
        11,
        597,
        307,
        257,
        343,
        16,
        1152,
        1154,
        13,
        400,
        10748,
        256,
        4883,
        307,
        9212,
        50744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06027911460562928,
      "compression_ratio": 1.6358024691358024,
      "no_speech_prob": 0.00016693382349330932
    },
    {
      "id": 291,
      "seek": 196204,
      "start": 1969.6399999999999,
      "end": 1978.2,
      "text": " to the independent set problem on C4 up to Cp free graphs. And that reduction was used to show",
      "tokens": [
        50744,
        281,
        264,
        6695,
        992,
        1154,
        322,
        383,
        19,
        493,
        281,
        383,
        79,
        1737,
        24877,
        13,
        400,
        300,
        11004,
        390,
        1143,
        281,
        855,
        51172
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06027911460562928,
      "compression_ratio": 1.6358024691358024,
      "no_speech_prob": 0.00016693382349330932
    },
    {
      "id": 292,
      "seek": 196204,
      "start": 1978.2,
      "end": 1985.3999999999999,
      "text": " that independent set remains W1 hard if you exclude C4 up to Cp for any constant P.",
      "tokens": [
        51172,
        300,
        6695,
        992,
        7023,
        343,
        16,
        1152,
        498,
        291,
        33536,
        383,
        19,
        493,
        281,
        383,
        79,
        337,
        604,
        5754,
        430,
        13,
        51532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06027911460562928,
      "compression_ratio": 1.6358024691358024,
      "no_speech_prob": 0.00016693382349330932
    },
    {
      "id": 293,
      "seek": 198540,
      "start": 1985.4,
      "end": 1992.6000000000001,
      "text": " But what is interesting and useful in that reduction is the graph that is obtained from",
      "tokens": [
        50364,
        583,
        437,
        307,
        1880,
        293,
        4420,
        294,
        300,
        11004,
        307,
        264,
        4295,
        300,
        307,
        14879,
        490,
        50724
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19004893832736544,
      "compression_ratio": 1.8431372549019607,
      "no_speech_prob": 0.0007096050539985299
    },
    {
      "id": 294,
      "seek": 198540,
      "start": 1992.6000000000001,
      "end": 1998.76,
      "text": " the reduction. So the graph that is obtained from the reduction has three properties that are going",
      "tokens": [
        50724,
        264,
        11004,
        13,
        407,
        264,
        4295,
        300,
        307,
        14879,
        490,
        264,
        11004,
        575,
        1045,
        7221,
        300,
        366,
        516,
        51032
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19004893832736544,
      "compression_ratio": 1.8431372549019607,
      "no_speech_prob": 0.0007096050539985299
    },
    {
      "id": 295,
      "seek": 198540,
      "start": 1998.76,
      "end": 2006.6000000000001,
      "text": " to be useful to us. The first property is that you can partition the graph into basically 8k",
      "tokens": [
        51032,
        281,
        312,
        4420,
        281,
        505,
        13,
        440,
        700,
        4707,
        307,
        300,
        291,
        393,
        24808,
        264,
        4295,
        666,
        1936,
        1649,
        74,
        51424
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19004893832736544,
      "compression_ratio": 1.8431372549019607,
      "no_speech_prob": 0.0007096050539985299
    },
    {
      "id": 296,
      "seek": 198540,
      "start": 2006.6000000000001,
      "end": 2013.88,
      "text": " squared into P plus one cliques. So you have a bunch of cliques, each of size n, and all of the",
      "tokens": [
        51424,
        8889,
        666,
        430,
        1804,
        472,
        596,
        4911,
        13,
        407,
        291,
        362,
        257,
        3840,
        295,
        596,
        4911,
        11,
        1184,
        295,
        2744,
        297,
        11,
        293,
        439,
        295,
        264,
        51788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19004893832736544,
      "compression_ratio": 1.8431372549019607,
      "no_speech_prob": 0.0007096050539985299
    },
    {
      "id": 297,
      "seek": 201388,
      "start": 2014.68,
      "end": 2021.64,
      "text": " edges basically are between the cliques. But that's it. That's it. That's the whole of the graph.",
      "tokens": [
        50404,
        8819,
        1936,
        366,
        1296,
        264,
        596,
        4911,
        13,
        583,
        300,
        311,
        309,
        13,
        663,
        311,
        309,
        13,
        663,
        311,
        264,
        1379,
        295,
        264,
        4295,
        13,
        50752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.05503107626226884,
      "compression_ratio": 1.5376344086021505,
      "no_speech_prob": 0.00018314880435355008
    },
    {
      "id": 298,
      "seek": 201388,
      "start": 2021.64,
      "end": 2028.6000000000001,
      "text": " It's a bunch of cliques and edges between them. Of course, the more important property as well",
      "tokens": [
        50752,
        467,
        311,
        257,
        3840,
        295,
        596,
        4911,
        293,
        8819,
        1296,
        552,
        13,
        2720,
        1164,
        11,
        264,
        544,
        1021,
        4707,
        382,
        731,
        51100
      ],
      "temperature": 0.0,
      "avg_logprob": -0.05503107626226884,
      "compression_ratio": 1.5376344086021505,
      "no_speech_prob": 0.00018314880435355008
    },
    {
      "id": 299,
      "seek": 201388,
      "start": 2028.6000000000001,
      "end": 2036.8400000000001,
      "text": " here is that this graph is going to be C4 up to Cp free. It will not have any of those cycles",
      "tokens": [
        51100,
        510,
        307,
        300,
        341,
        4295,
        307,
        516,
        281,
        312,
        383,
        19,
        493,
        281,
        383,
        79,
        1737,
        13,
        467,
        486,
        406,
        362,
        604,
        295,
        729,
        17796,
        51512
      ],
      "temperature": 0.0,
      "avg_logprob": -0.05503107626226884,
      "compression_ratio": 1.5376344086021505,
      "no_speech_prob": 0.00018314880435355008
    },
    {
      "id": 300,
      "seek": 203684,
      "start": 2036.84,
      "end": 2045.1599999999999,
      "text": " as an induced subgraph. And it's an equivalent instance to the grid tiling instance. And that",
      "tokens": [
        50364,
        382,
        364,
        33991,
        1422,
        34091,
        13,
        400,
        309,
        311,
        364,
        10344,
        5197,
        281,
        264,
        10748,
        256,
        4883,
        5197,
        13,
        400,
        300,
        50780
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07758926308673361,
      "compression_ratio": 1.7432432432432432,
      "no_speech_prob": 0.0005764028173871338
    },
    {
      "id": 301,
      "seek": 203684,
      "start": 2045.1599999999999,
      "end": 2054.68,
      "text": " basically gives you W1 hardness of independent set on this class of graphs. So notice in this case",
      "tokens": [
        50780,
        1936,
        2709,
        291,
        343,
        16,
        44019,
        295,
        6695,
        992,
        322,
        341,
        1508,
        295,
        24877,
        13,
        407,
        3449,
        294,
        341,
        1389,
        51256
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07758926308673361,
      "compression_ratio": 1.7432432432432432,
      "no_speech_prob": 0.0005764028173871338
    },
    {
      "id": 302,
      "seek": 203684,
      "start": 2054.68,
      "end": 2060.84,
      "text": " that an independent set of size 8k squared into P plus one will have to be a maximum independent",
      "tokens": [
        51256,
        300,
        364,
        6695,
        992,
        295,
        2744,
        1649,
        74,
        8889,
        666,
        430,
        1804,
        472,
        486,
        362,
        281,
        312,
        257,
        6674,
        6695,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07758926308673361,
      "compression_ratio": 1.7432432432432432,
      "no_speech_prob": 0.0005764028173871338
    },
    {
      "id": 303,
      "seek": 203684,
      "start": 2060.84,
      "end": 2066.36,
      "text": " set because that's how many cliques we get in the resulting graph. And that's basically the sizes",
      "tokens": [
        51564,
        992,
        570,
        300,
        311,
        577,
        867,
        596,
        4911,
        321,
        483,
        294,
        264,
        16505,
        4295,
        13,
        400,
        300,
        311,
        1936,
        264,
        11602,
        51840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07758926308673361,
      "compression_ratio": 1.7432432432432432,
      "no_speech_prob": 0.0005764028173871338
    },
    {
      "id": 304,
      "seek": 206636,
      "start": 2066.36,
      "end": 2071.6400000000003,
      "text": " that we will be working with more or less up to some modifications. But this will allow us to",
      "tokens": [
        50364,
        300,
        321,
        486,
        312,
        1364,
        365,
        544,
        420,
        1570,
        493,
        281,
        512,
        26881,
        13,
        583,
        341,
        486,
        2089,
        505,
        281,
        50628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.05041720700818439,
      "compression_ratio": 1.6883720930232557,
      "no_speech_prob": 0.00017276042490266263
    },
    {
      "id": 305,
      "seek": 206636,
      "start": 2071.6400000000003,
      "end": 2078.44,
      "text": " basically conclude that both sliding and jumping are hard on this class of graphs.",
      "tokens": [
        50628,
        1936,
        16886,
        300,
        1293,
        21169,
        293,
        11233,
        366,
        1152,
        322,
        341,
        1508,
        295,
        24877,
        13,
        50968
      ],
      "temperature": 0.0,
      "avg_logprob": -0.05041720700818439,
      "compression_ratio": 1.6883720930232557,
      "no_speech_prob": 0.00017276042490266263
    },
    {
      "id": 306,
      "seek": 206636,
      "start": 2081.4,
      "end": 2088.84,
      "text": " So how do we use this for showing hardness of token sliding and token jumping? And let's focus",
      "tokens": [
        51116,
        407,
        577,
        360,
        321,
        764,
        341,
        337,
        4099,
        44019,
        295,
        14862,
        21169,
        293,
        14862,
        11233,
        30,
        400,
        718,
        311,
        1879,
        51488
      ],
      "temperature": 0.0,
      "avg_logprob": -0.05041720700818439,
      "compression_ratio": 1.6883720930232557,
      "no_speech_prob": 0.00017276042490266263
    },
    {
      "id": 307,
      "seek": 206636,
      "start": 2088.84,
      "end": 2094.52,
      "text": " on token sliding for now because it's going to be the same anyway. So we have those cliques",
      "tokens": [
        51488,
        322,
        14862,
        21169,
        337,
        586,
        570,
        309,
        311,
        516,
        281,
        312,
        264,
        912,
        4033,
        13,
        407,
        321,
        362,
        729,
        596,
        4911,
        51772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.05041720700818439,
      "compression_ratio": 1.6883720930232557,
      "no_speech_prob": 0.00017276042490266263
    },
    {
      "id": 308,
      "seek": 209452,
      "start": 2095.08,
      "end": 2102.12,
      "text": " and some edges that go between the cliques. So the first attempt would be as follows. We will add",
      "tokens": [
        50392,
        293,
        512,
        8819,
        300,
        352,
        1296,
        264,
        596,
        4911,
        13,
        407,
        264,
        700,
        5217,
        576,
        312,
        382,
        10002,
        13,
        492,
        486,
        909,
        50744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.05408755313144641,
      "compression_ratio": 1.9489795918367347,
      "no_speech_prob": 0.000710974563844502
    },
    {
      "id": 309,
      "seek": 209452,
      "start": 2102.7599999999998,
      "end": 2108.2,
      "text": " a universal vertex to each one of the cliques and we will call this the starting set or the",
      "tokens": [
        50776,
        257,
        11455,
        28162,
        281,
        1184,
        472,
        295,
        264,
        596,
        4911,
        293,
        321,
        486,
        818,
        341,
        264,
        2891,
        992,
        420,
        264,
        51048
      ],
      "temperature": 0.0,
      "avg_logprob": -0.05408755313144641,
      "compression_ratio": 1.9489795918367347,
      "no_speech_prob": 0.000710974563844502
    },
    {
      "id": 310,
      "seek": 209452,
      "start": 2108.2,
      "end": 2114.12,
      "text": " starting independent set. And then we add another universal vertex to each one of the cliques and",
      "tokens": [
        51048,
        2891,
        6695,
        992,
        13,
        400,
        550,
        321,
        909,
        1071,
        11455,
        28162,
        281,
        1184,
        472,
        295,
        264,
        596,
        4911,
        293,
        51344
      ],
      "temperature": 0.0,
      "avg_logprob": -0.05408755313144641,
      "compression_ratio": 1.9489795918367347,
      "no_speech_prob": 0.000710974563844502
    },
    {
      "id": 311,
      "seek": 209452,
      "start": 2114.12,
      "end": 2120.04,
      "text": " call this the target independent set. And now basically we have our instance of token sliding.",
      "tokens": [
        51344,
        818,
        341,
        264,
        3779,
        6695,
        992,
        13,
        400,
        586,
        1936,
        321,
        362,
        527,
        5197,
        295,
        14862,
        21169,
        13,
        51640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.05408755313144641,
      "compression_ratio": 1.9489795918367347,
      "no_speech_prob": 0.000710974563844502
    },
    {
      "id": 312,
      "seek": 212004,
      "start": 2120.04,
      "end": 2129.16,
      "text": " We want to slide everybody in S down to T. So notice that this is useful because we don't",
      "tokens": [
        50364,
        492,
        528,
        281,
        4137,
        2201,
        294,
        318,
        760,
        281,
        314,
        13,
        407,
        3449,
        300,
        341,
        307,
        4420,
        570,
        321,
        500,
        380,
        50820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.05778571086771348,
      "compression_ratio": 1.5026737967914439,
      "no_speech_prob": 0.00029073897167108953
    },
    {
      "id": 313,
      "seek": 212004,
      "start": 2129.16,
      "end": 2136.52,
      "text": " introduce any of the forbidden cycles. So we are still fine. And if we could guarantee that all",
      "tokens": [
        50820,
        5366,
        604,
        295,
        264,
        25990,
        17796,
        13,
        407,
        321,
        366,
        920,
        2489,
        13,
        400,
        498,
        321,
        727,
        10815,
        300,
        439,
        51188
      ],
      "temperature": 0.0,
      "avg_logprob": -0.05778571086771348,
      "compression_ratio": 1.5026737967914439,
      "no_speech_prob": 0.00029073897167108953
    },
    {
      "id": 314,
      "seek": 212004,
      "start": 2136.52,
      "end": 2143.96,
      "text": " of the tokens will be on the on the cliques simultaneously, then this will imply an independent",
      "tokens": [
        51188,
        295,
        264,
        22667,
        486,
        312,
        322,
        264,
        322,
        264,
        596,
        4911,
        16561,
        11,
        550,
        341,
        486,
        33616,
        364,
        6695,
        51560
      ],
      "temperature": 0.0,
      "avg_logprob": -0.05778571086771348,
      "compression_ratio": 1.5026737967914439,
      "no_speech_prob": 0.00029073897167108953
    },
    {
      "id": 315,
      "seek": 214396,
      "start": 2143.96,
      "end": 2149.8,
      "text": " set in the original graph, which concludes our proof. But unfortunately in this case,",
      "tokens": [
        50364,
        992,
        294,
        264,
        3380,
        4295,
        11,
        597,
        24643,
        527,
        8177,
        13,
        583,
        7015,
        294,
        341,
        1389,
        11,
        50656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13114716893150694,
      "compression_ratio": 1.6497695852534562,
      "no_speech_prob": 0.003878528019413352
    },
    {
      "id": 316,
      "seek": 214396,
      "start": 2149.8,
      "end": 2157.7200000000003,
      "text": " we definitely cannot conclude that because each red token can slide independently here and then",
      "tokens": [
        50656,
        321,
        2138,
        2644,
        16886,
        300,
        570,
        1184,
        2182,
        14862,
        393,
        4137,
        21761,
        510,
        293,
        550,
        51052
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13114716893150694,
      "compression_ratio": 1.6497695852534562,
      "no_speech_prob": 0.003878528019413352
    },
    {
      "id": 317,
      "seek": 214396,
      "start": 2157.7200000000003,
      "end": 2164.36,
      "text": " here and then the next one can follow, etc, etc, etc. So you need some way of forbidden,",
      "tokens": [
        51052,
        510,
        293,
        550,
        264,
        958,
        472,
        393,
        1524,
        11,
        5183,
        11,
        5183,
        11,
        5183,
        13,
        407,
        291,
        643,
        512,
        636,
        295,
        25990,
        11,
        51384
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13114716893150694,
      "compression_ratio": 1.6497695852534562,
      "no_speech_prob": 0.003878528019413352
    },
    {
      "id": 318,
      "seek": 214396,
      "start": 2164.36,
      "end": 2171.16,
      "text": " of forbidding these tokens to behave freely. We want to make sure that they will all be",
      "tokens": [
        51384,
        295,
        34117,
        3584,
        613,
        22667,
        281,
        15158,
        16433,
        13,
        492,
        528,
        281,
        652,
        988,
        300,
        436,
        486,
        439,
        312,
        51724
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13114716893150694,
      "compression_ratio": 1.6497695852534562,
      "no_speech_prob": 0.003878528019413352
    },
    {
      "id": 319,
      "seek": 217116,
      "start": 2171.16,
      "end": 2178.04,
      "text": " inside the cliques simultaneously and we will be done. And notice that we're going to have 8k",
      "tokens": [
        50364,
        1854,
        264,
        596,
        4911,
        16561,
        293,
        321,
        486,
        312,
        1096,
        13,
        400,
        3449,
        300,
        321,
        434,
        516,
        281,
        362,
        1649,
        74,
        50708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13292558414419903,
      "compression_ratio": 1.7136563876651982,
      "no_speech_prob": 0.0007852209964767098
    },
    {
      "id": 320,
      "seek": 217116,
      "start": 2178.04,
      "end": 2184.12,
      "text": " squared and 2p plus 1 tokens, right? One for each clique and two universal vertices for each clique.",
      "tokens": [
        50708,
        8889,
        293,
        568,
        79,
        1804,
        502,
        22667,
        11,
        558,
        30,
        1485,
        337,
        1184,
        44467,
        293,
        732,
        11455,
        32053,
        337,
        1184,
        44467,
        13,
        51012
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13292558414419903,
      "compression_ratio": 1.7136563876651982,
      "no_speech_prob": 0.0007852209964767098
    },
    {
      "id": 321,
      "seek": 217116,
      "start": 2184.92,
      "end": 2194.2799999999997,
      "text": " So how do we fix this simultaneity issue? Well, here's how we can do it. So instead of simply",
      "tokens": [
        51052,
        407,
        577,
        360,
        321,
        3191,
        341,
        13899,
        1929,
        507,
        2734,
        30,
        1042,
        11,
        510,
        311,
        577,
        321,
        393,
        360,
        309,
        13,
        407,
        2602,
        295,
        2935,
        51520
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13292558414419903,
      "compression_ratio": 1.7136563876651982,
      "no_speech_prob": 0.0007852209964767098
    },
    {
      "id": 322,
      "seek": 217116,
      "start": 2194.2799999999997,
      "end": 2200.68,
      "text": " adding universal vertices, we're also going to add an edge between every two universal vertices of a",
      "tokens": [
        51520,
        5127,
        11455,
        32053,
        11,
        321,
        434,
        611,
        516,
        281,
        909,
        364,
        4691,
        1296,
        633,
        732,
        11455,
        32053,
        295,
        257,
        51840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13292558414419903,
      "compression_ratio": 1.7136563876651982,
      "no_speech_prob": 0.0007852209964767098
    },
    {
      "id": 323,
      "seek": 220068,
      "start": 2201.64,
      "end": 2206.9199999999996,
      "text": " clique and then we're going to add something that we call a switch. And in this case, it's a simple",
      "tokens": [
        50412,
        44467,
        293,
        550,
        321,
        434,
        516,
        281,
        909,
        746,
        300,
        321,
        818,
        257,
        3679,
        13,
        400,
        294,
        341,
        1389,
        11,
        309,
        311,
        257,
        2199,
        50676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12236181894938152,
      "compression_ratio": 1.5372340425531914,
      "no_speech_prob": 0.0014054874191060662
    },
    {
      "id": 324,
      "seek": 220068,
      "start": 2206.9199999999996,
      "end": 2215.08,
      "text": " edge and the red token here needs to go to the blue position, right? So now we have one extra",
      "tokens": [
        50676,
        4691,
        293,
        264,
        2182,
        14862,
        510,
        2203,
        281,
        352,
        281,
        264,
        3344,
        2535,
        11,
        558,
        30,
        407,
        586,
        321,
        362,
        472,
        2857,
        51084
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12236181894938152,
      "compression_ratio": 1.5372340425531914,
      "no_speech_prob": 0.0014054874191060662
    },
    {
      "id": 325,
      "seek": 220068,
      "start": 2215.7999999999997,
      "end": 2225.16,
      "text": " token inside our graph. But now notice what happens. If any red token wants to come to the blue",
      "tokens": [
        51120,
        14862,
        1854,
        527,
        4295,
        13,
        583,
        586,
        3449,
        437,
        2314,
        13,
        759,
        604,
        2182,
        14862,
        2738,
        281,
        808,
        281,
        264,
        3344,
        51588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12236181894938152,
      "compression_ratio": 1.5372340425531914,
      "no_speech_prob": 0.0014054874191060662
    },
    {
      "id": 326,
      "seek": 222516,
      "start": 2226.04,
      "end": 2233.56,
      "text": " position, then this red token needs to be moved to this position before. And if you move that token",
      "tokens": [
        50408,
        2535,
        11,
        550,
        341,
        2182,
        14862,
        2203,
        281,
        312,
        4259,
        281,
        341,
        2535,
        949,
        13,
        400,
        498,
        291,
        1286,
        300,
        14862,
        50784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06702602704366048,
      "compression_ratio": 1.778301886792453,
      "no_speech_prob": 0.00202628830447793
    },
    {
      "id": 327,
      "seek": 222516,
      "start": 2233.56,
      "end": 2238.92,
      "text": " up to the blue position, then you can no longer have any of the red tokens on the universal vertices,",
      "tokens": [
        50784,
        493,
        281,
        264,
        3344,
        2535,
        11,
        550,
        291,
        393,
        572,
        2854,
        362,
        604,
        295,
        264,
        2182,
        22667,
        322,
        264,
        11455,
        32053,
        11,
        51052
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06702602704366048,
      "compression_ratio": 1.778301886792453,
      "no_speech_prob": 0.00202628830447793
    },
    {
      "id": 328,
      "seek": 222516,
      "start": 2239.48,
      "end": 2243.7999999999997,
      "text": " which means that they will all have to be simultaneously inside the cliques.",
      "tokens": [
        51080,
        597,
        1355,
        300,
        436,
        486,
        439,
        362,
        281,
        312,
        16561,
        1854,
        264,
        596,
        4911,
        13,
        51296
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06702602704366048,
      "compression_ratio": 1.778301886792453,
      "no_speech_prob": 0.00202628830447793
    },
    {
      "id": 329,
      "seek": 222516,
      "start": 2245.24,
      "end": 2252.3599999999997,
      "text": " And now we get the behavior that we want. So now we can guarantee that if there is a sequence that",
      "tokens": [
        51368,
        400,
        586,
        321,
        483,
        264,
        5223,
        300,
        321,
        528,
        13,
        407,
        586,
        321,
        393,
        10815,
        300,
        498,
        456,
        307,
        257,
        8310,
        300,
        51724
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06702602704366048,
      "compression_ratio": 1.778301886792453,
      "no_speech_prob": 0.00202628830447793
    },
    {
      "id": 330,
      "seek": 225236,
      "start": 2252.36,
      "end": 2260.36,
      "text": " takes the red tokens to the blue position, then some way along that sequence, the tokens are all",
      "tokens": [
        50364,
        2516,
        264,
        2182,
        22667,
        281,
        264,
        3344,
        2535,
        11,
        550,
        512,
        636,
        2051,
        300,
        8310,
        11,
        264,
        22667,
        366,
        439,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06645587055953507,
      "compression_ratio": 1.6097560975609757,
      "no_speech_prob": 0.00028633695910684764
    },
    {
      "id": 331,
      "seek": 225236,
      "start": 2260.36,
      "end": 2265.88,
      "text": " going to be within the cliques. Unfortunately, what happened here is we might have introduced some of",
      "tokens": [
        50764,
        516,
        281,
        312,
        1951,
        264,
        596,
        4911,
        13,
        8590,
        11,
        437,
        2011,
        510,
        307,
        321,
        1062,
        362,
        7268,
        512,
        295,
        51040
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06645587055953507,
      "compression_ratio": 1.6097560975609757,
      "no_speech_prob": 0.00028633695910684764
    },
    {
      "id": 332,
      "seek": 225236,
      "start": 2265.88,
      "end": 2275.4,
      "text": " the forbidden cycles. We can no longer guarantee that this is C4 up to CP3. So what you can do in",
      "tokens": [
        51040,
        264,
        25990,
        17796,
        13,
        492,
        393,
        572,
        2854,
        10815,
        300,
        341,
        307,
        383,
        19,
        493,
        281,
        22431,
        18,
        13,
        407,
        437,
        291,
        393,
        360,
        294,
        51516
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06645587055953507,
      "compression_ratio": 1.6097560975609757,
      "no_speech_prob": 0.00028633695910684764
    },
    {
      "id": 333,
      "seek": 225236,
      "start": 2275.4,
      "end": 2280.84,
      "text": " this case to solve this problem, and I'm not going to go into the details, but the intuition should",
      "tokens": [
        51516,
        341,
        1389,
        281,
        5039,
        341,
        1154,
        11,
        293,
        286,
        478,
        406,
        516,
        281,
        352,
        666,
        264,
        4365,
        11,
        457,
        264,
        24002,
        820,
        51788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06645587055953507,
      "compression_ratio": 1.6097560975609757,
      "no_speech_prob": 0.00028633695910684764
    },
    {
      "id": 334,
      "seek": 228084,
      "start": 2280.84,
      "end": 2287.56,
      "text": " be pretty clear is that you can subdivide those edges, make them long enough so that you don't",
      "tokens": [
        50364,
        312,
        1238,
        1850,
        307,
        300,
        291,
        393,
        45331,
        482,
        729,
        8819,
        11,
        652,
        552,
        938,
        1547,
        370,
        300,
        291,
        500,
        380,
        50700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.115556271870931,
      "compression_ratio": 1.6575342465753424,
      "no_speech_prob": 0.0006801807903684676
    },
    {
      "id": 335,
      "seek": 228084,
      "start": 2287.56,
      "end": 2293.1600000000003,
      "text": " introduce any forbidden cycles, and add appropriate tokens inside of them to get the same behavior.",
      "tokens": [
        50700,
        5366,
        604,
        25990,
        17796,
        11,
        293,
        909,
        6854,
        22667,
        1854,
        295,
        552,
        281,
        483,
        264,
        912,
        5223,
        13,
        50980
      ],
      "temperature": 0.0,
      "avg_logprob": -0.115556271870931,
      "compression_ratio": 1.6575342465753424,
      "no_speech_prob": 0.0006801807903684676
    },
    {
      "id": 336,
      "seek": 228084,
      "start": 2295.2400000000002,
      "end": 2302.28,
      "text": " Because notice that the number of such edges is bounded by a function of K, by a function of,",
      "tokens": [
        51084,
        1436,
        3449,
        300,
        264,
        1230,
        295,
        1270,
        8819,
        307,
        37498,
        538,
        257,
        2445,
        295,
        591,
        11,
        538,
        257,
        2445,
        295,
        11,
        51436
      ],
      "temperature": 0.0,
      "avg_logprob": -0.115556271870931,
      "compression_ratio": 1.6575342465753424,
      "no_speech_prob": 0.0006801807903684676
    },
    {
      "id": 337,
      "seek": 228084,
      "start": 2302.28,
      "end": 2310.76,
      "text": " yes, K and P. So you can make these edges, subdivide them as many times as",
      "tokens": [
        51436,
        2086,
        11,
        591,
        293,
        430,
        13,
        407,
        291,
        393,
        652,
        613,
        8819,
        11,
        45331,
        482,
        552,
        382,
        867,
        1413,
        382,
        51860
      ],
      "temperature": 0.0,
      "avg_logprob": -0.115556271870931,
      "compression_ratio": 1.6575342465753424,
      "no_speech_prob": 0.0006801807903684676
    },
    {
      "id": 338,
      "seek": 231076,
      "start": 2310.76,
      "end": 2316.92,
      "text": " needed, add as many tokens as needed to maintain all the properties that we need, and to maintain",
      "tokens": [
        50364,
        2978,
        11,
        909,
        382,
        867,
        22667,
        382,
        2978,
        281,
        6909,
        439,
        264,
        7221,
        300,
        321,
        643,
        11,
        293,
        281,
        6909,
        50672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11383841883751654,
      "compression_ratio": 1.4915254237288136,
      "no_speech_prob": 0.0005570774665102363
    },
    {
      "id": 339,
      "seek": 231076,
      "start": 2316.92,
      "end": 2322.84,
      "text": " that we're going from one maximum independent set to the other, which will give you W1 hardness",
      "tokens": [
        50672,
        300,
        321,
        434,
        516,
        490,
        472,
        6674,
        6695,
        992,
        281,
        264,
        661,
        11,
        597,
        486,
        976,
        291,
        343,
        16,
        44019,
        50968
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11383841883751654,
      "compression_ratio": 1.4915254237288136,
      "no_speech_prob": 0.0005570774665102363
    },
    {
      "id": 340,
      "seek": 231076,
      "start": 2322.84,
      "end": 2335.2400000000002,
      "text": " for both token sliding as well as token jumping. All right. Questions?",
      "tokens": [
        50968,
        337,
        1293,
        14862,
        21169,
        382,
        731,
        382,
        14862,
        11233,
        13,
        1057,
        558,
        13,
        27738,
        30,
        51588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11383841883751654,
      "compression_ratio": 1.4915254237288136,
      "no_speech_prob": 0.0005570774665102363
    },
    {
      "id": 341,
      "seek": 234076,
      "start": 2341.48,
      "end": 2350.76,
      "text": " No questions. All right. So let's keep going.",
      "tokens": [
        50400,
        883,
        1651,
        13,
        1057,
        558,
        13,
        407,
        718,
        311,
        1066,
        516,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14638852382051773,
      "compression_ratio": 1.5503355704697988,
      "no_speech_prob": 0.000371085770893842
    },
    {
      "id": 342,
      "seek": 234076,
      "start": 2353.7200000000003,
      "end": 2360.5200000000004,
      "text": " So now I'm going to talk about some positive, a positive result. So the result that I'm going",
      "tokens": [
        51012,
        407,
        586,
        286,
        478,
        516,
        281,
        751,
        466,
        512,
        3353,
        11,
        257,
        3353,
        1874,
        13,
        407,
        264,
        1874,
        300,
        286,
        478,
        516,
        51352
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14638852382051773,
      "compression_ratio": 1.5503355704697988,
      "no_speech_prob": 0.000371085770893842
    },
    {
      "id": 343,
      "seek": 234076,
      "start": 2360.5200000000004,
      "end": 2369.5600000000004,
      "text": " to talk about is this one here. Right? So I'm going to show you that on C3, C4 free graphs,",
      "tokens": [
        51352,
        281,
        751,
        466,
        307,
        341,
        472,
        510,
        13,
        1779,
        30,
        407,
        286,
        478,
        516,
        281,
        855,
        291,
        300,
        322,
        383,
        18,
        11,
        383,
        19,
        1737,
        24877,
        11,
        51804
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14638852382051773,
      "compression_ratio": 1.5503355704697988,
      "no_speech_prob": 0.000371085770893842
    },
    {
      "id": 344,
      "seek": 236956,
      "start": 2370.04,
      "end": 2378.12,
      "text": " token jumping is actually FPT and has a quadratic kernel. But again, what we will show is a stronger",
      "tokens": [
        50388,
        14862,
        11233,
        307,
        767,
        36655,
        51,
        293,
        575,
        257,
        37262,
        28256,
        13,
        583,
        797,
        11,
        437,
        321,
        486,
        855,
        307,
        257,
        7249,
        50792
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10144419897170294,
      "compression_ratio": 1.7216494845360826,
      "no_speech_prob": 0.00044625066220760345
    },
    {
      "id": 345,
      "seek": 236956,
      "start": 2378.12,
      "end": 2383.56,
      "text": " result. So what we will show is the following theorem. What we will show",
      "tokens": [
        50792,
        1874,
        13,
        407,
        437,
        321,
        486,
        855,
        307,
        264,
        3480,
        20904,
        13,
        708,
        321,
        486,
        855,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10144419897170294,
      "compression_ratio": 1.7216494845360826,
      "no_speech_prob": 0.00044625066220760345
    },
    {
      "id": 346,
      "seek": 236956,
      "start": 2386.7599999999998,
      "end": 2390.7599999999998,
      "text": " is, can be summarized as follows. So if you look at any graph,",
      "tokens": [
        51224,
        307,
        11,
        393,
        312,
        14611,
        1602,
        382,
        10002,
        13,
        407,
        498,
        291,
        574,
        412,
        604,
        4295,
        11,
        51424
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10144419897170294,
      "compression_ratio": 1.7216494845360826,
      "no_speech_prob": 0.00044625066220760345
    },
    {
      "id": 347,
      "seek": 236956,
      "start": 2392.84,
      "end": 2397.96,
      "text": " or at any instance of the token jumping problem, so remember an instance of token jumping has the",
      "tokens": [
        51528,
        420,
        412,
        604,
        5197,
        295,
        264,
        14862,
        11233,
        1154,
        11,
        370,
        1604,
        364,
        5197,
        295,
        14862,
        11233,
        575,
        264,
        51784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10144419897170294,
      "compression_ratio": 1.7216494845360826,
      "no_speech_prob": 0.00044625066220760345
    },
    {
      "id": 348,
      "seek": 239796,
      "start": 2398.04,
      "end": 2402.84,
      "text": " input graph, the starting set, the target set, and K as the number of tokens.",
      "tokens": [
        50368,
        4846,
        4295,
        11,
        264,
        2891,
        992,
        11,
        264,
        3779,
        992,
        11,
        293,
        591,
        382,
        264,
        1230,
        295,
        22667,
        13,
        50608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08753796799542153,
      "compression_ratio": 1.6058823529411765,
      "no_speech_prob": 0.0002757646725513041
    },
    {
      "id": 349,
      "seek": 239796,
      "start": 2404.52,
      "end": 2413.7200000000003,
      "text": " So let me try and draw something here. So if you look at your graph, you can kind of decompose it",
      "tokens": [
        50692,
        407,
        718,
        385,
        853,
        293,
        2642,
        746,
        510,
        13,
        407,
        498,
        291,
        574,
        412,
        428,
        4295,
        11,
        291,
        393,
        733,
        295,
        22867,
        541,
        309,
        51152
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08753796799542153,
      "compression_ratio": 1.6058823529411765,
      "no_speech_prob": 0.0002757646725513041
    },
    {
      "id": 350,
      "seek": 239796,
      "start": 2413.7200000000003,
      "end": 2421.08,
      "text": " into something which is more or less as follows. So you have S, you have T, the intersection need",
      "tokens": [
        51152,
        666,
        746,
        597,
        307,
        544,
        420,
        1570,
        382,
        10002,
        13,
        407,
        291,
        362,
        318,
        11,
        291,
        362,
        314,
        11,
        264,
        15236,
        643,
        51520
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08753796799542153,
      "compression_ratio": 1.6058823529411765,
      "no_speech_prob": 0.0002757646725513041
    },
    {
      "id": 351,
      "seek": 242108,
      "start": 2421.08,
      "end": 2430.2799999999997,
      "text": " not be empty. And then you have the neighborhood of S, you need T. And then you have the rest of the",
      "tokens": [
        50364,
        406,
        312,
        6707,
        13,
        400,
        550,
        291,
        362,
        264,
        7630,
        295,
        318,
        11,
        291,
        643,
        314,
        13,
        400,
        550,
        291,
        362,
        264,
        1472,
        295,
        264,
        50824
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1301706779834836,
      "compression_ratio": 1.9235668789808917,
      "no_speech_prob": 0.0024571071844547987
    },
    {
      "id": 352,
      "seek": 242108,
      "start": 2430.2799999999997,
      "end": 2439.48,
      "text": " graph. So we're going to call the rest of the graph H. And we're going to call the closed neighborhood",
      "tokens": [
        50824,
        4295,
        13,
        407,
        321,
        434,
        516,
        281,
        818,
        264,
        1472,
        295,
        264,
        4295,
        389,
        13,
        400,
        321,
        434,
        516,
        281,
        818,
        264,
        5395,
        7630,
        51284
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1301706779834836,
      "compression_ratio": 1.9235668789808917,
      "no_speech_prob": 0.0024571071844547987
    },
    {
      "id": 353,
      "seek": 242108,
      "start": 2439.48,
      "end": 2448.6,
      "text": " of S, you need T, or if you will, this yellow part here, we call that J. Right? So we can think of",
      "tokens": [
        51284,
        295,
        318,
        11,
        291,
        643,
        314,
        11,
        420,
        498,
        291,
        486,
        11,
        341,
        5566,
        644,
        510,
        11,
        321,
        818,
        300,
        508,
        13,
        1779,
        30,
        407,
        321,
        393,
        519,
        295,
        51740
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1301706779834836,
      "compression_ratio": 1.9235668789808917,
      "no_speech_prob": 0.0024571071844547987
    },
    {
      "id": 354,
      "seek": 244860,
      "start": 2448.6,
      "end": 2457.56,
      "text": " our problem of our graph as being decomposed into those two areas, H and J. Okay, so the theorem",
      "tokens": [
        50364,
        527,
        1154,
        295,
        527,
        4295,
        382,
        885,
        22867,
        1744,
        666,
        729,
        732,
        3179,
        11,
        389,
        293,
        508,
        13,
        1033,
        11,
        370,
        264,
        20904,
        50812
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10109644876399511,
      "compression_ratio": 1.608187134502924,
      "no_speech_prob": 0.00026930266176350415
    },
    {
      "id": 355,
      "seek": 244860,
      "start": 2457.56,
      "end": 2465.4,
      "text": " states the following. If H is epsilon sparse, where epsilon sparse means that the number of",
      "tokens": [
        50812,
        4368,
        264,
        3480,
        13,
        759,
        389,
        307,
        17889,
        637,
        11668,
        11,
        689,
        17889,
        637,
        11668,
        1355,
        300,
        264,
        1230,
        295,
        51204
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10109644876399511,
      "compression_ratio": 1.608187134502924,
      "no_speech_prob": 0.00026930266176350415
    },
    {
      "id": 356,
      "seek": 244860,
      "start": 2465.4,
      "end": 2471.96,
      "text": " edges is at most N squared minus epsilon, positive epsilon. So if H is epsilon sparse,",
      "tokens": [
        51204,
        8819,
        307,
        412,
        881,
        426,
        8889,
        3175,
        17889,
        11,
        3353,
        17889,
        13,
        407,
        498,
        389,
        307,
        17889,
        637,
        11668,
        11,
        51532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10109644876399511,
      "compression_ratio": 1.608187134502924,
      "no_speech_prob": 0.00026930266176350415
    },
    {
      "id": 357,
      "seek": 247196,
      "start": 2472.68,
      "end": 2481.32,
      "text": " and J is C3, C4 free, then the problem admits a kernel, which is that big,",
      "tokens": [
        50400,
        293,
        508,
        307,
        383,
        18,
        11,
        383,
        19,
        1737,
        11,
        550,
        264,
        1154,
        46682,
        257,
        28256,
        11,
        597,
        307,
        300,
        955,
        11,
        50832
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16064789356329504,
      "compression_ratio": 1.4806629834254144,
      "no_speech_prob": 0.0005830339505337179
    },
    {
      "id": 358,
      "seek": 247196,
      "start": 2481.32,
      "end": 2489.7200000000003,
      "text": " k squared plus k into one plus one over epsilon. So notice now that we only need that H is epsilon",
      "tokens": [
        50832,
        350,
        8889,
        1804,
        350,
        666,
        472,
        1804,
        472,
        670,
        17889,
        13,
        407,
        3449,
        586,
        300,
        321,
        787,
        643,
        300,
        389,
        307,
        17889,
        51252
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16064789356329504,
      "compression_ratio": 1.4806629834254144,
      "no_speech_prob": 0.0005830339505337179
    },
    {
      "id": 359,
      "seek": 247196,
      "start": 2489.7200000000003,
      "end": 2498.92,
      "text": " sparse. And we only require C3, C4, freeness inside J, which is S union T closed neighborhood,",
      "tokens": [
        51252,
        637,
        11668,
        13,
        400,
        321,
        787,
        3651,
        383,
        18,
        11,
        383,
        19,
        11,
        1737,
        1287,
        1854,
        508,
        11,
        597,
        307,
        318,
        11671,
        314,
        5395,
        7630,
        11,
        51712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16064789356329504,
      "compression_ratio": 1.4806629834254144,
      "no_speech_prob": 0.0005830339505337179
    },
    {
      "id": 360,
      "seek": 249892,
      "start": 2499.88,
      "end": 2501.4,
      "text": " closed neighborhood of S union T.",
      "tokens": [
        50412,
        5395,
        7630,
        295,
        318,
        11671,
        314,
        13,
        50488
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10012560355954053,
      "compression_ratio": 1.6243654822335025,
      "no_speech_prob": 0.0003434802347328514
    },
    {
      "id": 361,
      "seek": 249892,
      "start": 2505.16,
      "end": 2513.0,
      "text": " And this idea is actually, is not a new idea. So this idea is, okay, I had the drawing here,",
      "tokens": [
        50676,
        400,
        341,
        1558,
        307,
        767,
        11,
        307,
        406,
        257,
        777,
        1558,
        13,
        407,
        341,
        1558,
        307,
        11,
        1392,
        11,
        286,
        632,
        264,
        6316,
        510,
        11,
        51068
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10012560355954053,
      "compression_ratio": 1.6243654822335025,
      "no_speech_prob": 0.0003434802347328514
    },
    {
      "id": 362,
      "seek": 249892,
      "start": 2513.0,
      "end": 2519.7200000000003,
      "text": " I should have used it. So the idea comes from, has been used before. And it's what we call the",
      "tokens": [
        51068,
        286,
        820,
        362,
        1143,
        309,
        13,
        407,
        264,
        1558,
        1487,
        490,
        11,
        575,
        668,
        1143,
        949,
        13,
        400,
        309,
        311,
        437,
        321,
        818,
        264,
        51404
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10012560355954053,
      "compression_ratio": 1.6243654822335025,
      "no_speech_prob": 0.0003434802347328514
    },
    {
      "id": 363,
      "seek": 249892,
      "start": 2519.7200000000003,
      "end": 2524.44,
      "text": " buffer technique for the token jumping problem. And then the intuition behind the buffer technique",
      "tokens": [
        51404,
        21762,
        6532,
        337,
        264,
        14862,
        11233,
        1154,
        13,
        400,
        550,
        264,
        24002,
        2261,
        264,
        21762,
        6532,
        51640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10012560355954053,
      "compression_ratio": 1.6243654822335025,
      "no_speech_prob": 0.0003434802347328514
    },
    {
      "id": 364,
      "seek": 252444,
      "start": 2524.44,
      "end": 2531.7200000000003,
      "text": " is very simple. So if I have S union T, but somewhere in the graph, which is not in the",
      "tokens": [
        50364,
        307,
        588,
        2199,
        13,
        407,
        498,
        286,
        362,
        318,
        11671,
        314,
        11,
        457,
        4079,
        294,
        264,
        4295,
        11,
        597,
        307,
        406,
        294,
        264,
        50728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0864683472832968,
      "compression_ratio": 1.7234042553191489,
      "no_speech_prob": 0.0008361625368706882
    },
    {
      "id": 365,
      "seek": 252444,
      "start": 2531.7200000000003,
      "end": 2537.2400000000002,
      "text": " closed neighborhood of S union T, I have a case sized independent set, then you are done.",
      "tokens": [
        50728,
        5395,
        7630,
        295,
        318,
        11671,
        314,
        11,
        286,
        362,
        257,
        1389,
        20004,
        6695,
        992,
        11,
        550,
        291,
        366,
        1096,
        13,
        51004
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0864683472832968,
      "compression_ratio": 1.7234042553191489,
      "no_speech_prob": 0.0008361625368706882
    },
    {
      "id": 366,
      "seek": 252444,
      "start": 2538.36,
      "end": 2541.32,
      "text": " Right, if I have a case sized independent set in H,",
      "tokens": [
        51060,
        1779,
        11,
        498,
        286,
        362,
        257,
        1389,
        20004,
        6695,
        992,
        294,
        389,
        11,
        51208
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0864683472832968,
      "compression_ratio": 1.7234042553191489,
      "no_speech_prob": 0.0008361625368706882
    },
    {
      "id": 367,
      "seek": 252444,
      "start": 2542.84,
      "end": 2549.96,
      "text": " then you're done. You can basically take all the tokens on S, jump them into those independent",
      "tokens": [
        51284,
        550,
        291,
        434,
        1096,
        13,
        509,
        393,
        1936,
        747,
        439,
        264,
        22667,
        322,
        318,
        11,
        3012,
        552,
        666,
        729,
        6695,
        51640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0864683472832968,
      "compression_ratio": 1.7234042553191489,
      "no_speech_prob": 0.0008361625368706882
    },
    {
      "id": 368,
      "seek": 254996,
      "start": 2549.96,
      "end": 2557.4,
      "text": " yellow vertices in H, and then jump them back to T. So in some sense, when H has a large independent",
      "tokens": [
        50364,
        5566,
        32053,
        294,
        389,
        11,
        293,
        550,
        3012,
        552,
        646,
        281,
        314,
        13,
        407,
        294,
        512,
        2020,
        11,
        562,
        389,
        575,
        257,
        2416,
        6695,
        50736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07706886867307267,
      "compression_ratio": 1.5967078189300412,
      "no_speech_prob": 0.0002125878381775692
    },
    {
      "id": 369,
      "seek": 254996,
      "start": 2557.4,
      "end": 2564.52,
      "text": " set, that's the easy case. Right, you're done. If you can find a large enough independent set in H,",
      "tokens": [
        50736,
        992,
        11,
        300,
        311,
        264,
        1858,
        1389,
        13,
        1779,
        11,
        291,
        434,
        1096,
        13,
        759,
        291,
        393,
        915,
        257,
        2416,
        1547,
        6695,
        992,
        294,
        389,
        11,
        51092
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07706886867307267,
      "compression_ratio": 1.5967078189300412,
      "no_speech_prob": 0.0002125878381775692
    },
    {
      "id": 370,
      "seek": 254996,
      "start": 2564.52,
      "end": 2570.2,
      "text": " you're done. And that's what we call the buffer technique, because it's been also used to show",
      "tokens": [
        51092,
        291,
        434,
        1096,
        13,
        400,
        300,
        311,
        437,
        321,
        818,
        264,
        21762,
        6532,
        11,
        570,
        309,
        311,
        668,
        611,
        1143,
        281,
        855,
        51376
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07706886867307267,
      "compression_ratio": 1.5967078189300412,
      "no_speech_prob": 0.0002125878381775692
    },
    {
      "id": 371,
      "seek": 254996,
      "start": 2570.2,
      "end": 2577.48,
      "text": " that the problem is FPT on planar graphs, for example, or K3J free graphs, so graphs without",
      "tokens": [
        51376,
        300,
        264,
        1154,
        307,
        36655,
        51,
        322,
        1393,
        289,
        24877,
        11,
        337,
        1365,
        11,
        420,
        591,
        18,
        41,
        1737,
        24877,
        11,
        370,
        24877,
        1553,
        51740
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07706886867307267,
      "compression_ratio": 1.5967078189300412,
      "no_speech_prob": 0.0002125878381775692
    },
    {
      "id": 372,
      "seek": 257748,
      "start": 2577.48,
      "end": 2586.04,
      "text": " large bikings. So it's a well known technique. All right.",
      "tokens": [
        50364,
        2416,
        26730,
        1109,
        13,
        407,
        309,
        311,
        257,
        731,
        2570,
        6532,
        13,
        1057,
        558,
        13,
        50792
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1305812542255108,
      "compression_ratio": 1.5182926829268293,
      "no_speech_prob": 0.0002964128798339516
    },
    {
      "id": 373,
      "seek": 257748,
      "start": 2589.16,
      "end": 2594.04,
      "text": " So what do we show? So we're going to use the buffer technique, and we're going to combine it with",
      "tokens": [
        50948,
        407,
        437,
        360,
        321,
        855,
        30,
        407,
        321,
        434,
        516,
        281,
        764,
        264,
        21762,
        6532,
        11,
        293,
        321,
        434,
        516,
        281,
        10432,
        309,
        365,
        51192
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1305812542255108,
      "compression_ratio": 1.5182926829268293,
      "no_speech_prob": 0.0002964128798339516
    },
    {
      "id": 374,
      "seek": 257748,
      "start": 2594.04,
      "end": 2603.4,
      "text": " something else. So we show that you have a yes instance whenever one of those two conditions",
      "tokens": [
        51192,
        746,
        1646,
        13,
        407,
        321,
        855,
        300,
        291,
        362,
        257,
        2086,
        5197,
        5699,
        472,
        295,
        729,
        732,
        4487,
        51660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1305812542255108,
      "compression_ratio": 1.5182926829268293,
      "no_speech_prob": 0.0002964128798339516
    },
    {
      "id": 375,
      "seek": 260340,
      "start": 2603.4,
      "end": 2613.08,
      "text": " is true. The first condition is that H is epsilon sparse and contains more than this many vertices.",
      "tokens": [
        50364,
        307,
        2074,
        13,
        440,
        700,
        4188,
        307,
        300,
        389,
        307,
        17889,
        637,
        11668,
        293,
        8306,
        544,
        813,
        341,
        867,
        32053,
        13,
        50848
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08662188990732257,
      "compression_ratio": 1.821256038647343,
      "no_speech_prob": 0.0003449651994742453
    },
    {
      "id": 376,
      "seek": 260340,
      "start": 2614.52,
      "end": 2621.0,
      "text": " And this is relatively easy. When you contain this many vertices and you add epsilon sparse,",
      "tokens": [
        50920,
        400,
        341,
        307,
        7226,
        1858,
        13,
        1133,
        291,
        5304,
        341,
        867,
        32053,
        293,
        291,
        909,
        17889,
        637,
        11668,
        11,
        51244
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08662188990732257,
      "compression_ratio": 1.821256038647343,
      "no_speech_prob": 0.0003449651994742453
    },
    {
      "id": 377,
      "seek": 260340,
      "start": 2621.0,
      "end": 2625.56,
      "text": " then you will have a case sized independent set. And that's basically the buffer technique.",
      "tokens": [
        51244,
        550,
        291,
        486,
        362,
        257,
        1389,
        20004,
        6695,
        992,
        13,
        400,
        300,
        311,
        1936,
        264,
        21762,
        6532,
        13,
        51472
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08662188990732257,
      "compression_ratio": 1.821256038647343,
      "no_speech_prob": 0.0003449651994742453
    },
    {
      "id": 378,
      "seek": 260340,
      "start": 2626.44,
      "end": 2631.96,
      "text": " When H is epsilon sparse and has that many vertices or more, then H is guaranteed to have an",
      "tokens": [
        51516,
        1133,
        389,
        307,
        17889,
        637,
        11668,
        293,
        575,
        300,
        867,
        32053,
        420,
        544,
        11,
        550,
        389,
        307,
        18031,
        281,
        362,
        364,
        51792
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08662188990732257,
      "compression_ratio": 1.821256038647343,
      "no_speech_prob": 0.0003449651994742453
    },
    {
      "id": 379,
      "seek": 263196,
      "start": 2631.96,
      "end": 2638.68,
      "text": " independent set of size K and you're done. So now you are stuck with what happens inside J,",
      "tokens": [
        50364,
        6695,
        992,
        295,
        2744,
        591,
        293,
        291,
        434,
        1096,
        13,
        407,
        586,
        291,
        366,
        5541,
        365,
        437,
        2314,
        1854,
        508,
        11,
        50700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16166226069132486,
      "compression_ratio": 1.4467005076142132,
      "no_speech_prob": 0.0003258284996263683
    },
    {
      "id": 380,
      "seek": 263196,
      "start": 2639.64,
      "end": 2646.68,
      "text": " or the closed neighborhood of S union T. And it turns out there, if you have C3C4 freeness,",
      "tokens": [
        50748,
        420,
        264,
        5395,
        7630,
        295,
        318,
        11671,
        314,
        13,
        400,
        309,
        4523,
        484,
        456,
        11,
        498,
        291,
        362,
        383,
        18,
        34,
        19,
        2130,
        15264,
        11,
        51100
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16166226069132486,
      "compression_ratio": 1.4467005076142132,
      "no_speech_prob": 0.0003258284996263683
    },
    {
      "id": 381,
      "seek": 263196,
      "start": 2646.68,
      "end": 2654.12,
      "text": " the only thing you need on top of that to guarantee a yes instance is a vertex of degree at least 3K.",
      "tokens": [
        51100,
        264,
        787,
        551,
        291,
        643,
        322,
        1192,
        295,
        300,
        281,
        10815,
        257,
        2086,
        5197,
        307,
        257,
        28162,
        295,
        4314,
        412,
        1935,
        805,
        42,
        13,
        51472
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16166226069132486,
      "compression_ratio": 1.4467005076142132,
      "no_speech_prob": 0.0003258284996263683
    },
    {
      "id": 382,
      "seek": 265412,
      "start": 2654.3599999999997,
      "end": 2664.52,
      "text": " So if you have C3C4 freeness inside J and the vertex of degree 3K, then again, you get a yes",
      "tokens": [
        50376,
        407,
        498,
        291,
        362,
        383,
        18,
        34,
        19,
        2130,
        15264,
        1854,
        508,
        293,
        264,
        28162,
        295,
        4314,
        805,
        42,
        11,
        550,
        797,
        11,
        291,
        483,
        257,
        2086,
        50884
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14514834086100262,
      "compression_ratio": 1.5164835164835164,
      "no_speech_prob": 0.0005502957501448691
    },
    {
      "id": 383,
      "seek": 265412,
      "start": 2664.52,
      "end": 2672.7599999999998,
      "text": " instance. So let me prove those two statements separately, because they will be basically",
      "tokens": [
        50884,
        5197,
        13,
        407,
        718,
        385,
        7081,
        729,
        732,
        12363,
        14759,
        11,
        570,
        436,
        486,
        312,
        1936,
        51296
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14514834086100262,
      "compression_ratio": 1.5164835164835164,
      "no_speech_prob": 0.0005502957501448691
    },
    {
      "id": 384,
      "seek": 265412,
      "start": 2673.7999999999997,
      "end": 2682.04,
      "text": " what we need for the final theorem, for the final theorem. So the first lemma, as I told you,",
      "tokens": [
        51348,
        437,
        321,
        643,
        337,
        264,
        2572,
        20904,
        11,
        337,
        264,
        2572,
        20904,
        13,
        407,
        264,
        700,
        7495,
        1696,
        11,
        382,
        286,
        1907,
        291,
        11,
        51760
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14514834086100262,
      "compression_ratio": 1.5164835164835164,
      "no_speech_prob": 0.0005502957501448691
    },
    {
      "id": 385,
      "seek": 268204,
      "start": 2682.04,
      "end": 2688.92,
      "text": " if H is epsilon sparse and has more than this many vertices, then it's a yes instance, because you",
      "tokens": [
        50364,
        498,
        389,
        307,
        17889,
        637,
        11668,
        293,
        575,
        544,
        813,
        341,
        867,
        32053,
        11,
        550,
        309,
        311,
        257,
        2086,
        5197,
        11,
        570,
        291,
        50708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0954493232395338,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 8.65017282194458e-05
    },
    {
      "id": 386,
      "seek": 268204,
      "start": 2688.92,
      "end": 2695.56,
      "text": " have a case sized independent set in H. The idea of this proof is simple. It's a counting argument.",
      "tokens": [
        50708,
        362,
        257,
        1389,
        20004,
        6695,
        992,
        294,
        389,
        13,
        440,
        1558,
        295,
        341,
        8177,
        307,
        2199,
        13,
        467,
        311,
        257,
        13251,
        6770,
        13,
        51040
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0954493232395338,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 8.65017282194458e-05
    },
    {
      "id": 387,
      "seek": 268204,
      "start": 2696.2,
      "end": 2701.4,
      "text": " And what you need to do basically first is to show that H must contain a vertex of degree",
      "tokens": [
        51072,
        400,
        437,
        291,
        643,
        281,
        360,
        1936,
        700,
        307,
        281,
        855,
        300,
        389,
        1633,
        5304,
        257,
        28162,
        295,
        4314,
        51332
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0954493232395338,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 8.65017282194458e-05
    },
    {
      "id": 388,
      "seek": 268204,
      "start": 2701.4,
      "end": 2707.96,
      "text": " less than an over K. And then basically you apply the standard greedy packing algorithm for",
      "tokens": [
        51332,
        1570,
        813,
        364,
        670,
        591,
        13,
        400,
        550,
        1936,
        291,
        3079,
        264,
        3832,
        28228,
        20815,
        9284,
        337,
        51660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0954493232395338,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 8.65017282194458e-05
    },
    {
      "id": 389,
      "seek": 270796,
      "start": 2707.96,
      "end": 2713.7200000000003,
      "text": " constructing an independent set of size K. And the reason you show that, the way you show that H",
      "tokens": [
        50364,
        39969,
        364,
        6695,
        992,
        295,
        2744,
        591,
        13,
        400,
        264,
        1778,
        291,
        855,
        300,
        11,
        264,
        636,
        291,
        855,
        300,
        389,
        50652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1035796087615344,
      "compression_ratio": 1.620253164556962,
      "no_speech_prob": 0.0003436298866290599
    },
    {
      "id": 390,
      "seek": 270796,
      "start": 2713.7200000000003,
      "end": 2720.2,
      "text": " has a vertex of degree less than N over K is, again, standard counting argument and the hand",
      "tokens": [
        50652,
        575,
        257,
        28162,
        295,
        4314,
        1570,
        813,
        426,
        670,
        591,
        307,
        11,
        797,
        11,
        3832,
        13251,
        6770,
        293,
        264,
        1011,
        50976
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1035796087615344,
      "compression_ratio": 1.620253164556962,
      "no_speech_prob": 0.0003436298866290599
    },
    {
      "id": 391,
      "seek": 270796,
      "start": 2720.2,
      "end": 2726.76,
      "text": " shaking lemma. So if the minimum degree in H was at least N over K, then the number of edges would",
      "tokens": [
        50976,
        15415,
        7495,
        1696,
        13,
        407,
        498,
        264,
        7285,
        4314,
        294,
        389,
        390,
        412,
        1935,
        426,
        670,
        591,
        11,
        550,
        264,
        1230,
        295,
        8819,
        576,
        51304
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1035796087615344,
      "compression_ratio": 1.620253164556962,
      "no_speech_prob": 0.0003436298866290599
    },
    {
      "id": 392,
      "seek": 270796,
      "start": 2726.76,
      "end": 2735.16,
      "text": " be at least N squared over 2K, which will only happen in an epsilon sparse graph when N is less",
      "tokens": [
        51304,
        312,
        412,
        1935,
        426,
        8889,
        670,
        568,
        42,
        11,
        597,
        486,
        787,
        1051,
        294,
        364,
        17889,
        637,
        11668,
        4295,
        562,
        426,
        307,
        1570,
        51724
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1035796087615344,
      "compression_ratio": 1.620253164556962,
      "no_speech_prob": 0.0003436298866290599
    },
    {
      "id": 393,
      "seek": 273516,
      "start": 2735.16,
      "end": 2742.7599999999998,
      "text": " than or equal to K to the power 1 over epsilon. And the rest of the proof is basically an induction",
      "tokens": [
        50364,
        813,
        420,
        2681,
        281,
        591,
        281,
        264,
        1347,
        502,
        670,
        17889,
        13,
        400,
        264,
        1472,
        295,
        264,
        8177,
        307,
        1936,
        364,
        33371,
        50744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08966839150206683,
      "compression_ratio": 1.569060773480663,
      "no_speech_prob": 0.0003202217922080308
    },
    {
      "id": 394,
      "seek": 273516,
      "start": 2742.7599999999998,
      "end": 2750.2,
      "text": " on K. And so that shows you that when you do have an epsilon sparse graph with more than",
      "tokens": [
        50744,
        322,
        591,
        13,
        400,
        370,
        300,
        3110,
        291,
        300,
        562,
        291,
        360,
        362,
        364,
        17889,
        637,
        11668,
        4295,
        365,
        544,
        813,
        51116
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08966839150206683,
      "compression_ratio": 1.569060773480663,
      "no_speech_prob": 0.0003202217922080308
    },
    {
      "id": 395,
      "seek": 273516,
      "start": 2750.7599999999998,
      "end": 2759.64,
      "text": " this many vertices, then we have a yes instance. All right, so how about the second part of the",
      "tokens": [
        51144,
        341,
        867,
        32053,
        11,
        550,
        321,
        362,
        257,
        2086,
        5197,
        13,
        1057,
        558,
        11,
        370,
        577,
        466,
        264,
        1150,
        644,
        295,
        264,
        51588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08966839150206683,
      "compression_ratio": 1.569060773480663,
      "no_speech_prob": 0.0003202217922080308
    },
    {
      "id": 396,
      "seek": 275964,
      "start": 2759.64,
      "end": 2766.12,
      "text": " claim? So now what happens if we have a C3 C4 free J that has a vertex of degree 3K?",
      "tokens": [
        50364,
        3932,
        30,
        407,
        586,
        437,
        2314,
        498,
        321,
        362,
        257,
        383,
        18,
        383,
        19,
        1737,
        508,
        300,
        575,
        257,
        28162,
        295,
        4314,
        805,
        42,
        30,
        50688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11191834853245662,
      "compression_ratio": 1.7488151658767772,
      "no_speech_prob": 0.0024629004765301943
    },
    {
      "id": 397,
      "seek": 275964,
      "start": 2767.0,
      "end": 2772.44,
      "text": " Well, let's see what happens. So if we have a vertex of degree 3K, and I'm going to",
      "tokens": [
        50732,
        1042,
        11,
        718,
        311,
        536,
        437,
        2314,
        13,
        407,
        498,
        321,
        362,
        257,
        28162,
        295,
        4314,
        805,
        42,
        11,
        293,
        286,
        478,
        516,
        281,
        51004
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11191834853245662,
      "compression_ratio": 1.7488151658767772,
      "no_speech_prob": 0.0024629004765301943
    },
    {
      "id": 398,
      "seek": 275964,
      "start": 2773.72,
      "end": 2780.92,
      "text": " circle it here in yellow. So how can the neighborhood of that vertex look? Well, we know that J is C3 free.",
      "tokens": [
        51068,
        6329,
        309,
        510,
        294,
        5566,
        13,
        407,
        577,
        393,
        264,
        7630,
        295,
        300,
        28162,
        574,
        30,
        1042,
        11,
        321,
        458,
        300,
        508,
        307,
        383,
        18,
        1737,
        13,
        51428
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11191834853245662,
      "compression_ratio": 1.7488151658767772,
      "no_speech_prob": 0.0024629004765301943
    },
    {
      "id": 399,
      "seek": 275964,
      "start": 2781.48,
      "end": 2787.08,
      "text": " So the blue edges cannot exist, which means that the neighborhood of the yellow vertex is an",
      "tokens": [
        51456,
        407,
        264,
        3344,
        8819,
        2644,
        2514,
        11,
        597,
        1355,
        300,
        264,
        7630,
        295,
        264,
        5566,
        28162,
        307,
        364,
        51736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11191834853245662,
      "compression_ratio": 1.7488151658767772,
      "no_speech_prob": 0.0024629004765301943
    },
    {
      "id": 400,
      "seek": 278708,
      "start": 2787.08,
      "end": 2794.92,
      "text": " independent set inside J, not in the whole graph. Well, in fact, in the whole well, no,",
      "tokens": [
        50364,
        6695,
        992,
        1854,
        508,
        11,
        406,
        294,
        264,
        1379,
        4295,
        13,
        1042,
        11,
        294,
        1186,
        11,
        294,
        264,
        1379,
        731,
        11,
        572,
        11,
        50756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1221716562906901,
      "compression_ratio": 1.5423728813559323,
      "no_speech_prob": 0.00038688888889737427
    },
    {
      "id": 401,
      "seek": 278708,
      "start": 2794.92,
      "end": 2802.52,
      "text": " because we're only talking about J as a sub graph. Right. So the blue edges cannot exist,",
      "tokens": [
        50756,
        570,
        321,
        434,
        787,
        1417,
        466,
        508,
        382,
        257,
        1422,
        4295,
        13,
        1779,
        13,
        407,
        264,
        3344,
        8819,
        2644,
        2514,
        11,
        51136
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1221716562906901,
      "compression_ratio": 1.5423728813559323,
      "no_speech_prob": 0.00038688888889737427
    },
    {
      "id": 402,
      "seek": 278708,
      "start": 2802.52,
      "end": 2813.72,
      "text": " because otherwise we will get a C3 inside J. All right. So now let's look at the other vertices",
      "tokens": [
        51136,
        570,
        5911,
        321,
        486,
        483,
        257,
        383,
        18,
        1854,
        508,
        13,
        1057,
        558,
        13,
        407,
        586,
        718,
        311,
        574,
        412,
        264,
        661,
        32053,
        51696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1221716562906901,
      "compression_ratio": 1.5423728813559323,
      "no_speech_prob": 0.00038688888889737427
    },
    {
      "id": 403,
      "seek": 281372,
      "start": 2813.72,
      "end": 2821.64,
      "text": " in S-Union T. The other, the second observation that you need is that any vertex other than the",
      "tokens": [
        50364,
        294,
        318,
        12,
        12405,
        313,
        314,
        13,
        440,
        661,
        11,
        264,
        1150,
        14816,
        300,
        291,
        643,
        307,
        300,
        604,
        28162,
        661,
        813,
        264,
        50760
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1175280777183739,
      "compression_ratio": 1.6179775280898876,
      "no_speech_prob": 0.0007784392801113427
    },
    {
      "id": 404,
      "seek": 281372,
      "start": 2821.64,
      "end": 2828.12,
      "text": " yellow vertex can have at most one neighbor in common with the yellow vertex. Because if you do",
      "tokens": [
        50760,
        5566,
        28162,
        393,
        362,
        412,
        881,
        472,
        5987,
        294,
        2689,
        365,
        264,
        5566,
        28162,
        13,
        1436,
        498,
        291,
        360,
        51084
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1175280777183739,
      "compression_ratio": 1.6179775280898876,
      "no_speech_prob": 0.0007784392801113427
    },
    {
      "id": 405,
      "seek": 281372,
      "start": 2828.12,
      "end": 2839.48,
      "text": " have two neighbors in common, then you will get a C4. So now what happens if we have 3K vertices",
      "tokens": [
        51084,
        362,
        732,
        12512,
        294,
        2689,
        11,
        550,
        291,
        486,
        483,
        257,
        383,
        19,
        13,
        407,
        586,
        437,
        2314,
        498,
        321,
        362,
        805,
        42,
        32053,
        51652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1175280777183739,
      "compression_ratio": 1.6179775280898876,
      "no_speech_prob": 0.0007784392801113427
    },
    {
      "id": 406,
      "seek": 283948,
      "start": 2839.48,
      "end": 2845.48,
      "text": " in the neighborhood of the yellow vertex? Well, at most 2K of them can be connected",
      "tokens": [
        50364,
        294,
        264,
        7630,
        295,
        264,
        5566,
        28162,
        30,
        1042,
        11,
        412,
        881,
        568,
        42,
        295,
        552,
        393,
        312,
        4582,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07374519548918071,
      "compression_ratio": 1.6761904761904762,
      "no_speech_prob": 0.0006756717339158058
    },
    {
      "id": 407,
      "seek": 283948,
      "start": 2846.6,
      "end": 2852.36,
      "text": " to some vertex in S-Union T, and you will get at least K of them, some K of them here",
      "tokens": [
        50720,
        281,
        512,
        28162,
        294,
        318,
        12,
        12405,
        313,
        314,
        11,
        293,
        291,
        486,
        483,
        412,
        1935,
        591,
        295,
        552,
        11,
        512,
        591,
        295,
        552,
        510,
        51008
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07374519548918071,
      "compression_ratio": 1.6761904761904762,
      "no_speech_prob": 0.0006756717339158058
    },
    {
      "id": 408,
      "seek": 283948,
      "start": 2853.72,
      "end": 2861.72,
      "text": " that are only connected to the yellow vertex. And so now basically, instead of using a buffer",
      "tokens": [
        51076,
        300,
        366,
        787,
        4582,
        281,
        264,
        5566,
        28162,
        13,
        400,
        370,
        586,
        1936,
        11,
        2602,
        295,
        1228,
        257,
        21762,
        51476
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07374519548918071,
      "compression_ratio": 1.6761904761904762,
      "no_speech_prob": 0.0006756717339158058
    },
    {
      "id": 409,
      "seek": 283948,
      "start": 2861.72,
      "end": 2869.32,
      "text": " inside H, we have just found a buffer inside J, and we can use the same strategy. We can",
      "tokens": [
        51476,
        1854,
        389,
        11,
        321,
        362,
        445,
        1352,
        257,
        21762,
        1854,
        508,
        11,
        293,
        321,
        393,
        764,
        264,
        912,
        5206,
        13,
        492,
        393,
        51856
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07374519548918071,
      "compression_ratio": 1.6761904761904762,
      "no_speech_prob": 0.0006756717339158058
    },
    {
      "id": 410,
      "seek": 286932,
      "start": 2869.32,
      "end": 2875.56,
      "text": " jump all the tokens here, starting of course by the yellow token, and then jump them to where they",
      "tokens": [
        50364,
        3012,
        439,
        264,
        22667,
        510,
        11,
        2891,
        295,
        1164,
        538,
        264,
        5566,
        14862,
        11,
        293,
        550,
        3012,
        552,
        281,
        689,
        436,
        50676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13466588020324707,
      "compression_ratio": 1.4420289855072463,
      "no_speech_prob": 0.0002133394154952839
    },
    {
      "id": 411,
      "seek": 286932,
      "start": 2875.56,
      "end": 2892.92,
      "text": " need to go. So now combining those two, observing lemmas together, if you will, we get the following",
      "tokens": [
        50676,
        643,
        281,
        352,
        13,
        407,
        586,
        21928,
        729,
        732,
        11,
        22107,
        7495,
        3799,
        1214,
        11,
        498,
        291,
        486,
        11,
        321,
        483,
        264,
        3480,
        51544
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13466588020324707,
      "compression_ratio": 1.4420289855072463,
      "no_speech_prob": 0.0002133394154952839
    },
    {
      "id": 412,
      "seek": 289292,
      "start": 2893.0,
      "end": 2900.36,
      "text": " theorem. So if H is alpha sparse, and J is C3, C4 free, then the problem admits a kernel on this",
      "tokens": [
        50368,
        20904,
        13,
        407,
        498,
        389,
        307,
        8961,
        637,
        11668,
        11,
        293,
        508,
        307,
        383,
        18,
        11,
        383,
        19,
        1737,
        11,
        550,
        264,
        1154,
        46682,
        257,
        28256,
        322,
        341,
        50736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09371004104614258,
      "compression_ratio": 1.6567796610169492,
      "no_speech_prob": 0.1538356989622116
    },
    {
      "id": 413,
      "seek": 289292,
      "start": 2900.36,
      "end": 2907.16,
      "text": " many vertices. And it's basically a simple application of the previous two lemmas. If we have more than",
      "tokens": [
        50736,
        867,
        32053,
        13,
        400,
        309,
        311,
        1936,
        257,
        2199,
        3861,
        295,
        264,
        3894,
        732,
        7495,
        3799,
        13,
        759,
        321,
        362,
        544,
        813,
        51076
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09371004104614258,
      "compression_ratio": 1.6567796610169492,
      "no_speech_prob": 0.1538356989622116
    },
    {
      "id": 414,
      "seek": 289292,
      "start": 2907.16,
      "end": 2914.36,
      "text": " this many vertices in H, it's a trivial yes instance. If J has a vertex of degree 3K or more,",
      "tokens": [
        51076,
        341,
        867,
        32053,
        294,
        389,
        11,
        309,
        311,
        257,
        26703,
        2086,
        5197,
        13,
        759,
        508,
        575,
        257,
        28162,
        295,
        4314,
        805,
        42,
        420,
        544,
        11,
        51436
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09371004104614258,
      "compression_ratio": 1.6567796610169492,
      "no_speech_prob": 0.1538356989622116
    },
    {
      "id": 415,
      "seek": 289292,
      "start": 2914.36,
      "end": 2919.88,
      "text": " it's a trivial yes instance. And now you combine all of this together. We know that S-Union T is",
      "tokens": [
        51436,
        309,
        311,
        257,
        26703,
        2086,
        5197,
        13,
        400,
        586,
        291,
        10432,
        439,
        295,
        341,
        1214,
        13,
        492,
        458,
        300,
        318,
        12,
        12405,
        313,
        314,
        307,
        51712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09371004104614258,
      "compression_ratio": 1.6567796610169492,
      "no_speech_prob": 0.1538356989622116
    },
    {
      "id": 416,
      "seek": 291988,
      "start": 2919.88,
      "end": 2926.92,
      "text": " of size at most 2K. We know that the neighborhood of S-Union T is of size at most 2K times 3K,",
      "tokens": [
        50364,
        295,
        2744,
        412,
        881,
        568,
        42,
        13,
        492,
        458,
        300,
        264,
        7630,
        295,
        318,
        12,
        12405,
        313,
        314,
        307,
        295,
        2744,
        412,
        881,
        568,
        42,
        1413,
        805,
        42,
        11,
        50716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07816576957702637,
      "compression_ratio": 1.4802259887005649,
      "no_speech_prob": 0.0008948248578235507
    },
    {
      "id": 417,
      "seek": 291988,
      "start": 2926.92,
      "end": 2933.32,
      "text": " which is roughly 6K squared. And now we know that the rest of the graph has at most that many vertices.",
      "tokens": [
        50716,
        597,
        307,
        9810,
        1386,
        42,
        8889,
        13,
        400,
        586,
        321,
        458,
        300,
        264,
        1472,
        295,
        264,
        4295,
        575,
        412,
        881,
        300,
        867,
        32053,
        13,
        51036
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07816576957702637,
      "compression_ratio": 1.4802259887005649,
      "no_speech_prob": 0.0008948248578235507
    },
    {
      "id": 418,
      "seek": 291988,
      "start": 2934.84,
      "end": 2938.2000000000003,
      "text": " So basically, you sum up those numbers, and you get this bound.",
      "tokens": [
        51112,
        407,
        1936,
        11,
        291,
        2408,
        493,
        729,
        3547,
        11,
        293,
        291,
        483,
        341,
        5472,
        13,
        51280
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07816576957702637,
      "compression_ratio": 1.4802259887005649,
      "no_speech_prob": 0.0008948248578235507
    },
    {
      "id": 419,
      "seek": 293820,
      "start": 2938.9199999999996,
      "end": 2952.3599999999997,
      "text": " All right. So how does this theorem imply the result that I promised you to start with?",
      "tokens": [
        50400,
        1057,
        558,
        13,
        407,
        577,
        775,
        341,
        20904,
        33616,
        264,
        1874,
        300,
        286,
        10768,
        291,
        281,
        722,
        365,
        30,
        51072
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24721951484680177,
      "compression_ratio": 1.3153846153846154,
      "no_speech_prob": 0.0005726650124415755
    },
    {
      "id": 420,
      "seek": 293820,
      "start": 2955.56,
      "end": 2962.04,
      "text": " So that token jumping and token sliding admit kernel with order K squared vertices,",
      "tokens": [
        51232,
        407,
        300,
        14862,
        11233,
        293,
        14862,
        21169,
        9796,
        28256,
        365,
        1668,
        591,
        8889,
        32053,
        11,
        51556
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24721951484680177,
      "compression_ratio": 1.3153846153846154,
      "no_speech_prob": 0.0005726650124415755
    },
    {
      "id": 421,
      "seek": 296204,
      "start": 2963.0,
      "end": 2969.56,
      "text": " I mean, it also holds for bipartite C4 free graphs, obviously, because they are C3, C4 free.",
      "tokens": [
        50412,
        286,
        914,
        11,
        309,
        611,
        9190,
        337,
        28741,
        642,
        383,
        19,
        1737,
        24877,
        11,
        2745,
        11,
        570,
        436,
        366,
        383,
        18,
        11,
        383,
        19,
        1737,
        13,
        50740
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13744694477803,
      "compression_ratio": 1.4516129032258065,
      "no_speech_prob": 0.0005196536076255143
    },
    {
      "id": 422,
      "seek": 296204,
      "start": 2970.2799999999997,
      "end": 2977.4,
      "text": " So how do you get the kernel? Well, we know that J cannot contain more than 6K squared",
      "tokens": [
        50776,
        407,
        577,
        360,
        291,
        483,
        264,
        28256,
        30,
        1042,
        11,
        321,
        458,
        300,
        508,
        2644,
        5304,
        544,
        813,
        1386,
        42,
        8889,
        51132
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13744694477803,
      "compression_ratio": 1.4516129032258065,
      "no_speech_prob": 0.0005196536076255143
    },
    {
      "id": 423,
      "seek": 296204,
      "start": 2977.4,
      "end": 2986.84,
      "text": " minus 2K vertices. And we know from another theorem from another paper that C3 free graphs",
      "tokens": [
        51132,
        3175,
        568,
        42,
        32053,
        13,
        400,
        321,
        458,
        490,
        1071,
        20904,
        490,
        1071,
        3035,
        300,
        383,
        18,
        1737,
        24877,
        51604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13744694477803,
      "compression_ratio": 1.4516129032258065,
      "no_speech_prob": 0.0005196536076255143
    },
    {
      "id": 424,
      "seek": 298684,
      "start": 2987.7200000000003,
      "end": 2992.28,
      "text": " with K squared over log K vertices must have an independent set of size at least K.",
      "tokens": [
        50408,
        365,
        591,
        8889,
        670,
        3565,
        591,
        32053,
        1633,
        362,
        364,
        6695,
        992,
        295,
        2744,
        412,
        1935,
        591,
        13,
        50636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1072603935419127,
      "compression_ratio": 1.640552995391705,
      "no_speech_prob": 0.00048316558240912855
    },
    {
      "id": 425,
      "seek": 298684,
      "start": 2993.56,
      "end": 2997.96,
      "text": " And now we know that if H contains more than this many vertices, then we will get the yes",
      "tokens": [
        50700,
        400,
        586,
        321,
        458,
        300,
        498,
        389,
        8306,
        544,
        813,
        341,
        867,
        32053,
        11,
        550,
        321,
        486,
        483,
        264,
        2086,
        50920
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1072603935419127,
      "compression_ratio": 1.640552995391705,
      "no_speech_prob": 0.00048316558240912855
    },
    {
      "id": 426,
      "seek": 298684,
      "start": 2997.96,
      "end": 3005.7200000000003,
      "text": " instance as well. Right? So it becomes an immediate consequence of the previous theorem,",
      "tokens": [
        50920,
        5197,
        382,
        731,
        13,
        1779,
        30,
        407,
        309,
        3643,
        364,
        11629,
        18326,
        295,
        264,
        3894,
        20904,
        11,
        51308
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1072603935419127,
      "compression_ratio": 1.640552995391705,
      "no_speech_prob": 0.00048316558240912855
    },
    {
      "id": 427,
      "seek": 298684,
      "start": 3005.7200000000003,
      "end": 3010.52,
      "text": " but the previous theorem is even more general than this corollary. So this corollary does not",
      "tokens": [
        51308,
        457,
        264,
        3894,
        20904,
        307,
        754,
        544,
        2674,
        813,
        341,
        1181,
        1833,
        822,
        13,
        407,
        341,
        1181,
        1833,
        822,
        775,
        406,
        51548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1072603935419127,
      "compression_ratio": 1.640552995391705,
      "no_speech_prob": 0.00048316558240912855
    },
    {
      "id": 428,
      "seek": 301052,
      "start": 3010.52,
      "end": 3019.72,
      "text": " really use the full power of this theorem. All right. That's it. I think I'm going to",
      "tokens": [
        50364,
        534,
        764,
        264,
        1577,
        1347,
        295,
        341,
        20904,
        13,
        1057,
        558,
        13,
        663,
        311,
        309,
        13,
        286,
        519,
        286,
        478,
        516,
        281,
        50824
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22400899231433868,
      "compression_ratio": 1.396103896103896,
      "no_speech_prob": 0.003650674596428871
    },
    {
      "id": 429,
      "seek": 301052,
      "start": 3019.72,
      "end": 3023.24,
      "text": " finish on time. If you have questions, I will take them now.",
      "tokens": [
        50824,
        2413,
        322,
        565,
        13,
        759,
        291,
        362,
        1651,
        11,
        286,
        486,
        747,
        552,
        586,
        13,
        51000
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22400899231433868,
      "compression_ratio": 1.396103896103896,
      "no_speech_prob": 0.003650674596428871
    },
    {
      "id": 430,
      "seek": 301052,
      "start": 3030.28,
      "end": 3035.24,
      "text": " It was 55 minutes, right, for the talk. I did not go under the time.",
      "tokens": [
        51352,
        467,
        390,
        12330,
        2077,
        11,
        558,
        11,
        337,
        264,
        751,
        13,
        286,
        630,
        406,
        352,
        833,
        264,
        565,
        13,
        51600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22400899231433868,
      "compression_ratio": 1.396103896103896,
      "no_speech_prob": 0.003650674596428871
    },
    {
      "id": 431,
      "seek": 303524,
      "start": 3035.24,
      "end": 3039.16,
      "text": " It's fine. We usually allow plus minus 10 minutes. That's all right.",
      "tokens": [
        50364,
        467,
        311,
        2489,
        13,
        492,
        2673,
        2089,
        1804,
        3175,
        1266,
        2077,
        13,
        663,
        311,
        439,
        558,
        13,
        50560
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1298332458887345,
      "compression_ratio": 1.4766355140186915,
      "no_speech_prob": 0.00102254468947649
    },
    {
      "id": 432,
      "seek": 303524,
      "start": 3042.4399999999996,
      "end": 3045.8799999999997,
      "text": " So I have a question about token sliding. Yes.",
      "tokens": [
        50724,
        407,
        286,
        362,
        257,
        1168,
        466,
        14862,
        21169,
        13,
        1079,
        13,
        50896
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1298332458887345,
      "compression_ratio": 1.4766355140186915,
      "no_speech_prob": 0.00102254468947649
    },
    {
      "id": 433,
      "seek": 303524,
      "start": 3047.0,
      "end": 3054.3599999999997,
      "text": " So how crucial, what happens if one does not restrict the independent sets during the configuration",
      "tokens": [
        50952,
        407,
        577,
        11462,
        11,
        437,
        2314,
        498,
        472,
        775,
        406,
        7694,
        264,
        6695,
        6352,
        1830,
        264,
        11694,
        51320
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1298332458887345,
      "compression_ratio": 1.4766355140186915,
      "no_speech_prob": 0.00102254468947649
    },
    {
      "id": 434,
      "seek": 303524,
      "start": 3055.4799999999996,
      "end": 3062.6,
      "text": " to be not of the same size? Is that very critical for the difficulty or the easiness of the problem?",
      "tokens": [
        51376,
        281,
        312,
        406,
        295,
        264,
        912,
        2744,
        30,
        1119,
        300,
        588,
        4924,
        337,
        264,
        10360,
        420,
        264,
        1195,
        1324,
        295,
        264,
        1154,
        30,
        51732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1298332458887345,
      "compression_ratio": 1.4766355140186915,
      "no_speech_prob": 0.00102254468947649
    },
    {
      "id": 435,
      "seek": 306260,
      "start": 3062.6,
      "end": 3070.44,
      "text": " Well, you have to be careful how you define that because in token sliding, tokens cannot",
      "tokens": [
        50364,
        1042,
        11,
        291,
        362,
        281,
        312,
        5026,
        577,
        291,
        6964,
        300,
        570,
        294,
        14862,
        21169,
        11,
        22667,
        2644,
        50756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1389196955639383,
      "compression_ratio": 1.6754385964912282,
      "no_speech_prob": 0.0015254952013492584
    },
    {
      "id": 436,
      "seek": 306260,
      "start": 3070.44,
      "end": 3077.0,
      "text": " leave the graph. That's correct. But the independent set sequence, all the independent sets have to",
      "tokens": [
        50756,
        1856,
        264,
        4295,
        13,
        663,
        311,
        3006,
        13,
        583,
        264,
        6695,
        992,
        8310,
        11,
        439,
        264,
        6695,
        6352,
        362,
        281,
        51084
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1389196955639383,
      "compression_ratio": 1.6754385964912282,
      "no_speech_prob": 0.0015254952013492584
    },
    {
      "id": 437,
      "seek": 306260,
      "start": 3077.0,
      "end": 3083.4,
      "text": " be the same size, right? Well, if not, some token disappeared at some point. And I'm not sure how",
      "tokens": [
        51084,
        312,
        264,
        912,
        2744,
        11,
        558,
        30,
        1042,
        11,
        498,
        406,
        11,
        512,
        14862,
        13954,
        412,
        512,
        935,
        13,
        400,
        286,
        478,
        406,
        988,
        577,
        51404
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1389196955639383,
      "compression_ratio": 1.6754385964912282,
      "no_speech_prob": 0.0015254952013492584
    },
    {
      "id": 438,
      "seek": 306260,
      "start": 3083.4,
      "end": 3090.6,
      "text": " it disappeared. Right? Because you start with something of size K and you're going to something",
      "tokens": [
        51404,
        309,
        13954,
        13,
        1779,
        30,
        1436,
        291,
        722,
        365,
        746,
        295,
        2744,
        591,
        293,
        291,
        434,
        516,
        281,
        746,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1389196955639383,
      "compression_ratio": 1.6754385964912282,
      "no_speech_prob": 0.0015254952013492584
    },
    {
      "id": 439,
      "seek": 309060,
      "start": 3090.6,
      "end": 3099.0,
      "text": " of size K, you cannot leave the graph unless you define it in some way. So you will remain",
      "tokens": [
        50364,
        295,
        2744,
        591,
        11,
        291,
        2644,
        1856,
        264,
        4295,
        5969,
        291,
        6964,
        309,
        294,
        512,
        636,
        13,
        407,
        291,
        486,
        6222,
        50784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08690192302068074,
      "compression_ratio": 1.5132275132275133,
      "no_speech_prob": 0.003912957850843668
    },
    {
      "id": 440,
      "seek": 309060,
      "start": 3099.0,
      "end": 3105.96,
      "text": " of size K throughout. But you can become slightly larger than K. But where does the new token come",
      "tokens": [
        50784,
        295,
        2744,
        591,
        3710,
        13,
        583,
        291,
        393,
        1813,
        4748,
        4833,
        813,
        591,
        13,
        583,
        689,
        775,
        264,
        777,
        14862,
        808,
        51132
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08690192302068074,
      "compression_ratio": 1.5132275132275133,
      "no_speech_prob": 0.003912957850843668
    },
    {
      "id": 441,
      "seek": 309060,
      "start": 3105.96,
      "end": 3114.68,
      "text": " from? So there is a third rule that I did not tell you about, which is called token addition and",
      "tokens": [
        51132,
        490,
        30,
        407,
        456,
        307,
        257,
        2636,
        4978,
        300,
        286,
        630,
        406,
        980,
        291,
        466,
        11,
        597,
        307,
        1219,
        14862,
        4500,
        293,
        51568
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08690192302068074,
      "compression_ratio": 1.5132275132275133,
      "no_speech_prob": 0.003912957850843668
    },
    {
      "id": 442,
      "seek": 311468,
      "start": 3114.68,
      "end": 3123.16,
      "text": " removal. Under that rule, we actually allow you to remove vertices and add vertices as long as you",
      "tokens": [
        50364,
        17933,
        13,
        6974,
        300,
        4978,
        11,
        321,
        767,
        2089,
        291,
        281,
        4159,
        32053,
        293,
        909,
        32053,
        382,
        938,
        382,
        291,
        50788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1542463699976603,
      "compression_ratio": 1.608695652173913,
      "no_speech_prob": 0.005880639888346195
    },
    {
      "id": 443,
      "seek": 311468,
      "start": 3123.16,
      "end": 3134.04,
      "text": " remain an independent set of size at least K. Does that answer your question? Yeah. Yeah. Yeah.",
      "tokens": [
        50788,
        6222,
        364,
        6695,
        992,
        295,
        2744,
        412,
        1935,
        591,
        13,
        4402,
        300,
        1867,
        428,
        1168,
        30,
        865,
        13,
        865,
        13,
        865,
        13,
        51332
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1542463699976603,
      "compression_ratio": 1.608695652173913,
      "no_speech_prob": 0.005880639888346195
    },
    {
      "id": 444,
      "seek": 311468,
      "start": 3134.04,
      "end": 3143.3999999999996,
      "text": " Yeah. But in fact, it was shown that it was shown that so addition and removal is equivalent to token",
      "tokens": [
        51332,
        865,
        13,
        583,
        294,
        1186,
        11,
        309,
        390,
        4898,
        300,
        309,
        390,
        4898,
        300,
        370,
        4500,
        293,
        17933,
        307,
        10344,
        281,
        14862,
        51800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1542463699976603,
      "compression_ratio": 1.608695652173913,
      "no_speech_prob": 0.005880639888346195
    },
    {
      "id": 445,
      "seek": 314340,
      "start": 3143.4,
      "end": 3150.36,
      "text": " jumping. I see. It doesn't, it never makes sense to add more tokens to your graph if you don't need",
      "tokens": [
        50364,
        11233,
        13,
        286,
        536,
        13,
        467,
        1177,
        380,
        11,
        309,
        1128,
        1669,
        2020,
        281,
        909,
        544,
        22667,
        281,
        428,
        4295,
        498,
        291,
        500,
        380,
        643,
        50712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20204774160233754,
      "compression_ratio": 1.4258064516129032,
      "no_speech_prob": 0.0034582149237394333
    },
    {
      "id": 446,
      "seek": 314340,
      "start": 3150.36,
      "end": 3157.4,
      "text": " them. You're only making your life harder, intuitively speaking.",
      "tokens": [
        50712,
        552,
        13,
        509,
        434,
        787,
        1455,
        428,
        993,
        6081,
        11,
        46506,
        4124,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20204774160233754,
      "compression_ratio": 1.4258064516129032,
      "no_speech_prob": 0.0034582149237394333
    },
    {
      "id": 447,
      "seek": 314340,
      "start": 3161.08,
      "end": 3163.8,
      "text": " So the other question that I had is, I mean, I heard, I,",
      "tokens": [
        51248,
        407,
        264,
        661,
        1168,
        300,
        286,
        632,
        307,
        11,
        286,
        914,
        11,
        286,
        2198,
        11,
        286,
        11,
        51384
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20204774160233754,
      "compression_ratio": 1.4258064516129032,
      "no_speech_prob": 0.0034582149237394333
    },
    {
      "id": 448,
      "seek": 316380,
      "start": 3164.36,
      "end": 3174.6800000000003,
      "text": " so is it possible to view this whole problem on an exponential size graph where every vertex",
      "tokens": [
        50392,
        370,
        307,
        309,
        1944,
        281,
        1910,
        341,
        1379,
        1154,
        322,
        364,
        21510,
        2744,
        4295,
        689,
        633,
        28162,
        50908
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19181090134840745,
      "compression_ratio": 1.6408839779005524,
      "no_speech_prob": 0.003566075349226594
    },
    {
      "id": 449,
      "seek": 316380,
      "start": 3175.32,
      "end": 3184.04,
      "text": " corresponds to an independent set in the original graph? And then you have edges between two vertices.",
      "tokens": [
        50940,
        23249,
        281,
        364,
        6695,
        992,
        294,
        264,
        3380,
        4295,
        30,
        400,
        550,
        291,
        362,
        8819,
        1296,
        732,
        32053,
        13,
        51376
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19181090134840745,
      "compression_ratio": 1.6408839779005524,
      "no_speech_prob": 0.003566075349226594
    },
    {
      "id": 450,
      "seek": 316380,
      "start": 3184.92,
      "end": 3189.6400000000003,
      "text": " If there is an edge between two vertices of the independent set, and now you are doing a reachability",
      "tokens": [
        51420,
        759,
        456,
        307,
        364,
        4691,
        1296,
        732,
        32053,
        295,
        264,
        6695,
        992,
        11,
        293,
        586,
        291,
        366,
        884,
        257,
        2524,
        2310,
        51656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19181090134840745,
      "compression_ratio": 1.6408839779005524,
      "no_speech_prob": 0.003566075349226594
    },
    {
      "id": 451,
      "seek": 318964,
      "start": 3189.64,
      "end": 3195.56,
      "text": " question, is that a meaningful way to think about this? But that's exactly what we're doing.",
      "tokens": [
        50364,
        1168,
        11,
        307,
        300,
        257,
        10995,
        636,
        281,
        519,
        466,
        341,
        30,
        583,
        300,
        311,
        2293,
        437,
        321,
        434,
        884,
        13,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14602461814880371,
      "compression_ratio": 1.6784140969162995,
      "no_speech_prob": 0.008984023705124855
    },
    {
      "id": 452,
      "seek": 318964,
      "start": 3197.72,
      "end": 3202.8399999999997,
      "text": " The way you define your adjacency, I think, so you mean you define, you make two independent",
      "tokens": [
        50768,
        440,
        636,
        291,
        6964,
        428,
        22940,
        3020,
        11,
        286,
        519,
        11,
        370,
        291,
        914,
        291,
        6964,
        11,
        291,
        652,
        732,
        6695,
        51024
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14602461814880371,
      "compression_ratio": 1.6784140969162995,
      "no_speech_prob": 0.008984023705124855
    },
    {
      "id": 453,
      "seek": 318964,
      "start": 3202.8399999999997,
      "end": 3207.7999999999997,
      "text": " sets adjacent if one can be reached from the other via a single slide or a single jump. Exactly.",
      "tokens": [
        51024,
        6352,
        24441,
        498,
        472,
        393,
        312,
        6488,
        490,
        264,
        661,
        5766,
        257,
        2167,
        4137,
        420,
        257,
        2167,
        3012,
        13,
        7587,
        13,
        51272
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14602461814880371,
      "compression_ratio": 1.6784140969162995,
      "no_speech_prob": 0.008984023705124855
    },
    {
      "id": 454,
      "seek": 318964,
      "start": 3207.7999999999997,
      "end": 3214.04,
      "text": " Yeah. One edge. Yeah. There is one pair, U and B, which is adjacent. But that's exactly what we're",
      "tokens": [
        51272,
        865,
        13,
        1485,
        4691,
        13,
        865,
        13,
        821,
        307,
        472,
        6119,
        11,
        624,
        293,
        363,
        11,
        597,
        307,
        24441,
        13,
        583,
        300,
        311,
        2293,
        437,
        321,
        434,
        51584
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14602461814880371,
      "compression_ratio": 1.6784140969162995,
      "no_speech_prob": 0.008984023705124855
    },
    {
      "id": 455,
      "seek": 321404,
      "start": 3214.04,
      "end": 3221.88,
      "text": " doing. Okay. Yeah. Right. I mean, if you, because we're looking at algorithms here, we kind of forget",
      "tokens": [
        50364,
        884,
        13,
        1033,
        13,
        865,
        13,
        1779,
        13,
        286,
        914,
        11,
        498,
        291,
        11,
        570,
        321,
        434,
        1237,
        412,
        14642,
        510,
        11,
        321,
        733,
        295,
        2870,
        50756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14993452142786096,
      "compression_ratio": 1.5024875621890548,
      "no_speech_prob": 0.008386315777897835
    },
    {
      "id": 456,
      "seek": 321404,
      "start": 3221.88,
      "end": 3227.08,
      "text": " the structural picture behind it. But this algorithm is finding a path in this graph that you're",
      "tokens": [
        50756,
        264,
        15067,
        3036,
        2261,
        309,
        13,
        583,
        341,
        9284,
        307,
        5006,
        257,
        3100,
        294,
        341,
        4295,
        300,
        291,
        434,
        51016
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14993452142786096,
      "compression_ratio": 1.5024875621890548,
      "no_speech_prob": 0.008386315777897835
    },
    {
      "id": 457,
      "seek": 321404,
      "start": 3227.08,
      "end": 3234.6,
      "text": " describing. Yeah. Yeah. That's it. And what we're saying is you can do it in FBT time or not, depending",
      "tokens": [
        51016,
        16141,
        13,
        865,
        13,
        865,
        13,
        663,
        311,
        309,
        13,
        400,
        437,
        321,
        434,
        1566,
        307,
        291,
        393,
        360,
        309,
        294,
        479,
        33853,
        565,
        420,
        406,
        11,
        5413,
        51392
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14993452142786096,
      "compression_ratio": 1.5024875621890548,
      "no_speech_prob": 0.008386315777897835
    },
    {
      "id": 458,
      "seek": 323460,
      "start": 3234.6,
      "end": 3252.52,
      "text": " on the problem we're talking about. Hi, Amir. Hi. How are you? Yeah, I'm good. So I had a question.",
      "tokens": [
        50364,
        322,
        264,
        1154,
        321,
        434,
        1417,
        466,
        13,
        2421,
        11,
        2012,
        347,
        13,
        2421,
        13,
        1012,
        366,
        291,
        30,
        865,
        11,
        286,
        478,
        665,
        13,
        407,
        286,
        632,
        257,
        1168,
        13,
        51260
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1622329485618462,
      "compression_ratio": 1.342281879194631,
      "no_speech_prob": 0.04336007311940193
    },
    {
      "id": 459,
      "seek": 323460,
      "start": 3253.16,
      "end": 3261.24,
      "text": " So do problems remain equally hard if we bound the, if we have a restriction on the number of times,",
      "tokens": [
        51292,
        407,
        360,
        2740,
        6222,
        12309,
        1152,
        498,
        321,
        5472,
        264,
        11,
        498,
        321,
        362,
        257,
        29529,
        322,
        264,
        1230,
        295,
        1413,
        11,
        51696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1622329485618462,
      "compression_ratio": 1.342281879194631,
      "no_speech_prob": 0.04336007311940193
    },
    {
      "id": 460,
      "seek": 326124,
      "start": 3261.24,
      "end": 3264.7599999999998,
      "text": " we can move the token to a particular vertex.",
      "tokens": [
        50364,
        321,
        393,
        1286,
        264,
        14862,
        281,
        257,
        1729,
        28162,
        13,
        50540
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12594325975938278,
      "compression_ratio": 1.7024390243902439,
      "no_speech_prob": 0.002014833502471447
    },
    {
      "id": 461,
      "seek": 326124,
      "start": 3268.2,
      "end": 3271.9599999999996,
      "text": " The number of times you can move a token to a particular vertex.",
      "tokens": [
        50712,
        440,
        1230,
        295,
        1413,
        291,
        393,
        1286,
        257,
        14862,
        281,
        257,
        1729,
        28162,
        13,
        50900
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12594325975938278,
      "compression_ratio": 1.7024390243902439,
      "no_speech_prob": 0.002014833502471447
    },
    {
      "id": 462,
      "seek": 326124,
      "start": 3273.08,
      "end": 3276.4399999999996,
      "text": " Like the number of times the tokens can be moved to a vertex.",
      "tokens": [
        50956,
        1743,
        264,
        1230,
        295,
        1413,
        264,
        22667,
        393,
        312,
        4259,
        281,
        257,
        28162,
        13,
        51124
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12594325975938278,
      "compression_ratio": 1.7024390243902439,
      "no_speech_prob": 0.002014833502471447
    },
    {
      "id": 463,
      "seek": 326124,
      "start": 3278.3599999999997,
      "end": 3284.4399999999996,
      "text": " Well, that's definitely going to change the complexity in, at least intuitively speaking,",
      "tokens": [
        51220,
        1042,
        11,
        300,
        311,
        2138,
        516,
        281,
        1319,
        264,
        14024,
        294,
        11,
        412,
        1935,
        46506,
        4124,
        11,
        51524
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12594325975938278,
      "compression_ratio": 1.7024390243902439,
      "no_speech_prob": 0.002014833502471447
    },
    {
      "id": 464,
      "seek": 326124,
      "start": 3284.4399999999996,
      "end": 3289.7999999999997,
      "text": " right? Because now you're saying maybe it will, if you're bounding that by a constant,",
      "tokens": [
        51524,
        558,
        30,
        1436,
        586,
        291,
        434,
        1566,
        1310,
        309,
        486,
        11,
        498,
        291,
        434,
        5472,
        278,
        300,
        538,
        257,
        5754,
        11,
        51792
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12594325975938278,
      "compression_ratio": 1.7024390243902439,
      "no_speech_prob": 0.002014833502471447
    },
    {
      "id": 465,
      "seek": 328980,
      "start": 3289.8,
      "end": 3296.36,
      "text": " then you might be saying that I'm not allowing exponentially large sequences anymore. But in",
      "tokens": [
        50364,
        550,
        291,
        1062,
        312,
        1566,
        300,
        286,
        478,
        406,
        8293,
        37330,
        2416,
        22978,
        3602,
        13,
        583,
        294,
        50692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09510858031525009,
      "compression_ratio": 1.6324786324786325,
      "no_speech_prob": 0.0009822348365560174
    },
    {
      "id": 466,
      "seek": 328980,
      "start": 3296.36,
      "end": 3301.48,
      "text": " terms of exactly how the complexity changes, I don't have answers. I think it's a very nice",
      "tokens": [
        50692,
        2115,
        295,
        2293,
        577,
        264,
        14024,
        2962,
        11,
        286,
        500,
        380,
        362,
        6338,
        13,
        286,
        519,
        309,
        311,
        257,
        588,
        1481,
        50948
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09510858031525009,
      "compression_ratio": 1.6324786324786325,
      "no_speech_prob": 0.0009822348365560174
    },
    {
      "id": 467,
      "seek": 328980,
      "start": 3302.36,
      "end": 3310.04,
      "text": " question to pose. Even in terms of non-parameterized complexity, standard complexity, I think that",
      "tokens": [
        50992,
        1168,
        281,
        10774,
        13,
        2754,
        294,
        2115,
        295,
        2107,
        12,
        2181,
        335,
        2398,
        1602,
        14024,
        11,
        3832,
        14024,
        11,
        286,
        519,
        300,
        51376
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09510858031525009,
      "compression_ratio": 1.6324786324786325,
      "no_speech_prob": 0.0009822348365560174
    },
    {
      "id": 468,
      "seek": 328980,
      "start": 3310.04,
      "end": 3315.5600000000004,
      "text": " that would be a very interesting question because, because it will definitely affect the behavior.",
      "tokens": [
        51376,
        300,
        576,
        312,
        257,
        588,
        1880,
        1168,
        570,
        11,
        570,
        309,
        486,
        2138,
        3345,
        264,
        5223,
        13,
        51652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09510858031525009,
      "compression_ratio": 1.6324786324786325,
      "no_speech_prob": 0.0009822348365560174
    },
    {
      "id": 469,
      "seek": 331556,
      "start": 3315.56,
      "end": 3322.68,
      "text": " I'm not sure exactly how yet. I don't know of any results that ask this particular question.",
      "tokens": [
        50364,
        286,
        478,
        406,
        988,
        2293,
        577,
        1939,
        13,
        286,
        500,
        380,
        458,
        295,
        604,
        3542,
        300,
        1029,
        341,
        1729,
        1168,
        13,
        50720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25739167750566855,
      "compression_ratio": 1.587962962962963,
      "no_speech_prob": 0.0038859357591718435
    },
    {
      "id": 470,
      "seek": 331556,
      "start": 3323.88,
      "end": 3330.36,
      "text": " Okay. So I had one more question in the W hardness result that you presented. So do you know",
      "tokens": [
        50780,
        1033,
        13,
        407,
        286,
        632,
        472,
        544,
        1168,
        294,
        264,
        343,
        44019,
        1874,
        300,
        291,
        8212,
        13,
        407,
        360,
        291,
        458,
        51104
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25739167750566855,
      "compression_ratio": 1.587962962962963,
      "no_speech_prob": 0.0038859357591718435
    },
    {
      "id": 471,
      "seek": 331556,
      "start": 3330.36,
      "end": 3338.6,
      "text": " what is the length of the, the length of the changes, actually the number of changes or flips",
      "tokens": [
        51104,
        437,
        307,
        264,
        4641,
        295,
        264,
        11,
        264,
        4641,
        295,
        264,
        2962,
        11,
        767,
        264,
        1230,
        295,
        2962,
        420,
        40249,
        51516
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25739167750566855,
      "compression_ratio": 1.587962962962963,
      "no_speech_prob": 0.0038859357591718435
    },
    {
      "id": 472,
      "seek": 331556,
      "start": 3338.6,
      "end": 3343.64,
      "text": " that you make in your independence set? This is just, yes. Yes.",
      "tokens": [
        51516,
        300,
        291,
        652,
        294,
        428,
        14640,
        992,
        30,
        639,
        307,
        445,
        11,
        2086,
        13,
        1079,
        13,
        51768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25739167750566855,
      "compression_ratio": 1.587962962962963,
      "no_speech_prob": 0.0038859357591718435
    },
    {
      "id": 473,
      "seek": 334556,
      "start": 3345.64,
      "end": 3349.7999999999997,
      "text": " We do. So here the number of changes is going to be very, it's, it's, it's basically going to be",
      "tokens": [
        50368,
        492,
        360,
        13,
        407,
        510,
        264,
        1230,
        295,
        2962,
        307,
        516,
        281,
        312,
        588,
        11,
        309,
        311,
        11,
        309,
        311,
        11,
        309,
        311,
        1936,
        516,
        281,
        312,
        50576
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11591969936265858,
      "compression_ratio": 1.9644670050761421,
      "no_speech_prob": 0.0018733986653387547
    },
    {
      "id": 474,
      "seek": 334556,
      "start": 3349.7999999999997,
      "end": 3357.88,
      "text": " the shortest possible sequence. So it's, it's, it's, it's, it's basically going to be, so if you",
      "tokens": [
        50576,
        264,
        31875,
        1944,
        8310,
        13,
        407,
        309,
        311,
        11,
        309,
        311,
        11,
        309,
        311,
        11,
        309,
        311,
        11,
        309,
        311,
        1936,
        516,
        281,
        312,
        11,
        370,
        498,
        291,
        50980
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11591969936265858,
      "compression_ratio": 1.9644670050761421,
      "no_speech_prob": 0.0018733986653387547
    },
    {
      "id": 475,
      "seek": 334556,
      "start": 3357.88,
      "end": 3366.2,
      "text": " think about the simple construction, this one, it's basically literally going to be, these guys",
      "tokens": [
        50980,
        519,
        466,
        264,
        2199,
        6435,
        11,
        341,
        472,
        11,
        309,
        311,
        1936,
        3736,
        516,
        281,
        312,
        11,
        613,
        1074,
        51396
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11591969936265858,
      "compression_ratio": 1.9644670050761421,
      "no_speech_prob": 0.0018733986653387547
    },
    {
      "id": 476,
      "seek": 334556,
      "start": 3366.2,
      "end": 3372.52,
      "text": " are going to move here. So each is going to cost me one slide. And then they're all going to, and",
      "tokens": [
        51396,
        366,
        516,
        281,
        1286,
        510,
        13,
        407,
        1184,
        307,
        516,
        281,
        2063,
        385,
        472,
        4137,
        13,
        400,
        550,
        436,
        434,
        439,
        516,
        281,
        11,
        293,
        51712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11591969936265858,
      "compression_ratio": 1.9644670050761421,
      "no_speech_prob": 0.0018733986653387547
    },
    {
      "id": 477,
      "seek": 337252,
      "start": 3372.52,
      "end": 3377.88,
      "text": " now this guy is going to move here. And now I will pay one slide for each one here.",
      "tokens": [
        50364,
        586,
        341,
        2146,
        307,
        516,
        281,
        1286,
        510,
        13,
        400,
        586,
        286,
        486,
        1689,
        472,
        4137,
        337,
        1184,
        472,
        510,
        13,
        50632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10971652377735484,
      "compression_ratio": 1.655,
      "no_speech_prob": 0.0015911107184365392
    },
    {
      "id": 478,
      "seek": 337252,
      "start": 3379.0,
      "end": 3383.32,
      "text": " Now this is the simplified version of it. Once you go to the complete version of it,",
      "tokens": [
        50688,
        823,
        341,
        307,
        264,
        26335,
        3037,
        295,
        309,
        13,
        3443,
        291,
        352,
        281,
        264,
        3566,
        3037,
        295,
        309,
        11,
        50904
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10971652377735484,
      "compression_ratio": 1.655,
      "no_speech_prob": 0.0015911107184365392
    },
    {
      "id": 479,
      "seek": 337252,
      "start": 3383.32,
      "end": 3387.64,
      "text": " you have some extra slides within the path, but you can also count those.",
      "tokens": [
        50904,
        291,
        362,
        512,
        2857,
        9788,
        1951,
        264,
        3100,
        11,
        457,
        291,
        393,
        611,
        1207,
        729,
        13,
        51120
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10971652377735484,
      "compression_ratio": 1.655,
      "no_speech_prob": 0.0015911107184365392
    },
    {
      "id": 480,
      "seek": 337252,
      "start": 3389.48,
      "end": 3397.48,
      "text": " Okay. So, but does this mean that, so does this mean that at a particular vertex, we are",
      "tokens": [
        51212,
        1033,
        13,
        407,
        11,
        457,
        775,
        341,
        914,
        300,
        11,
        370,
        775,
        341,
        914,
        300,
        412,
        257,
        1729,
        28162,
        11,
        321,
        366,
        51612
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10971652377735484,
      "compression_ratio": 1.655,
      "no_speech_prob": 0.0015911107184365392
    },
    {
      "id": 481,
      "seek": 339748,
      "start": 3397.56,
      "end": 3407.4,
      "text": " placing the token at most once? In this case, yes. Okay. In this case, yes. Okay. So this problem",
      "tokens": [
        50368,
        17221,
        264,
        14862,
        412,
        881,
        1564,
        30,
        682,
        341,
        1389,
        11,
        2086,
        13,
        1033,
        13,
        682,
        341,
        1389,
        11,
        2086,
        13,
        1033,
        13,
        407,
        341,
        1154,
        50860
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12087835584368024,
      "compression_ratio": 1.607361963190184,
      "no_speech_prob": 0.01257529016584158
    },
    {
      "id": 482,
      "seek": 339748,
      "start": 3407.4,
      "end": 3412.68,
      "text": " should be hard even if we bound the number of times tokens can be moved to a vertex, right?",
      "tokens": [
        50860,
        820,
        312,
        1152,
        754,
        498,
        321,
        5472,
        264,
        1230,
        295,
        1413,
        22667,
        393,
        312,
        4259,
        281,
        257,
        28162,
        11,
        558,
        30,
        51124
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12087835584368024,
      "compression_ratio": 1.607361963190184,
      "no_speech_prob": 0.01257529016584158
    },
    {
      "id": 483,
      "seek": 339748,
      "start": 3415.64,
      "end": 3422.76,
      "text": " Yes. Okay. Yes. So, so here in this case, yes. Absolutely. Okay. Thanks.",
      "tokens": [
        51272,
        1079,
        13,
        1033,
        13,
        1079,
        13,
        407,
        11,
        370,
        510,
        294,
        341,
        1389,
        11,
        2086,
        13,
        7021,
        13,
        1033,
        13,
        2561,
        13,
        51628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12087835584368024,
      "compression_ratio": 1.607361963190184,
      "no_speech_prob": 0.01257529016584158
    },
    {
      "id": 484,
      "seek": 342276,
      "start": 3423.32,
      "end": 3432.44,
      "text": " So Akanshya, I might, I have a remark about your question. So if a vertex, if a vertex cannot get",
      "tokens": [
        50392,
        407,
        9629,
        599,
        71,
        3016,
        11,
        286,
        1062,
        11,
        286,
        362,
        257,
        7942,
        466,
        428,
        1168,
        13,
        407,
        498,
        257,
        28162,
        11,
        498,
        257,
        28162,
        2644,
        483,
        50848
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26304152352469307,
      "compression_ratio": 1.48,
      "no_speech_prob": 0.004343031905591488
    },
    {
      "id": 485,
      "seek": 342276,
      "start": 3432.44,
      "end": 3438.2000000000003,
      "text": " a token twice, then it somehow seems to be selecting disjoint independent sets,",
      "tokens": [
        50848,
        257,
        14862,
        6091,
        11,
        550,
        309,
        6063,
        2544,
        281,
        312,
        18182,
        717,
        48613,
        6695,
        6352,
        11,
        51136
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26304152352469307,
      "compression_ratio": 1.48,
      "no_speech_prob": 0.004343031905591488
    },
    {
      "id": 486,
      "seek": 342276,
      "start": 3440.84,
      "end": 3445.48,
      "text": " a sequence of them, and that may have some bearing on coloring, just a top level.",
      "tokens": [
        51268,
        257,
        8310,
        295,
        552,
        11,
        293,
        300,
        815,
        362,
        512,
        17350,
        322,
        23198,
        11,
        445,
        257,
        1192,
        1496,
        13,
        51500
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26304152352469307,
      "compression_ratio": 1.48,
      "no_speech_prob": 0.004343031905591488
    },
    {
      "id": 487,
      "seek": 344548,
      "start": 3446.28,
      "end": 3456.92,
      "text": " So actually for the W hardness case that Amir presented, it is exactly the case, right? So",
      "tokens": [
        50404,
        407,
        767,
        337,
        264,
        343,
        44019,
        1389,
        300,
        2012,
        347,
        8212,
        11,
        309,
        307,
        2293,
        264,
        1389,
        11,
        558,
        30,
        407,
        50936
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17866152859805676,
      "compression_ratio": 1.5248868778280542,
      "no_speech_prob": 0.003449946641921997
    },
    {
      "id": 488,
      "seek": 344548,
      "start": 3456.92,
      "end": 3461.32,
      "text": " we are not allowed to move the token like twice on the same vertex.",
      "tokens": [
        50936,
        321,
        366,
        406,
        4350,
        281,
        1286,
        264,
        14862,
        411,
        6091,
        322,
        264,
        912,
        28162,
        13,
        51156
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17866152859805676,
      "compression_ratio": 1.5248868778280542,
      "no_speech_prob": 0.003449946641921997
    },
    {
      "id": 489,
      "seek": 344548,
      "start": 3463.32,
      "end": 3469.4,
      "text": " Yeah. So I didn't get your point of moving. So getting this disjoint independent sets actually.",
      "tokens": [
        51256,
        865,
        13,
        407,
        286,
        994,
        380,
        483,
        428,
        935,
        295,
        2684,
        13,
        407,
        1242,
        341,
        717,
        48613,
        6695,
        6352,
        767,
        13,
        51560
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17866152859805676,
      "compression_ratio": 1.5248868778280542,
      "no_speech_prob": 0.003449946641921997
    },
    {
      "id": 490,
      "seek": 344548,
      "start": 3470.12,
      "end": 3474.76,
      "text": " Because if you say, if you think of it from my, the way I thought about it, right,",
      "tokens": [
        51596,
        1436,
        498,
        291,
        584,
        11,
        498,
        291,
        519,
        295,
        309,
        490,
        452,
        11,
        264,
        636,
        286,
        1194,
        466,
        309,
        11,
        558,
        11,
        51828
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17866152859805676,
      "compression_ratio": 1.5248868778280542,
      "no_speech_prob": 0.003449946641921997
    },
    {
      "id": 491,
      "seek": 347476,
      "start": 3474.76,
      "end": 3479.48,
      "text": " that you are actually trying to find a path in a large graph where every vertex corresponds to",
      "tokens": [
        50364,
        300,
        291,
        366,
        767,
        1382,
        281,
        915,
        257,
        3100,
        294,
        257,
        2416,
        4295,
        689,
        633,
        28162,
        23249,
        281,
        50600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21240680694580077,
      "compression_ratio": 1.6702702702702703,
      "no_speech_prob": 0.003509762929752469
    },
    {
      "id": 492,
      "seek": 347476,
      "start": 3479.48,
      "end": 3487.4,
      "text": " an independent set and you move from one independent set to another. So, but we can only move from",
      "tokens": [
        50600,
        364,
        6695,
        992,
        293,
        291,
        1286,
        490,
        472,
        6695,
        992,
        281,
        1071,
        13,
        407,
        11,
        457,
        321,
        393,
        787,
        1286,
        490,
        50996
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21240680694580077,
      "compression_ratio": 1.6702702702702703,
      "no_speech_prob": 0.003509762929752469
    },
    {
      "id": 493,
      "seek": 347476,
      "start": 3487.4,
      "end": 3496.6000000000004,
      "text": " one independent set to the other if the changes is like in case of token sliding, it's one probably.",
      "tokens": [
        50996,
        472,
        6695,
        992,
        281,
        264,
        661,
        498,
        264,
        2962,
        307,
        411,
        294,
        1389,
        295,
        14862,
        21169,
        11,
        309,
        311,
        472,
        1391,
        13,
        51456
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21240680694580077,
      "compression_ratio": 1.6702702702702703,
      "no_speech_prob": 0.003509762929752469
    },
    {
      "id": 494,
      "seek": 347476,
      "start": 3497.48,
      "end": 3498.2000000000003,
      "text": " Yeah. Exactly.",
      "tokens": [
        51500,
        865,
        13,
        7587,
        13,
        51536
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21240680694580077,
      "compression_ratio": 1.6702702702702703,
      "no_speech_prob": 0.003509762929752469
    },
    {
      "id": 495,
      "seek": 349820,
      "start": 3498.6,
      "end": 3509.0,
      "text": " So it looks to me that you're asking for a collection of independent sets which are",
      "tokens": [
        50384,
        407,
        309,
        1542,
        281,
        385,
        300,
        291,
        434,
        3365,
        337,
        257,
        5765,
        295,
        6695,
        6352,
        597,
        366,
        50904
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16949027973216968,
      "compression_ratio": 1.722488038277512,
      "no_speech_prob": 0.0025276250671595335
    },
    {
      "id": 496,
      "seek": 349820,
      "start": 3509.0,
      "end": 3513.96,
      "text": " vertex disjoint. If the token, a sequence of independent sets which are vertex disjoint.",
      "tokens": [
        50904,
        28162,
        717,
        48613,
        13,
        759,
        264,
        14862,
        11,
        257,
        8310,
        295,
        6695,
        6352,
        597,
        366,
        28162,
        717,
        48613,
        13,
        51152
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16949027973216968,
      "compression_ratio": 1.722488038277512,
      "no_speech_prob": 0.0025276250671595335
    },
    {
      "id": 497,
      "seek": 349820,
      "start": 3514.9199999999996,
      "end": 3521.56,
      "text": " Yeah. So if I may, I think, I think a conscious question would be more relevant in a place where",
      "tokens": [
        51200,
        865,
        13,
        407,
        498,
        286,
        815,
        11,
        286,
        519,
        11,
        286,
        519,
        257,
        6648,
        1168,
        576,
        312,
        544,
        7340,
        294,
        257,
        1081,
        689,
        51532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16949027973216968,
      "compression_ratio": 1.722488038277512,
      "no_speech_prob": 0.0025276250671595335
    },
    {
      "id": 498,
      "seek": 349820,
      "start": 3521.56,
      "end": 3527.64,
      "text": " we don't have a monotone sequence, meaning a sequence. So we need a version of the problem",
      "tokens": [
        51532,
        321,
        500,
        380,
        362,
        257,
        1108,
        310,
        546,
        8310,
        11,
        3620,
        257,
        8310,
        13,
        407,
        321,
        643,
        257,
        3037,
        295,
        264,
        1154,
        51836
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16949027973216968,
      "compression_ratio": 1.722488038277512,
      "no_speech_prob": 0.0025276250671595335
    },
    {
      "id": 499,
      "seek": 352764,
      "start": 3527.64,
      "end": 3531.96,
      "text": " or some cases of the problem where a vertex has to be visited multiple times",
      "tokens": [
        50364,
        420,
        512,
        3331,
        295,
        264,
        1154,
        689,
        257,
        28162,
        575,
        281,
        312,
        11220,
        3866,
        1413,
        50580
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12995493412017822,
      "compression_ratio": 1.7372549019607844,
      "no_speech_prob": 0.0017006213311105967
    },
    {
      "id": 500,
      "seek": 352764,
      "start": 3533.56,
      "end": 3539.08,
      "text": " to find solutions. And that is known to be the case for some versions or some statements of the",
      "tokens": [
        50660,
        281,
        915,
        6547,
        13,
        400,
        300,
        307,
        2570,
        281,
        312,
        264,
        1389,
        337,
        512,
        9606,
        420,
        512,
        12363,
        295,
        264,
        50936
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12995493412017822,
      "compression_ratio": 1.7372549019607844,
      "no_speech_prob": 0.0017006213311105967
    },
    {
      "id": 501,
      "seek": 352764,
      "start": 3539.08,
      "end": 3544.68,
      "text": " problem. And in fact, I can just also, this is also, this was the crucial difference between",
      "tokens": [
        50936,
        1154,
        13,
        400,
        294,
        1186,
        11,
        286,
        393,
        445,
        611,
        11,
        341,
        307,
        611,
        11,
        341,
        390,
        264,
        11462,
        2649,
        1296,
        51216
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12995493412017822,
      "compression_ratio": 1.7372549019607844,
      "no_speech_prob": 0.0017006213311105967
    },
    {
      "id": 502,
      "seek": 352764,
      "start": 3544.68,
      "end": 3549.96,
      "text": " piece-based completeness and NP completeness of sliding versus jumping in bipartite graphs.",
      "tokens": [
        51216,
        2522,
        12,
        6032,
        1557,
        15264,
        293,
        38611,
        1557,
        15264,
        295,
        21169,
        5717,
        11233,
        294,
        28741,
        642,
        24877,
        13,
        51480
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12995493412017822,
      "compression_ratio": 1.7372549019607844,
      "no_speech_prob": 0.0017006213311105967
    },
    {
      "id": 503,
      "seek": 352764,
      "start": 3551.16,
      "end": 3555.72,
      "text": " So it was because we were able to show that no vertex will be visited more than once.",
      "tokens": [
        51540,
        407,
        309,
        390,
        570,
        321,
        645,
        1075,
        281,
        855,
        300,
        572,
        28162,
        486,
        312,
        11220,
        544,
        813,
        1564,
        13,
        51768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12995493412017822,
      "compression_ratio": 1.7372549019607844,
      "no_speech_prob": 0.0017006213311105967
    },
    {
      "id": 504,
      "seek": 355764,
      "start": 3558.04,
      "end": 3562.3599999999997,
      "text": " And the other problem. So that's why it's definitely an interesting question to pose,",
      "tokens": [
        50384,
        400,
        264,
        661,
        1154,
        13,
        407,
        300,
        311,
        983,
        309,
        311,
        2138,
        364,
        1880,
        1168,
        281,
        10774,
        11,
        50600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1970676329077744,
      "compression_ratio": 1.4216216216216215,
      "no_speech_prob": 0.00422322703525424
    },
    {
      "id": 505,
      "seek": 355764,
      "start": 3562.3599999999997,
      "end": 3565.0,
      "text": " but you have to be careful in what context you pose it.",
      "tokens": [
        50600,
        457,
        291,
        362,
        281,
        312,
        5026,
        294,
        437,
        4319,
        291,
        10774,
        309,
        13,
        50732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1970676329077744,
      "compression_ratio": 1.4216216216216215,
      "no_speech_prob": 0.00422322703525424
    },
    {
      "id": 506,
      "seek": 355764,
      "start": 3566.2,
      "end": 3566.52,
      "text": " Great.",
      "tokens": [
        50792,
        3769,
        13,
        50808
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1970676329077744,
      "compression_ratio": 1.4216216216216215,
      "no_speech_prob": 0.00422322703525424
    },
    {
      "id": 507,
      "seek": 355764,
      "start": 3569.0,
      "end": 3573.64,
      "text": " I don't know if that kind of settles, answers your question.",
      "tokens": [
        50932,
        286,
        500,
        380,
        458,
        498,
        300,
        733,
        295,
        5584,
        904,
        11,
        6338,
        428,
        1168,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1970676329077744,
      "compression_ratio": 1.4216216216216215,
      "no_speech_prob": 0.00422322703525424
    },
    {
      "id": 508,
      "seek": 355764,
      "start": 3574.68,
      "end": 3575.56,
      "text": " Yes, yes, it does.",
      "tokens": [
        51216,
        1079,
        11,
        2086,
        11,
        309,
        775,
        13,
        51260
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1970676329077744,
      "compression_ratio": 1.4216216216216215,
      "no_speech_prob": 0.00422322703525424
    },
    {
      "id": 509,
      "seek": 355764,
      "start": 3576.2,
      "end": 3576.52,
      "text": " All right.",
      "tokens": [
        51292,
        1057,
        558,
        13,
        51308
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1970676329077744,
      "compression_ratio": 1.4216216216216215,
      "no_speech_prob": 0.00422322703525424
    },
    {
      "id": 510,
      "seek": 355764,
      "start": 3577.3199999999997,
      "end": 3577.72,
      "text": " Thanks.",
      "tokens": [
        51348,
        2561,
        13,
        51368
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1970676329077744,
      "compression_ratio": 1.4216216216216215,
      "no_speech_prob": 0.00422322703525424
    },
    {
      "id": 511,
      "seek": 355764,
      "start": 3578.44,
      "end": 3579.08,
      "text": " You're welcome.",
      "tokens": [
        51404,
        509,
        434,
        2928,
        13,
        51436
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1970676329077744,
      "compression_ratio": 1.4216216216216215,
      "no_speech_prob": 0.00422322703525424
    },
    {
      "id": 512,
      "seek": 357908,
      "start": 3579.08,
      "end": 3588.52,
      "text": " Any more questions?",
      "tokens": [
        50364,
        2639,
        544,
        1651,
        30,
        50836
      ],
      "temperature": 0.0,
      "avg_logprob": -0.8273048400878906,
      "compression_ratio": 0.7037037037037037,
      "no_speech_prob": 0.014697320759296417
    },
    {
      "id": 513,
      "seek": 360908,
      "start": 3609.48,
      "end": 3620.44,
      "text": " I guess not.",
      "tokens": [
        50384,
        286,
        2041,
        406,
        13,
        50932
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2635530615752598,
      "compression_ratio": 1.3503184713375795,
      "no_speech_prob": 0.008060523308813572
    },
    {
      "id": 514,
      "seek": 360908,
      "start": 3621.24,
      "end": 3627.4,
      "text": " Yeah, I don't think there are any more questions. I will just once again announce the parameterized",
      "tokens": [
        50972,
        865,
        11,
        286,
        500,
        380,
        519,
        456,
        366,
        604,
        544,
        1651,
        13,
        286,
        486,
        445,
        1564,
        797,
        7478,
        264,
        13075,
        1602,
        51280
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2635530615752598,
      "compression_ratio": 1.3503184713375795,
      "no_speech_prob": 0.008060523308813572
    },
    {
      "id": 515,
      "seek": 360908,
      "start": 3627.4,
      "end": 3633.48,
      "text": " algorithm 301 workshop, which is going to happen in December in the link has been posted once again",
      "tokens": [
        51280,
        9284,
        2217,
        16,
        13541,
        11,
        597,
        307,
        516,
        281,
        1051,
        294,
        7687,
        294,
        264,
        2113,
        575,
        668,
        9437,
        1564,
        797,
        51584
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2635530615752598,
      "compression_ratio": 1.3503184713375795,
      "no_speech_prob": 0.008060523308813572
    },
    {
      "id": 516,
      "seek": 363348,
      "start": 3633.48,
      "end": 3639.48,
      "text": " in the chat. Some advanced topics in parameterized complexity will be discussed. Those interested",
      "tokens": [
        50364,
        294,
        264,
        5081,
        13,
        2188,
        7339,
        8378,
        294,
        13075,
        1602,
        14024,
        486,
        312,
        7152,
        13,
        3950,
        3102,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16644395192464193,
      "compression_ratio": 1.3287671232876712,
      "no_speech_prob": 0.0076775033958256245
    },
    {
      "id": 517,
      "seek": 363348,
      "start": 3639.48,
      "end": 3658.84,
      "text": " can have a look and register for it. And yeah, if there are any more questions, please ask away.",
      "tokens": [
        50664,
        393,
        362,
        257,
        574,
        293,
        7280,
        337,
        309,
        13,
        400,
        1338,
        11,
        498,
        456,
        366,
        604,
        544,
        1651,
        11,
        1767,
        1029,
        1314,
        13,
        51632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16644395192464193,
      "compression_ratio": 1.3287671232876712,
      "no_speech_prob": 0.0076775033958256245
    },
    {
      "id": 518,
      "seek": 366348,
      "start": 3663.48,
      "end": 3678.84,
      "text": " So anyone can register for the school?",
      "tokens": [
        50364,
        407,
        2878,
        393,
        7280,
        337,
        264,
        1395,
        30,
        51132
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2563601571160394,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.00853046029806137
    },
    {
      "id": 519,
      "seek": 366348,
      "start": 3679.32,
      "end": 3680.44,
      "text": " Yes, yes, anyone can.",
      "tokens": [
        51156,
        1079,
        11,
        2086,
        11,
        2878,
        393,
        13,
        51212
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2563601571160394,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.00853046029806137
    },
    {
      "id": 520,
      "seek": 366348,
      "start": 3683.4,
      "end": 3687.16,
      "text": " Yeah, it's free and it's online and yeah, it's open to everyone.",
      "tokens": [
        51360,
        865,
        11,
        309,
        311,
        1737,
        293,
        309,
        311,
        2950,
        293,
        1338,
        11,
        309,
        311,
        1269,
        281,
        1518,
        13,
        51548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2563601571160394,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.00853046029806137
    },
    {
      "id": 521,
      "seek": 366348,
      "start": 3688.12,
      "end": 3690.36,
      "text": " Awesome. So I can share it with my students as well.",
      "tokens": [
        51596,
        10391,
        13,
        407,
        286,
        393,
        2073,
        309,
        365,
        452,
        1731,
        382,
        731,
        13,
        51708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2563601571160394,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.00853046029806137
    },
    {
      "id": 522,
      "seek": 366348,
      "start": 3690.36,
      "end": 3692.52,
      "text": " Of course, of course, please do. Yeah, that would be good.",
      "tokens": [
        51708,
        2720,
        1164,
        11,
        295,
        1164,
        11,
        1767,
        360,
        13,
        865,
        11,
        300,
        576,
        312,
        665,
        13,
        51816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2563601571160394,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.00853046029806137
    },
    {
      "id": 523,
      "seek": 369252,
      "start": 3692.52,
      "end": 3698.68,
      "text": " And we assume some basic understanding of parameterized algorithms, but we have already",
      "tokens": [
        50364,
        400,
        321,
        6552,
        512,
        3875,
        3701,
        295,
        13075,
        1602,
        14642,
        11,
        457,
        321,
        362,
        1217,
        50672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11125267876519097,
      "compression_ratio": 1.5403726708074534,
      "no_speech_prob": 0.0023847308475524187
    },
    {
      "id": 524,
      "seek": 369252,
      "start": 3698.68,
      "end": 3705.16,
      "text": " shared a link on the page where students can go and go through some previous lectures in",
      "tokens": [
        50672,
        5507,
        257,
        2113,
        322,
        264,
        3028,
        689,
        1731,
        393,
        352,
        293,
        352,
        807,
        512,
        3894,
        16564,
        294,
        50996
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11125267876519097,
      "compression_ratio": 1.5403726708074534,
      "no_speech_prob": 0.0023847308475524187
    },
    {
      "id": 525,
      "seek": 369252,
      "start": 3705.16,
      "end": 3710.36,
      "text": " parameterized algorithms if they wish to just brace up or revise stuff.",
      "tokens": [
        50996,
        13075,
        1602,
        14642,
        498,
        436,
        3172,
        281,
        445,
        38458,
        493,
        420,
        44252,
        1507,
        13,
        51256
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11125267876519097,
      "compression_ratio": 1.5403726708074534,
      "no_speech_prob": 0.0023847308475524187
    },
    {
      "id": 526,
      "seek": 371036,
      "start": 3710.36,
      "end": 3725.32,
      "text": " All right, so I guess, okay, I don't think there are any more questions. So maybe this is a good",
      "tokens": [
        50364,
        1057,
        558,
        11,
        370,
        286,
        2041,
        11,
        1392,
        11,
        286,
        500,
        380,
        519,
        456,
        366,
        604,
        544,
        1651,
        13,
        407,
        1310,
        341,
        307,
        257,
        665,
        51112
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23009024168315687,
      "compression_ratio": 1.5154639175257731,
      "no_speech_prob": 0.012436045333743095
    },
    {
      "id": 527,
      "seek": 371036,
      "start": 3725.32,
      "end": 3732.1200000000003,
      "text": " time to wrap up. So thank you once again, Professor Amitro for agreeing to give the talk. It was",
      "tokens": [
        51112,
        565,
        281,
        7019,
        493,
        13,
        407,
        1309,
        291,
        1564,
        797,
        11,
        8419,
        2012,
        270,
        340,
        337,
        36900,
        281,
        976,
        264,
        751,
        13,
        467,
        390,
        51452
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23009024168315687,
      "compression_ratio": 1.5154639175257731,
      "no_speech_prob": 0.012436045333743095
    },
    {
      "id": 528,
      "seek": 371036,
      "start": 3732.1200000000003,
      "end": 3736.84,
      "text": " really nice to have you and it was really good to have something different than what we usually hear",
      "tokens": [
        51452,
        534,
        1481,
        281,
        362,
        291,
        293,
        309,
        390,
        534,
        665,
        281,
        362,
        746,
        819,
        813,
        437,
        321,
        2673,
        1568,
        51688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23009024168315687,
      "compression_ratio": 1.5154639175257731,
      "no_speech_prob": 0.012436045333743095
    },
    {
      "id": 529,
      "seek": 373684,
      "start": 3736.84,
      "end": 3743.0,
      "text": " in every parent-based complexity talk, at least most of them. So and yeah, these are really",
      "tokens": [
        50364,
        294,
        633,
        2596,
        12,
        6032,
        14024,
        751,
        11,
        412,
        1935,
        881,
        295,
        552,
        13,
        407,
        293,
        1338,
        11,
        613,
        366,
        534,
        50672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18293140994177925,
      "compression_ratio": 1.4972067039106145,
      "no_speech_prob": 0.0029446918051689863
    },
    {
      "id": 530,
      "seek": 373684,
      "start": 3743.0,
      "end": 3749.4,
      "text": " interesting problems to think upon. And thank you to the audience for being with us. And that's",
      "tokens": [
        50672,
        1880,
        2740,
        281,
        519,
        3564,
        13,
        400,
        1309,
        291,
        281,
        264,
        4034,
        337,
        885,
        365,
        505,
        13,
        400,
        300,
        311,
        50992
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18293140994177925,
      "compression_ratio": 1.4972067039106145,
      "no_speech_prob": 0.0029446918051689863
    },
    {
      "id": 531,
      "seek": 373684,
      "start": 3749.4,
      "end": 3757.48,
      "text": " it for today. We wrap up. See you all next week. Thank you. Bye. Thank you. Bye.",
      "tokens": [
        50992,
        309,
        337,
        965,
        13,
        492,
        7019,
        493,
        13,
        3008,
        291,
        439,
        958,
        1243,
        13,
        1044,
        291,
        13,
        4621,
        13,
        1044,
        291,
        13,
        4621,
        13,
        51396
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18293140994177925,
      "compression_ratio": 1.4972067039106145,
      "no_speech_prob": 0.0029446918051689863
    }
  ],
  "language": "en"
}